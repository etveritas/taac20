{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if used pip install package\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install wget\n",
    "# !pip install gensim\n",
    "# !pip install catboost\n",
    "# !pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import gc\n",
    "import wget\n",
    "import time\n",
    "import tarfile\n",
    "import zipfile\n",
    "import functools\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from itertools import product, combinations\n",
    "from scipy.special import comb, perm\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cbt\n",
    "from glove import *\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression,BayesianRidge,SGDClassifier,PassiveAggressiveClassifier,RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC,NuSVC,SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Conv1D, LSTM, GRU  #, CuDNNGRU, CuDNNLSTM\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import *\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import gensim\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.init(object_store_memory=int(100e6))\n",
    "# import modin.pandas as pd\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, filename='default.log', stream=sys.stdout):\n",
    "        self.terminal = stream\n",
    "        self.log = open(filename, 'a')\n",
    "        \n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "        \n",
    "    def flush(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.stdout = Logger(\"logs/default.log\", sys.stdout)\n",
    "# sys.stderr = Logger(\"logs/default_err.log\", sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDIR = \"data\"\n",
    "UDDIR = \"user_data\"\n",
    "UFEDIR = \"user_data/feat_data_v05\"\n",
    "UMDIR = \"user_data/model_data\"\n",
    "RESDIR = \"prediction_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UID = \"user_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (Only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fname = wget.download(\"https://tesla-ap-shanghai-1256322946.cos.ap-shanghai.myqcloud.com/cephfs/tesla_common/deeplearning/dataset/algo_contest/train_preliminary.zip\", out=DDIR)\n",
    "# test_fname = wget.download(\"https://tesla-ap-shanghai-1256322946.cos.ap-shanghai.myqcloud.com/cephfs/tesla_common/deeplearning/dataset/algo_contest/test.zip\", out=DDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myunzip(filename):\n",
    "#     zFile = zipfile.ZipFile(filename, \"r\")\n",
    "#     for fileM in zFile.namelist(): \n",
    "#         zFile.extract(fileM, DDIR)\n",
    "#         print(fileM)\n",
    "#     zFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myunzip(train_fname)\n",
    "# myunzip(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bch_rencol(values, prefix=\"\", suffix=\"\"):\n",
    "    return list(map(lambda x: f\"{prefix}\"+\"_\".join(list(map(lambda y: str(y), x)))+f\"{suffix}\" \n",
    "                    if hasattr(x, \"__iter__\") and not isinstance(x, str) \n",
    "                    else f\"{prefix}\"+str(x)+f\"{suffix}\", values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mynunique(values):\n",
    "    return values.nunique(dropna=False)\n",
    "def getidxmax(x):\n",
    "    return x.idxmax()[1]\n",
    "# for time series\n",
    "def at_len(x):\n",
    "    return len(x)\n",
    "\n",
    "def at_sum(x):\n",
    "    return np.sum(x)\n",
    "\n",
    "def at_max(x):\n",
    "    return np.max(x)\n",
    "\n",
    "def at_min(x):\n",
    "    return np.min(x)\n",
    "\n",
    "def at_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def at_range(x):\n",
    "    return at_max(x) - at_min(x)\n",
    "\n",
    "def at_nunq(x):\n",
    "    return len(set(x))\n",
    "\n",
    "def at_lenDrange(x):\n",
    "    return at_len(x)/(at_range(x)+1)\n",
    "\n",
    "def at_lenDnunq(x):\n",
    "    return at_len(x)/at_nunq(x)\n",
    "\n",
    "def at_percentile(n):\n",
    "    def at_percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    at_percentile_.__name__ = f\"at_percentile_{n}\"\n",
    "    return at_percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP_SET = [\"sum\", \"max\", \"min\", \"mean\", \"std\"]\n",
    "OP_SET1 = [\"nunique\", \"sum\", \"max\", \"min\", \"mean\", \"std\", \"median\", \"skew\", at_percentile(0.25), at_percentile(0.75)]\n",
    "OP_SET2 = [\"sum\", \"max\", \"min\", \"mean\", \"std\", \"median\", \"skew\", at_percentile(0.25), at_percentile(0.75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_SET = [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\", \"time\", \"click_times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesting_level = 0\n",
    "is_start = None\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "        self.history = [self.start]\n",
    "\n",
    "    def check(self, info):\n",
    "        current = time.time()\n",
    "        print(f\"[{info}] spend {current - self.history[-1]:0.2f} sec\")\n",
    "        self.history.append(current)\n",
    "\n",
    "def log(entry):\n",
    "    global nesting_level\n",
    "    space = \"-\" * (4 * nesting_level)\n",
    "    print(f\"{space}{entry}\")\n",
    "\n",
    "def timeit(method, start_log=None):\n",
    "    @functools.wraps(method)\n",
    "    def timed(*args, **kw):\n",
    "        global is_start\n",
    "        global nesting_level\n",
    "\n",
    "        if not is_start:\n",
    "            print()\n",
    "\n",
    "        is_start = True\n",
    "        log(f\"Start [{method.__name__}]:\" + (start_log if start_log else \"\"))\n",
    "        log(f'Start time: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "        nesting_level += 1\n",
    "\n",
    "        start_time = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        end_time = time.time()\n",
    "\n",
    "        nesting_level -= 1\n",
    "        log(f\"End   [{method.__name__}]. Time elapsed: {end_time - start_time:0.2f} sec.\")\n",
    "        is_start = False\n",
    "\n",
    "        return result\n",
    "\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training&Prediction by NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAdam(Optimizer):\n",
    "\n",
    "    \"\"\"RAdam optimizer.\n",
    "\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.learning_rate\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = self.total_steps - warmup_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr * (1.0 - K.minimum(t, decay_steps) / decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t) + self.epsilon)\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t > 5, r_t * m_corr_t / v_corr_t, m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'lr': float(K.get_value(self.learning_rate)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lookahead(object):\n",
    "    \"\"\"Add the [Lookahead Optimizer](https://arxiv.org/abs/1907.08610) functionality for [keras](https://keras.io/).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5, alpha=0.5):\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.count = 0\n",
    "\n",
    "    def inject(self, model):\n",
    "        \"\"\"Inject the Lookahead algorithm for the given model.\n",
    "        The following code is modified from keras's _make_train_function method.\n",
    "        See: https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L497\n",
    "        \"\"\"\n",
    "        if not hasattr(model, 'train_function'):\n",
    "            raise RuntimeError('You must compile your model before using it.')\n",
    "\n",
    "        model._check_trainable_weights_consistency()\n",
    "\n",
    "        if model.train_function is None:\n",
    "            inputs = (model._feed_inputs +\n",
    "                      model._feed_targets +\n",
    "                      model._feed_sample_weights)\n",
    "            if model._uses_dynamic_learning_phase():\n",
    "                inputs += [K.learning_phase()]\n",
    "            fast_params = model._collected_trainable_weights\n",
    "\n",
    "            with K.name_scope('training'):\n",
    "                with K.name_scope(model.optimizer.__class__.__name__):\n",
    "                    training_updates = model.optimizer.get_updates(\n",
    "                        params=fast_params,\n",
    "                        loss=model.total_loss)\n",
    "                    slow_params = [K.variable(p) for p in fast_params]\n",
    "                fast_updates = (model.updates +\n",
    "                                training_updates +\n",
    "                                model.metrics_updates)\n",
    "\n",
    "                slow_updates, copy_updates = [], []\n",
    "                for p, q in zip(fast_params, slow_params):\n",
    "                    slow_updates.append(K.update(q, q + self.alpha * (p - q)))\n",
    "                    copy_updates.append(K.update(p, q))\n",
    "\n",
    "                # Gets loss and metrics. Updates weights at each call.\n",
    "                fast_train_function = K.function(\n",
    "                    inputs,\n",
    "                    [model.total_loss] + model.metrics_tensors,\n",
    "                    updates=fast_updates,\n",
    "                    name='fast_train_function',\n",
    "                    **model._function_kwargs)\n",
    "\n",
    "                def F(inputs):\n",
    "                    self.count += 1\n",
    "                    R = fast_train_function(inputs)\n",
    "                    if self.count % self.k == 0:\n",
    "                        K.batch_get_value(slow_updates)\n",
    "                        K.batch_get_value(copy_updates)\n",
    "                    return R\n",
    "                \n",
    "                model.train_function = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(tf.keras.backend.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = tf.keras.backend.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamW(Optimizer):\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/4)\n",
    "                 epsilon=1e-8, decay=0., **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            # decoupled weight decay (2/4)\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay')\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "#     @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd  # decoupled weight decay (3/4)\n",
    "\n",
    "        lr = self.learning_rate\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            # decoupled weight decay (4/4)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - lr * wd * p\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.learning_rate)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.wd)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position_Embedding(Layer): \n",
    "    def __init__(self, size=None, mode='sum', **kwargs):        \n",
    "        self.size = size         \n",
    "        self.mode = mode       \n",
    "        super(Position_Embedding, self).__init__(**kwargs) \n",
    "\n",
    "    def call(self, x): \n",
    "        if (self.size == None) or (self.mode == 'sum'):            \n",
    "            self.size = int(x.shape[-1])        \n",
    "            batch_size, seq_len = K.shape(x)[0], K.shape(x)[1]        \n",
    "            position_j = 1. / K.pow(10000., \\\n",
    "                2 * K.arange(self.size / 2, dtype='float32') / self.size)        \n",
    "            position_j = K.expand_dims(position_j, 0)        \n",
    "            position_i = K.cumsum(K.ones_like(x[:, :, 0]), 1)-1     \n",
    "            position_i = K.expand_dims(position_i, 2)        \n",
    "            position_ij = K.dot(position_i, position_j)        \n",
    "            position_ij = K.concatenate([K.cos(position_ij), K.sin(position_ij)], 2) \n",
    "            if self.mode == 'sum': \n",
    "                return position_ij + x \n",
    "            elif self.mode == 'concat': \n",
    "                return K.concatenate([position_ij, x], 2) \n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        if self.mode == 'sum': \n",
    "            return input_shape \n",
    "        elif self.mode == 'concat': \n",
    "            return (input_shape[0], input_shape[1], input_shape[2]+self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Layer): \n",
    "    def __init__(self, output_dim=30, activation=\"relu\",**kwargs): \n",
    "        self.output_dim = output_dim \n",
    "        self.activate = activations.get(activation)\n",
    "        super(FM, self).__init__(**kwargs) \n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.weight = self.add_weight(name='weight',shape=(input_shape[1], self.output_dim),initializer='glorot_uniform',trainable=True) \n",
    "        self.bias = self.add_weight(name='bias',shape=(self.output_dim,),initializer='zeros',trainable=True) \n",
    "        self.kernel = self.add_weight(name='kernel',shape=(input_shape[1], self.output_dim),initializer='glorot_uniform',trainable=True) \n",
    "        super(FM, self).build(input_shape) \n",
    "        \n",
    "    def call(self, x):\n",
    "        feature = K.dot(x,self.weight) + self.bias\n",
    "        a = K.pow(K.dot(x,self.kernel), 2)\n",
    "        b = K.dot(x, K.pow(self.kernel, 2))\n",
    "        cross = K.mean(a-b, 1, keepdims=True)*0.5\n",
    "        cross = K.repeat_elements(K.reshape(cross, (-1, 1)), self.output_dim, axis=-1) \n",
    "        return self.activate(feature + cross) \n",
    "    \n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(inshape, outshape):\n",
    "    # create two models\n",
    "    input1 = Input(shape=inshape)\n",
    "    embed_1 = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(input1)\n",
    "#     lstm_1 = LSTM(256)\n",
    "    dense_1 = Dense(128, kernel_initializer='normal', activation='relu')(input1)\n",
    "#     dense_1 = Dropout(0.5)(dense_1)\n",
    "    dense_2 = Dense(64, kernel_initializer='normal', activation='relu')(dense_1)\n",
    "#     dense_2 = Dropout(0.5)(dense_2)\n",
    "    dense_3 = Dense(32, kernel_initializer='normal', activation='relu')(dense_2)\n",
    "#     dense_3 = Dropout(0.5)(dense_3)\n",
    "    out     = Dense(outshape,kernel_initializer='normal', activation='softmax')(dense_3)\n",
    "    # Compile model\n",
    "    model = Model(inputs=input1, outputs = out)\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer=\"adadelta\", metrics=['accuracy'])  #logloss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet(inshape, outshape):\n",
    "    # create two models\n",
    "    input1  = Input(shape=inshape)\n",
    "\n",
    "    dense_1 = Dense(256, kernel_initializer='normal', activation='relu')(input1)\n",
    "    #dense_1 = Dropout(0.6)(dense_1)\n",
    "    dense_2 = Dense(128, kernel_initializer='normal', activation='relu')(dense_1)\n",
    "    #dense_2 = Dropout(0.6)(dense_2)\n",
    "    dense_2_x  = concatenate([dense_1,dense_2])\n",
    "    dense_3 = Dense(64, kernel_initializer='normal', activation='relu')(dense_2_x)\n",
    "    #dense_3 = Dropout(0.6)(dense_3)\n",
    "    dense_3_x  = concatenate([dense_1,dense_2,dense_3])\n",
    "    dense_4 = Dense(7, kernel_initializer='normal', activation='relu')(dense_3_x)\n",
    "    #dense_4 = Dropout(0.6)(dense_4)\n",
    "    dense_4_x  = concatenate([dense_1,dense_2,dense_3,dense_4])\n",
    "    out     = Dense(outshape,kernel_initializer='normal', activation='softmax')(dense_4_x)\n",
    "    # Compile model\n",
    "    model = Model(inputs=input1, outputs = out)\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FMNet(inshape, outshape):\n",
    "    # create two models\n",
    "    input1  = Input(shape=inshape)\n",
    "    #DNN_model_I\n",
    "    dense_1 = Dense(100, kernel_initializer='normal', activation='tanh')(input1)\n",
    "    dense_2 = Dense(150, kernel_initializer='normal', activation='tanh')(dense_1)\n",
    "    dense_3 = Dense(150, kernel_initializer='normal', activation='tanh')(dense_2)\n",
    "    dense_4 = Dense(100, kernel_initializer='normal', activation='tanh')(dense_3)\n",
    "    dense_5 = Dense(64, kernel_initializer='normal', activation='tanh')(dense_4)\n",
    "    #FM_model_II\n",
    "    FM_1    = FM(200)(input1)\n",
    "    FM_2    = FM(64)(FM_1)\n",
    "\n",
    "    x       = concatenate([dense_5,FM_2])\n",
    "    x_tmp   = Dense(32,kernel_initializer='normal', activation='softmax')(x)\n",
    "    out     = Dense(outshape,kernel_initializer='normal', activation='softmax')(x_tmp)\n",
    "    # Compile model\n",
    "    model = Model(inputs=input1, outputs = out)\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadnprec(col, max_feature=None, maxlen=None):\n",
    "    train_seq = pd.read_pickle(f\"{UDDIR}/imd/train_{col}_seq.pkl\")\n",
    "    test_seq = pd.read_pickle(f\"{UDDIR}/imd/test_{col}_seq.pkl\")\n",
    "    \n",
    "    train_X = train_seq[col].values\n",
    "    test_X = test_seq[col].values\n",
    "    \n",
    "    # Tokenize the sentences\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(train_X))\n",
    "    \n",
    "    train_X = tokenizer.texts_to_sequences(train_X)\n",
    "    test_X = tokenizer.texts_to_sequences(test_X)\n",
    "    \n",
    "    # Pad the sentences \n",
    "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "    test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "    \n",
    "    return train_X, test_X, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(col, word_index, max_features):\n",
    "    \n",
    "    EMBEDDING_FILE = (f\"{UMDIR}/vectors/glove_{col}.model\")\n",
    "    k = Glove.load(EMBEDDING_FILE)\n",
    "    \n",
    "    embeddings_index = []\n",
    "    for i in tqdm(k.dictionary.keys()):\n",
    "        embeddings_index.append((i,k.word_vectors[k.dictionary[i]]))\n",
    "\n",
    "    embeddings_index = dict(pd.DataFrame(embeddings_index).values)\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v(col, word_index, max_features):    \n",
    "    EMBEDDING_FILE = (f\"{UMDIR}/vectors/glove_{col}.model\")\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init,\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     initializer='zero',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_fname = sorted(os.listdir(UFEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = pd.read_csv(f\"{DDIR}/train_preliminary/user.csv\")\n",
    "test_user = pd.read_csv(f\"{DDIR}/test/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.DataFrame()\n",
    "test_feat = pd.DataFrame()\n",
    "train_feat[UID] = train_user[UID]\n",
    "test_feat[UID] = test_user[UID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.set_index(UID, inplace=True)\n",
    "test_feat.set_index(UID, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_IDSET = ID_SET[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  w2v_avg_creative_id.pkl\n",
      "current filename:  w2v_avg_ad_id.pkl\n",
      "current filename:  w2v_avg_product_id.pkl\n",
      "current filename:  w2v_avg_product_category.pkl\n",
      "current filename:  w2v_avg_advertiser_id.pkl\n",
      "current filename:  w2v_avg_industry.pkl\n"
     ]
    }
   ],
   "source": [
    "# word2vec\n",
    "train_ftset_w2v = dict()\n",
    "test_ftset_w2v = dict()\n",
    "for cur_id in USE_IDSET:\n",
    "    fname = f\"w2v_avg_{cur_id}.pkl\"\n",
    "    print(\"current filename: \", fname)\n",
    "    cur_df = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "    train_ftset_w2v[cur_id] = pd.merge(train_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 300)\n",
    "    test_ftset_w2v[cur_id] = pd.merge(test_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_id in USE_IDSET:\n",
    "    assert len(train_ftset_w2v[cur_id]) == len(train_feat)\n",
    "    assert len(test_ftset_w2v[cur_id]) == len(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  d2v_avg_creative_id.pkl\n",
      "current filename:  d2v_avg_ad_id.pkl\n",
      "current filename:  d2v_avg_product_id.pkl\n",
      "current filename:  d2v_avg_product_category.pkl\n",
      "current filename:  d2v_avg_advertiser_id.pkl\n",
      "current filename:  d2v_avg_industry.pkl\n"
     ]
    }
   ],
   "source": [
    "# doc2vec\n",
    "train_ftset_d2v = dict()\n",
    "test_ftset_d2v = dict()\n",
    "for cur_id in USE_IDSET:\n",
    "    fname = f\"d2v_avg_{cur_id}.pkl\"\n",
    "    print(\"current filename: \", fname)\n",
    "    cur_df = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "    train_ftset_d2v[cur_id] = pd.merge(train_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 300)\n",
    "    test_ftset_d2v[cur_id] = pd.merge(test_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_id in USE_IDSET:\n",
    "    assert len(train_ftset_d2v[cur_id]) == len(train_feat)\n",
    "    assert len(test_ftset_d2v[cur_id]) == len(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove\n",
    "train_ftset_glv = dict()\n",
    "test_ftset_glv = dict()\n",
    "for cur_id in USE_IDSET:\n",
    "    fname = f\"glove_avg_{cur_id}.pkl\"\n",
    "    print(\"current filename: \", fname)\n",
    "    cur_df = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "    train_ftset_glv[cur_id] = pd.merge(train_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 300)\n",
    "    test_ftset_glv[cur_id] = pd.merge(test_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_id in USE_IDSET:\n",
    "    assert len(train_ftset_glv[cur_id]) == len(train_feat)\n",
    "    assert len(test_ftset_glv[cur_id]) == len(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf svd\n",
    "train_ftset_svd = dict()\n",
    "test_ftset_svd = dict()\n",
    "for cur_id in USE_IDSET:\n",
    "    fname = f\"tfidf_svd_{cur_id}.pkl\"\n",
    "    print(\"current filename: \", fname)\n",
    "    cur_df = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "    train_ftset_svd[cur_id] = pd.merge(train_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 64)\n",
    "    test_ftset_svd[cur_id] = pd.merge(test_feat, cur_df, how=\"left\", on=UID).values.reshape(-1, 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_id in USE_IDSET:\n",
    "    assert len(train_ftset_svd[cur_id]) == len(train_feat)\n",
    "    assert len(test_ftset_svd[cur_id]) == len(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pemb = pd.DataFrame()\n",
    "test_pemb = pd.DataFrame()\n",
    "train_pemb[UID] = train_user[UID]\n",
    "test_pemb[UID] = test_user[UID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  meta_age_group_regeress.pkl\n",
      "current filename:  meta_gender_group_regeress.pkl\n"
     ]
    }
   ],
   "source": [
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"meta_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        gender_agg_pred = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "        train_pemb = pd.merge(train_pemb, gender_agg_pred, how=\"left\", on=UID)\n",
    "        test_pemb = pd.merge(test_pemb, gender_agg_pred, how=\"left\", on=UID)\n",
    "        gender_agg_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  tfidf_count_emb_age_all.pkl\n",
      "current filename:  tfidf_count_emb_gender_all.pkl\n"
     ]
    }
   ],
   "source": [
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"tfidf_count_emb_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        cur_tce = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "        train_pemb = pd.merge(train_pemb, cur_tce, how=\"left\", on=UID)\n",
    "        test_pemb = pd.merge(test_pemb, cur_tce, how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  test_stats_catemlb_ad_id-advertiser_id.pkl\n",
      "current filename:  test_stats_catemlb_ad_id-product_id.pkl\n",
      "current filename:  test_stats_catemlb_ad_id.pkl\n",
      "current filename:  test_stats_catemlb_advertiser_id-industry.pkl\n",
      "current filename:  test_stats_catemlb_advertiser_id.pkl\n",
      "current filename:  test_stats_catemlb_creative_id.pkl\n",
      "current filename:  test_stats_catemlb_industry.pkl\n",
      "current filename:  test_stats_catemlb_product_category-advertiser_id.pkl\n",
      "current filename:  test_stats_catemlb_product_category-industry.pkl\n",
      "current filename:  test_stats_catemlb_product_category.pkl\n",
      "current filename:  test_stats_catemlb_product_id-product_category.pkl\n",
      "current filename:  test_stats_catemlb_product_id.pkl\n",
      "current filename:  train_stats_catemlb_ad_id-advertiser_id.pkl\n",
      "current filename:  train_stats_catemlb_ad_id-product_id.pkl\n",
      "current filename:  train_stats_catemlb_ad_id.pkl\n",
      "current filename:  train_stats_catemlb_advertiser_id-industry.pkl\n",
      "current filename:  train_stats_catemlb_advertiser_id.pkl\n",
      "current filename:  train_stats_catemlb_creative_id.pkl\n",
      "current filename:  train_stats_catemlb_industry.pkl\n",
      "current filename:  train_stats_catemlb_product_category-advertiser_id.pkl\n",
      "current filename:  train_stats_catemlb_product_category-industry.pkl\n",
      "current filename:  train_stats_catemlb_product_category.pkl\n",
      "current filename:  train_stats_catemlb_product_id-product_category.pkl\n",
      "current filename:  train_stats_catemlb_product_id.pkl\n"
     ]
    }
   ],
   "source": [
    "# stats cate target encode\n",
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"train_stats_catemlb\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        train_pemb = pd.merge(train_pemb, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "    elif fname.startswith(\"test_stats_catemlb\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        test_pemb = pd.merge(test_pemb, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  test_stats_o1.pkl\n",
      "current filename:  train_stats_o1.pkl\n"
     ]
    }
   ],
   "source": [
    "# stats o1\n",
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"train_stats_o1\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        train_pemb = pd.merge(train_pemb, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "    elif fname.startswith(\"test_stats_o1\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        test_pemb = pd.merge(test_pemb, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  test_stats_o2_getidxmax_user_idCad_id.pkl\n",
      "current filename:  test_stats_o2_getidxmax_user_idCadvertiser_id.pkl\n",
      "current filename:  test_stats_o2_getidxmax_user_idCcreative_id.pkl\n",
      "current filename:  test_stats_o2_getidxmax_user_idCindustry.pkl\n",
      "current filename:  test_stats_o2_getidxmax_user_idCproduct_category.pkl\n",
      "current filename:  test_stats_o2_getidxmax_user_idCproduct_id.pkl\n",
      "current filename:  train_stats_o2_getidxmax_user_idCad_id.pkl\n",
      "current filename:  train_stats_o2_getidxmax_user_idCadvertiser_id.pkl\n",
      "current filename:  train_stats_o2_getidxmax_user_idCcreative_id.pkl\n",
      "current filename:  train_stats_o2_getidxmax_user_idCindustry.pkl\n",
      "current filename:  train_stats_o2_getidxmax_user_idCproduct_category.pkl\n",
      "current filename:  train_stats_o2_getidxmax_user_idCproduct_id.pkl\n"
     ]
    }
   ],
   "source": [
    "# stats getidxmax\n",
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"train_stats_o2_getidxmax\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        train_pemb = pd.merge(train_pemb, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "    elif fname.startswith(\"test_stats_o2_getidxmax\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        test_pemb = pd.merge(test_pemb, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pemb.set_index(UID, inplace=True)\n",
    "test_pemb.set_index(UID, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_pemb.columns == train_pemb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna and inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnaninf(val):\n",
    "    return np.mean(val[(~np.isnan(val))&(~np.isinf(val))].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillmean(df):\n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].count() < len(df):\n",
    "            df[col] = df[col].replace([np.nan, np.inf], nnaninf(df[col]))\n",
    "    # check\n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].count() < len(df):\n",
    "            log(col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [00:01<00:00, 558.87it/s]\n",
      "100%|██████████| 1017/1017 [00:01<00:00, 588.69it/s]\n",
      "100%|██████████| 1017/1017 [00:02<00:00, 426.08it/s]\n",
      "100%|██████████| 1017/1017 [00:01<00:00, 550.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_pemb = fillmean(train_pemb)\n",
    "test_pemb = fillmean(test_pemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445581.0 -7.8203125\n",
      "4789123.0 -7.1171875\n"
     ]
    }
   ],
   "source": [
    "print(train_pemb.values.max(), train_pemb.values.min())\n",
    "print(test_pemb.values.max(), test_pemb.values.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmms(tr_df, te_df):\n",
    "    tol_df = pd.concat([tr_df, te_df])\n",
    "    mms = MinMaxScaler()\n",
    "    mms_tol_df = mms.fit_transform(tol_df)\n",
    "    mms_tr_df = mms_tol_df[:len(tr_df)]\n",
    "    mms_te_df = mms_tol_df[len(tr_df):]\n",
    "    \n",
    "    return mms_tr_df, mms_te_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_tr_df, mms_te_df = transmms(train_pemb, test_pemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002 0.0\n",
      "1.0000000000000002 0.0\n"
     ]
    }
   ],
   "source": [
    "print(mms_tr_df.max(), mms_tr_df.min())\n",
    "print(mms_te_df.max(), mms_te_df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 1017)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms_tr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1017)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms_te_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 1, 300)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(900000,1,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nn k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_lstm_atten(inp, maxlen):\n",
    "    # Stage ctid\n",
    "    x = inp\n",
    "#     x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp_ctid)\n",
    "    x = Position_Embedding()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    y = Bidirectional(GRU(64, return_sequences=True))(x)\n",
    "#     z = Conv1D(64, kernel_size = 1, kernel_initializer=initializers.he_uniform(seed=2020), activation = \"tanh\")(y)\n",
    "\n",
    "    atten_1 = Attention(maxlen)(x) # skip connect\n",
    "    atten_2 = Attention(maxlen)(y)\n",
    "    avg_pool_1 = GlobalAveragePooling1D()(y)\n",
    "    max_pool_1 = GlobalMaxPooling1D()(y)\n",
    "#     max_pool1_1 = GlobalMaxPooling1D()(z)\n",
    "\n",
    "    convs = []\n",
    "    filter_sizes = [2, 3, 5, 8]\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(filters=maxlen, kernel_size=fsz, activation='relu', padding=\"same\")(y)\n",
    "        l_pool = MaxPooling1D(maxlen - fsz + 1, padding=\"same\")(l_conv)\n",
    "        l_pool = Flatten()(l_pool)\n",
    "        convs.append(l_pool)\n",
    "    text_cnn = concatenate(convs, axis=1)\n",
    "    \n",
    "    return atten_1, atten_2, avg_pool_1, max_pool_1, text_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_lstm_atten(maxlen, num_classes):\n",
    "    \n",
    "    w2v_inp = dict()\n",
    "    d2v_inp = dict()\n",
    "#     glv_inp = dict()\n",
    "#     svd_inp = dict()\n",
    "    \n",
    "    for cur_id in USE_IDSET:\n",
    "        w2v_inp[cur_id] = Input(shape=(1,300))\n",
    "        d2v_inp[cur_id] = Input(shape=(1,300))\n",
    "#         glv_inp[cur_id] = Input(shape=(1,300))\n",
    "#         svd_inp[cur_id] = Input(shape=(1,64))\n",
    "\n",
    "    w2v_nn = dict()\n",
    "    d2v_nn = dict()\n",
    "#     glv_nn = dict()\n",
    "#     svd_nn = dict()\n",
    "        \n",
    "    for cur_id in USE_IDSET:\n",
    "        w2v_nn[cur_id] = list(cp_lstm_atten(w2v_inp[cur_id], maxlen))\n",
    "        d2v_nn[cur_id] = list(cp_lstm_atten(d2v_inp[cur_id], maxlen))\n",
    "#         glv_nn[cur_id] = list(cp_lstm_atten(glv_inp[cur_id], maxlen))\n",
    "#         svd_nn[cur_id] = list(cp_lstm_atten(svd_inp[cur_id], maxlen))\n",
    "    \n",
    "    inps = list(w2v_inp.values()) + \\\n",
    "           list(d2v_inp.values())\n",
    "#            list(glv_inp.values()) + \\\n",
    "#            list(svd_inp.values())\n",
    "    \n",
    "    nnls = list(np.array(list(w2v_nn.values())).flatten()) + \\\n",
    "           list(np.array(list(d2v_nn.values())).flatten())\n",
    "#            list(np.array(list(glv_nn.values())).flatten()) + \\\n",
    "#            list(np.array(list(svd_nn.values())).flatten())\n",
    "    \n",
    "    # Stage prediction embedding\n",
    "    inp_pemb = Input(shape=(1017, ))\n",
    "    aux_1 = Dense(128)(inp_pemb)\n",
    "    aux_1 = Dense(32)(aux_1)\n",
    "#     aux_1 = BatchNormalization()(aux_1)\n",
    "\n",
    "\n",
    "    conc = concatenate(nnls+[aux_1,])\n",
    "    \n",
    "    conc = Dense(256)(conc)\n",
    "    conc = BatchNormalization()(conc)\n",
    "    conc = PReLU()(conc)\n",
    "    conc = Dropout(0.2)(conc)\n",
    "\n",
    "    conc = Dense(128)(conc)\n",
    "    conc = BatchNormalization()(conc)\n",
    "    # conc = PReLU()(conc)\n",
    "\n",
    "    if num_classes == 1:\n",
    "        outp = Dense(num_classes, activation=\"sigmoid\")(conc)\n",
    "    else:\n",
    "        outp = Dense(num_classes, activation=\"softmax\")(conc)\n",
    "\n",
    "    model = Model(inputs=inps+[inp_pemb, ], outputs=outp)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL COMPLIE...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, 1, 300)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, 1, 300)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_5 (Position (None, 1, 300)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_7 (Position (None, 1, 300)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_9 (Position (None, 1, 300)       0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_11 (Positio (None, 1, 300)       0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, 1, 300)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, 1, 300)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_6 (Position (None, 1, 300)       0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_8 (Position (None, 1, 300)       0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_10 (Positio (None, 1, 300)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_12 (Positio (None, 1, 300)       0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 300)       0           position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 300)       0           position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 300)       0           position__embedding_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 300)       0           position__embedding_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 300)       0           position__embedding_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 300)       0           position__embedding_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 300)       0           position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 300)       0           position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 300)       0           position__embedding_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 300)       0           position__embedding_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 300)       0           position__embedding_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 300)       0           position__embedding_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 128)       123264      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 128)       123264      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 128)       123264      bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 128)       123264      bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1, 128)       123264      bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1, 128)       123264      bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 128)       123264      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 128)       123264      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 128)       123264      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 128)       123264      bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1, 128)       123264      bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1, 128)       123264      bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 200)       51400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 200)       77000       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 200)       128200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 200)       205000      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1, 200)       51400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1, 200)       77000       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 200)       128200      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 200)       205000      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 200)       51400       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 200)       77000       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 200)       128200      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 200)       205000      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 200)       51400       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1, 200)       77000       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1, 200)       128200      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1, 200)       205000      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1, 200)       51400       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1, 200)       77000       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1, 200)       128200      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1, 200)       205000      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1, 200)       51400       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1, 200)       77000       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1, 200)       128200      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1, 200)       205000      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1, 200)       51400       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1, 200)       77000       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 200)       128200      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 200)       205000      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1, 200)       51400       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1, 200)       77000       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 200)       128200      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 200)       205000      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1, 200)       51400       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1, 200)       77000       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1, 200)       128200      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 200)       205000      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 200)       51400       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1, 200)       77000       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1, 200)       128200      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1, 200)       205000      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1, 200)       51400       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1, 200)       77000       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1, 200)       128200      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1, 200)       205000      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1, 200)       51400       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1, 200)       77000       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1, 200)       128200      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1, 200)       205000      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 200)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 200)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 200)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 200)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 200)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 200)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 200)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 200)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 200)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 200)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1, 200)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 1, 200)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1, 200)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1, 200)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 1, 200)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1, 200)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 1, 200)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1, 200)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1, 200)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1, 200)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1, 200)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 1, 200)       0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1, 200)       0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 1, 200)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 200)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 200)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 200)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 200)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 200)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 200)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 200)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 200)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 1, 200)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 1, 200)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 1, 200)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 1, 200)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 200)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 200)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 1, 200)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1, 200)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1, 200)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1, 200)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 1, 200)       0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 1, 200)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1, 200)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1, 200)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1, 200)       0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1, 200)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1017)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 200)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 200)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 200)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 200)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 200)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 200)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 200)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 200)          0           max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 200)          0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 200)          0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 200)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 200)          0           max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 200)          0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 200)          0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 200)          0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 200)          0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 200)          0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 200)          0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 200)          0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 200)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 200)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 200)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 200)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 200)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 200)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 200)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 200)          0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 200)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 200)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 200)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 200)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 200)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 200)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 200)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 200)          0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 200)          0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 200)          0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 200)          0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 200)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 200)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 200)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 200)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          130304      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          257         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          129         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 256)          257         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          129         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800)          0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 256)          257         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 128)          129         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 800)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 256)          257         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 128)          129         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 800)          0           flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 256)          257         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 128)          129         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 800)          0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 256)          257         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_22 (Attention)        (None, 128)          129         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          257         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          129         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 800)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 256)          257         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          129         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800)          0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 256)          257         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 128)          129         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 800)          0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 256)          257         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 128)          129         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 800)          0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 256)          257         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 128)          129         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 800)          0           flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_23 (Attention)        (None, 256)          257         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 128)          129         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17312)        0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 attention_6[0][0]                \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 attention_9[0][0]                \n",
      "                                                                 attention_10[0][0]               \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 attention_13[0][0]               \n",
      "                                                                 attention_14[0][0]               \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 attention_17[0][0]               \n",
      "                                                                 attention_18[0][0]               \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 attention_21[0][0]               \n",
      "                                                                 attention_22[0][0]               \n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 attention_8[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 attention_11[0][0]               \n",
      "                                                                 attention_12[0][0]               \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 attention_15[0][0]               \n",
      "                                                                 attention_16[0][0]               \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 attention_19[0][0]               \n",
      "                                                                 attention_20[0][0]               \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 attention_23[0][0]               \n",
      "                                                                 attention_24[0][0]               \n",
      "                                                                 global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          4432128     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 256)          256         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           1290        batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 16,897,090\n",
      "Trainable params: 16,896,322\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 180000 samples\n",
      "Epoch 1/50\n",
      "   400/720000 [..............................] - ETA: 14:33:30 - loss: 3.0285 - acc: 0.1125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.339584). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000/720000 [==============================] - 1084s 2ms/step - loss: 1.4054 - acc: 0.4316 - val_loss: 1.3618 - val_acc: 0.4460\n",
      "Epoch 2/50\n",
      "720000/720000 [==============================] - 1054s 1ms/step - loss: 1.3386 - acc: 0.4483 - val_loss: 1.3224 - val_acc: 0.4532\n",
      "Epoch 3/50\n",
      "720000/720000 [==============================] - 1052s 1ms/step - loss: 1.3260 - acc: 0.4541 - val_loss: 1.3190 - val_acc: 0.4561\n",
      "Epoch 4/50\n",
      "720000/720000 [==============================] - 1054s 1ms/step - loss: 1.3178 - acc: 0.4564 - val_loss: 1.3231 - val_acc: 0.4564\n",
      "Epoch 5/50\n",
      "720000/720000 [==============================] - 1056s 1ms/step - loss: 1.3120 - acc: 0.4583 - val_loss: 1.3109 - val_acc: 0.4574\n",
      "Epoch 6/50\n",
      "720000/720000 [==============================] - 1053s 1ms/step - loss: 1.3068 - acc: 0.4604 - val_loss: 1.3073 - val_acc: 0.4582\n",
      "Epoch 7/50\n",
      "720000/720000 [==============================] - 1039s 1ms/step - loss: 1.3032 - acc: 0.4622 - val_loss: 1.3038 - val_acc: 0.4600\n",
      "Epoch 8/50\n",
      "720000/720000 [==============================] - 1026s 1ms/step - loss: 1.2991 - acc: 0.4629 - val_loss: 1.3096 - val_acc: 0.4604\n",
      "Epoch 9/50\n",
      "720000/720000 [==============================] - 1027s 1ms/step - loss: 1.2961 - acc: 0.4645 - val_loss: 1.2970 - val_acc: 0.4634\n",
      "Epoch 10/50\n",
      "720000/720000 [==============================] - 1027s 1ms/step - loss: 1.2930 - acc: 0.4654 - val_loss: 1.2925 - val_acc: 0.4644\n",
      "Epoch 11/50\n",
      "720000/720000 [==============================] - 1026s 1ms/step - loss: 1.2909 - acc: 0.4663 - val_loss: 1.2974 - val_acc: 0.4635\n",
      "Epoch 12/50\n",
      "720000/720000 [==============================] - 1028s 1ms/step - loss: 1.2882 - acc: 0.4672 - val_loss: 1.3002 - val_acc: 0.4621\n",
      "Epoch 13/50\n",
      "720000/720000 [==============================] - 1027s 1ms/step - loss: 1.2861 - acc: 0.4678 - val_loss: 1.2917 - val_acc: 0.4662\n",
      "Epoch 14/50\n",
      "720000/720000 [==============================] - 1024s 1ms/step - loss: 1.2835 - acc: 0.4690 - val_loss: 1.2949 - val_acc: 0.4645\n",
      "Epoch 15/50\n",
      "720000/720000 [==============================] - 1026s 1ms/step - loss: 1.2814 - acc: 0.4698 - val_loss: 1.2924 - val_acc: 0.4649\n",
      "Epoch 16/50\n",
      "720000/720000 [==============================] - 1029s 1ms/step - loss: 1.2796 - acc: 0.4705 - val_loss: 1.2945 - val_acc: 0.4646\n",
      "180000/180000 [==============================] - 62s 343us/step\n",
      "1000000/1000000 [==============================] - 315s 315us/step\n",
      "MODEL COMPLIE...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, 1, 300)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, 1, 300)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_5 (Position (None, 1, 300)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_7 (Position (None, 1, 300)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_9 (Position (None, 1, 300)       0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_11 (Positio (None, 1, 300)       0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, 1, 300)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, 1, 300)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_6 (Position (None, 1, 300)       0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_8 (Position (None, 1, 300)       0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_10 (Positio (None, 1, 300)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_12 (Positio (None, 1, 300)       0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 300)       0           position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 300)       0           position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 300)       0           position__embedding_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 300)       0           position__embedding_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 300)       0           position__embedding_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 300)       0           position__embedding_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 300)       0           position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 300)       0           position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 300)       0           position__embedding_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 300)       0           position__embedding_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 300)       0           position__embedding_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 300)       0           position__embedding_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 128)       123264      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 128)       123264      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 128)       123264      bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 128)       123264      bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1, 128)       123264      bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1, 128)       123264      bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 128)       123264      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 128)       123264      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 128)       123264      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 128)       123264      bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1, 128)       123264      bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1, 128)       123264      bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 200)       51400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 200)       77000       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 200)       128200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 200)       205000      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1, 200)       51400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1, 200)       77000       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 200)       128200      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 200)       205000      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 200)       51400       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 200)       77000       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 200)       128200      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 200)       205000      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 200)       51400       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1, 200)       77000       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1, 200)       128200      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1, 200)       205000      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1, 200)       51400       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1, 200)       77000       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1, 200)       128200      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1, 200)       205000      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1, 200)       51400       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1, 200)       77000       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1, 200)       128200      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1, 200)       205000      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1, 200)       51400       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1, 200)       77000       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 200)       128200      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 200)       205000      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1, 200)       51400       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1, 200)       77000       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 200)       128200      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 200)       205000      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1, 200)       51400       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1, 200)       77000       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1, 200)       128200      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 200)       205000      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 200)       51400       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1, 200)       77000       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1, 200)       128200      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1, 200)       205000      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1, 200)       51400       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1, 200)       77000       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1, 200)       128200      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1, 200)       205000      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1, 200)       51400       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1, 200)       77000       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1, 200)       128200      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1, 200)       205000      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 200)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 200)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 200)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 200)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 200)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 200)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 200)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 200)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 200)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 200)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1, 200)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 1, 200)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1, 200)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1, 200)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 1, 200)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1, 200)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 1, 200)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1, 200)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1, 200)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1, 200)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1, 200)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 1, 200)       0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1, 200)       0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 1, 200)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 200)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 200)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 200)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 200)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 200)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 200)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 200)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 200)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 1, 200)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 1, 200)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 1, 200)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 1, 200)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 200)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 200)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 1, 200)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1, 200)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1, 200)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1, 200)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 1, 200)       0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 1, 200)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1, 200)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1, 200)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1, 200)       0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1, 200)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1017)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 200)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 200)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 200)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 200)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 200)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 200)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 200)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 200)          0           max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 200)          0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 200)          0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 200)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 200)          0           max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 200)          0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 200)          0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 200)          0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 200)          0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 200)          0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 200)          0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 200)          0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 200)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 200)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 200)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 200)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 200)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 200)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 200)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 200)          0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 200)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 200)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 200)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 200)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 200)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 200)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 200)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 200)          0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 200)          0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 200)          0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 200)          0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 200)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 200)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 200)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 200)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          130304      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          257         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          129         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 256)          257         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          129         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800)          0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 256)          257         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 128)          129         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 800)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 256)          257         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 128)          129         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 800)          0           flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 256)          257         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 128)          129         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 800)          0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 256)          257         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_22 (Attention)        (None, 128)          129         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          257         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          129         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 800)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 256)          257         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          129         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800)          0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 256)          257         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 128)          129         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 800)          0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 256)          257         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 128)          129         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 800)          0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 256)          257         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 128)          129         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 800)          0           flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_23 (Attention)        (None, 256)          257         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 128)          129         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17312)        0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 attention_6[0][0]                \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 attention_9[0][0]                \n",
      "                                                                 attention_10[0][0]               \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 attention_13[0][0]               \n",
      "                                                                 attention_14[0][0]               \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 attention_17[0][0]               \n",
      "                                                                 attention_18[0][0]               \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 attention_21[0][0]               \n",
      "                                                                 attention_22[0][0]               \n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 attention_8[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 attention_11[0][0]               \n",
      "                                                                 attention_12[0][0]               \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 attention_15[0][0]               \n",
      "                                                                 attention_16[0][0]               \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 attention_19[0][0]               \n",
      "                                                                 attention_20[0][0]               \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 attention_23[0][0]               \n",
      "                                                                 attention_24[0][0]               \n",
      "                                                                 global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          4432128     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 256)          256         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           1290        batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 16,897,090\n",
      "Trainable params: 16,896,322\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 180000 samples\n",
      "Epoch 1/50\n",
      "   400/720000 [..............................] - ETA: 14:32:57 - loss: 2.9092 - acc: 0.1100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.322055). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000/720000 [==============================] - 1074s 1ms/step - loss: 1.4122 - acc: 0.4301 - val_loss: 1.3479 - val_acc: 0.4459\n",
      "Epoch 2/50\n",
      "720000/720000 [==============================] - 1032s 1ms/step - loss: 1.3383 - acc: 0.4491 - val_loss: 1.3259 - val_acc: 0.4535\n",
      "Epoch 3/50\n",
      "644600/720000 [=========================>....] - ETA: 1:41 - loss: 1.3255 - acc: 0.4529"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-5492cb276f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mpred_val_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 184\u001b[0;31m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATA_SPLIT_SEED = 2020\n",
    "cb = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "      CyclicLR(base_lr=0.001, max_lr=0.002,\n",
    "               step_size=300., mode='exp_range',\n",
    "               gamma=0.99994)]\n",
    "maxlen=200\n",
    "# for age\n",
    "num_classes = 10\n",
    "train_y = np_utils.to_categorical(train_user[\"age\"]-1)\n",
    "\n",
    "\n",
    "train_set = list(train_ftset_w2v.values()) + \\\n",
    "            list(train_ftset_d2v.values()) + [mms_tr_df, ]\n",
    "#             list(train_ftset_glv.values()) + \\\n",
    "#             list(train_ftset_svd.values()) + \n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "test_set = list(test_ftset_w2v.values()) + \\\n",
    "           list(test_ftset_d2v.values()) + [mms_te_df, ]\n",
    "#            list(test_ftset_glv.values()) + \\\n",
    "#            list(test_ftset_svd.values()) + \n",
    "\n",
    "predicted_train_age = np.zeros(train_y.shape)\n",
    "predicted_age = np.zeros((len(test_user),num_classes))\n",
    "splits = list(KFold(n_splits=5, shuffle=True, random_state=DATA_SPLIT_SEED).split(train_set[0], train_y))\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(splits):\n",
    "    K.clear_session()\n",
    "\n",
    "    X_train_set = list()\n",
    "    X_val_set = list()\n",
    "\n",
    "    for cur_train in train_set:\n",
    "        X_train_set.append(cur_train[train_idx])\n",
    "        X_val_set.append(cur_train[valid_idx])\n",
    "\n",
    "    y_train = train_y[train_idx]\n",
    "    y_val = train_y[valid_idx]\n",
    "\n",
    "\n",
    "    model = sim_lstm_atten(maxlen, num_classes)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RAdam(lr=0.001), metrics=['acc'])\n",
    "    print(\"MODEL COMPLIE...\")\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(X_train_set, y_train, batch_size=200, epochs=50, validation_data=(X_val_set, y_val), callbacks=cb, verbose=1)\n",
    "    pred_val_y = model.predict(X_val_set, batch_size=200, verbose=1)\n",
    "    pred_test_y = model.predict(test_set, batch_size=200, verbose=1)\n",
    "    predicted_train_age[valid_idx] = pred_val_y\n",
    "    predicted_age += pred_test_y / len(splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12427111111111111"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(train_y,axis=1),np.argmax(predicted_train_age,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     278243\n",
       "4     179808\n",
       "2     172987\n",
       "5     145293\n",
       "6      97462\n",
       "7      48419\n",
       "9      25342\n",
       "1      24323\n",
       "10     14655\n",
       "8      13468\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.argmax(predicted_age, axis=1)+1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46462777777777775\n",
      "0.038933333333333334\n",
      "0.03905\n",
      "0.03961666666666667\n",
      "0.039127777777777775\n"
     ]
    }
   ],
   "source": [
    "for idx, (train_idx, valid_idx) in enumerate(splits):\n",
    "    print(accuracy_score(np.argmax(train_y[valid_idx],axis=1),np.argmax(predicted_train_age[valid_idx],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.4562333333333333+0.45637222222222223+0.4559666666666667)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.46275 - 0.45755555555555555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.46275 - 0.4561907407407408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = (train_user[\"gender\"]-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "MODEL COMPLIE...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, 1, 300)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, 1, 300)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_5 (Position (None, 1, 300)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_7 (Position (None, 1, 300)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_9 (Position (None, 1, 300)       0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_11 (Positio (None, 1, 300)       0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, 1, 300)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, 1, 300)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_6 (Position (None, 1, 300)       0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_8 (Position (None, 1, 300)       0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_10 (Positio (None, 1, 300)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_12 (Positio (None, 1, 300)       0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 300)       0           position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 300)       0           position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 300)       0           position__embedding_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 300)       0           position__embedding_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 300)       0           position__embedding_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 300)       0           position__embedding_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 300)       0           position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 300)       0           position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 300)       0           position__embedding_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 300)       0           position__embedding_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 300)       0           position__embedding_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 300)       0           position__embedding_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 128)       123264      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 128)       123264      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 128)       123264      bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 128)       123264      bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1, 128)       123264      bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1, 128)       123264      bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 128)       123264      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 128)       123264      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 128)       123264      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 128)       123264      bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1, 128)       123264      bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1, 128)       123264      bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 200)       51400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 200)       77000       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 200)       128200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 200)       205000      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1, 200)       51400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1, 200)       77000       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 200)       128200      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 200)       205000      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 200)       51400       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 200)       77000       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 200)       128200      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 200)       205000      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 200)       51400       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1, 200)       77000       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1, 200)       128200      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1, 200)       205000      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1, 200)       51400       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1, 200)       77000       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1, 200)       128200      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1, 200)       205000      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1, 200)       51400       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1, 200)       77000       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1, 200)       128200      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1, 200)       205000      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1, 200)       51400       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1, 200)       77000       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 200)       128200      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 200)       205000      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1, 200)       51400       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1, 200)       77000       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 200)       128200      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 200)       205000      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1, 200)       51400       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1, 200)       77000       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1, 200)       128200      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 200)       205000      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 200)       51400       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1, 200)       77000       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1, 200)       128200      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1, 200)       205000      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1, 200)       51400       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1, 200)       77000       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1, 200)       128200      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1, 200)       205000      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1, 200)       51400       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1, 200)       77000       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1, 200)       128200      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1, 200)       205000      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 200)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 200)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 200)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 200)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 200)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 200)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 200)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 200)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 200)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 200)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1, 200)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 1, 200)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1, 200)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1, 200)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 1, 200)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1, 200)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 1, 200)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1, 200)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1, 200)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1, 200)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1, 200)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 1, 200)       0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1, 200)       0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 1, 200)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 200)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 200)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 200)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 200)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 200)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 200)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 200)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 200)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 1, 200)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 1, 200)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 1, 200)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 1, 200)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 200)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 200)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 1, 200)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1, 200)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1, 200)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1, 200)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 1, 200)       0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 1, 200)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1, 200)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1, 200)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1, 200)       0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1, 200)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1017)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 200)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 200)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 200)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 200)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 200)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 200)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 200)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 200)          0           max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 200)          0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 200)          0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 200)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 200)          0           max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 200)          0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 200)          0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 200)          0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 200)          0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 200)          0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 200)          0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 200)          0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 200)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 200)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 200)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 200)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 200)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 200)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 200)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 200)          0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 200)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 200)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 200)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 200)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 200)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 200)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 200)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 200)          0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 200)          0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 200)          0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 200)          0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 200)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 200)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 200)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 200)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          130304      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          257         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          129         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 256)          257         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          129         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800)          0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 256)          257         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 128)          129         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 800)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 256)          257         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 128)          129         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 800)          0           flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 256)          257         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 128)          129         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 800)          0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 256)          257         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_22 (Attention)        (None, 128)          129         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          257         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          129         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 800)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 256)          257         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          129         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800)          0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 256)          257         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 128)          129         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 800)          0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 256)          257         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 128)          129         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 800)          0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 256)          257         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 128)          129         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 800)          0           flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_23 (Attention)        (None, 256)          257         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 128)          129         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17312)        0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 attention_6[0][0]                \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 attention_9[0][0]                \n",
      "                                                                 attention_10[0][0]               \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 attention_13[0][0]               \n",
      "                                                                 attention_14[0][0]               \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 attention_17[0][0]               \n",
      "                                                                 attention_18[0][0]               \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 attention_21[0][0]               \n",
      "                                                                 attention_22[0][0]               \n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 attention_8[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 attention_11[0][0]               \n",
      "                                                                 attention_12[0][0]               \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 attention_15[0][0]               \n",
      "                                                                 attention_16[0][0]               \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 attention_19[0][0]               \n",
      "                                                                 attention_20[0][0]               \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 attention_23[0][0]               \n",
      "                                                                 attention_24[0][0]               \n",
      "                                                                 global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          4432128     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 256)          256         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 16,895,929\n",
      "Trainable params: 16,895,161\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 720000 samples, validate on 180000 samples\n",
      "Epoch 1/50\n",
      "720000/720000 [==============================] - 1125s 2ms/step - loss: 0.1926 - acc: 0.9306 - val_loss: 0.1748 - val_acc: 0.9361\n",
      "Epoch 2/50\n",
      "720000/720000 [==============================] - 1060s 1ms/step - loss: 0.1800 - acc: 0.9354 - val_loss: 0.1706 - val_acc: 0.9388\n",
      "Epoch 3/50\n",
      "720000/720000 [==============================] - 1058s 1ms/step - loss: 0.1759 - acc: 0.9368 - val_loss: 0.1690 - val_acc: 0.9393\n",
      "Epoch 4/50\n",
      "720000/720000 [==============================] - 1067s 1ms/step - loss: 0.1734 - acc: 0.9380 - val_loss: 0.1743 - val_acc: 0.9372\n",
      "Epoch 5/50\n",
      "720000/720000 [==============================] - 1054s 1ms/step - loss: 0.1723 - acc: 0.9382 - val_loss: 0.1750 - val_acc: 0.9376\n",
      "Epoch 6/50\n",
      "720000/720000 [==============================] - 1057s 1ms/step - loss: 0.1710 - acc: 0.9389 - val_loss: 0.1673 - val_acc: 0.9401\n",
      "Epoch 7/50\n",
      "720000/720000 [==============================] - 1055s 1ms/step - loss: 0.1699 - acc: 0.9391 - val_loss: 0.1668 - val_acc: 0.9402\n",
      "Epoch 8/50\n",
      "720000/720000 [==============================] - 1043s 1ms/step - loss: 0.1692 - acc: 0.9394 - val_loss: 0.1693 - val_acc: 0.9396\n",
      "Epoch 9/50\n",
      "720000/720000 [==============================] - 1043s 1ms/step - loss: 0.1681 - acc: 0.9397 - val_loss: 0.1653 - val_acc: 0.9408\n",
      "Epoch 10/50\n",
      "720000/720000 [==============================] - 1037s 1ms/step - loss: 0.1676 - acc: 0.9400 - val_loss: 0.1647 - val_acc: 0.9412\n",
      "Epoch 11/50\n",
      "720000/720000 [==============================] - 1036s 1ms/step - loss: 0.1667 - acc: 0.9404 - val_loss: 0.1673 - val_acc: 0.9405\n",
      "Epoch 12/50\n",
      "720000/720000 [==============================] - 1029s 1ms/step - loss: 0.1661 - acc: 0.9406 - val_loss: 0.1657 - val_acc: 0.9409\n",
      "Epoch 13/50\n",
      "720000/720000 [==============================] - 1031s 1ms/step - loss: 0.1653 - acc: 0.9410 - val_loss: 0.1650 - val_acc: 0.9410\n",
      "180000/180000 [==============================] - 58s 321us/step\n",
      "1000000/1000000 [==============================] - 291s 291us/step\n",
      "MODEL COMPLIE...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, 1, 300)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, 1, 300)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_5 (Position (None, 1, 300)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_7 (Position (None, 1, 300)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_9 (Position (None, 1, 300)       0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_11 (Positio (None, 1, 300)       0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, 1, 300)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, 1, 300)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_6 (Position (None, 1, 300)       0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_8 (Position (None, 1, 300)       0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_10 (Positio (None, 1, 300)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_12 (Positio (None, 1, 300)       0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 300)       0           position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 300)       0           position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 300)       0           position__embedding_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 300)       0           position__embedding_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 300)       0           position__embedding_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 300)       0           position__embedding_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 300)       0           position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 300)       0           position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 300)       0           position__embedding_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 300)       0           position__embedding_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 300)       0           position__embedding_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 300)       0           position__embedding_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 128)       123264      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 128)       123264      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 128)       123264      bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 128)       123264      bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1, 128)       123264      bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1, 128)       123264      bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 128)       123264      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 128)       123264      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 128)       123264      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 128)       123264      bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1, 128)       123264      bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1, 128)       123264      bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 200)       51400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 200)       77000       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 200)       128200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 200)       205000      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1, 200)       51400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1, 200)       77000       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 200)       128200      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 200)       205000      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 200)       51400       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 200)       77000       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 200)       128200      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 200)       205000      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 200)       51400       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1, 200)       77000       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1, 200)       128200      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1, 200)       205000      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1, 200)       51400       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1, 200)       77000       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1, 200)       128200      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1, 200)       205000      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1, 200)       51400       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1, 200)       77000       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1, 200)       128200      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1, 200)       205000      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1, 200)       51400       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1, 200)       77000       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 200)       128200      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 200)       205000      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1, 200)       51400       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1, 200)       77000       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 200)       128200      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 200)       205000      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1, 200)       51400       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1, 200)       77000       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1, 200)       128200      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 200)       205000      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 200)       51400       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1, 200)       77000       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1, 200)       128200      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1, 200)       205000      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1, 200)       51400       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1, 200)       77000       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1, 200)       128200      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1, 200)       205000      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1, 200)       51400       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1, 200)       77000       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1, 200)       128200      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1, 200)       205000      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 200)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 200)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 200)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 200)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 200)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 200)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 200)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 200)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 200)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 200)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1, 200)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 1, 200)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1, 200)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1, 200)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 1, 200)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1, 200)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 1, 200)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1, 200)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1, 200)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1, 200)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1, 200)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 1, 200)       0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1, 200)       0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 1, 200)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 200)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 200)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 200)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 200)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 200)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 200)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 200)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 200)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 1, 200)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 1, 200)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 1, 200)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 1, 200)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 200)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 200)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 1, 200)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1, 200)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1, 200)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1, 200)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 1, 200)       0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 1, 200)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1, 200)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1, 200)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1, 200)       0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1, 200)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1017)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 200)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 200)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 200)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 200)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 200)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 200)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 200)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 200)          0           max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 200)          0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 200)          0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 200)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 200)          0           max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 200)          0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 200)          0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 200)          0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 200)          0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 200)          0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 200)          0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 200)          0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 200)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 200)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 200)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 200)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 200)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 200)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 200)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 200)          0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 200)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 200)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 200)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 200)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 200)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 200)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 200)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 200)          0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 200)          0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 200)          0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 200)          0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 200)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 200)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 200)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 200)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          130304      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          257         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          129         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 256)          257         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          129         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800)          0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 256)          257         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 128)          129         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 800)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 256)          257         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 128)          129         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 800)          0           flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 256)          257         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 128)          129         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 800)          0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 256)          257         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_22 (Attention)        (None, 128)          129         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          257         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          129         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 800)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 256)          257         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          129         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800)          0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 256)          257         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 128)          129         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 800)          0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 256)          257         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 128)          129         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 800)          0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 256)          257         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 128)          129         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 800)          0           flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_23 (Attention)        (None, 256)          257         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 128)          129         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17312)        0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 attention_6[0][0]                \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 attention_9[0][0]                \n",
      "                                                                 attention_10[0][0]               \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 attention_13[0][0]               \n",
      "                                                                 attention_14[0][0]               \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 attention_17[0][0]               \n",
      "                                                                 attention_18[0][0]               \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 attention_21[0][0]               \n",
      "                                                                 attention_22[0][0]               \n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 attention_8[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 attention_11[0][0]               \n",
      "                                                                 attention_12[0][0]               \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 attention_15[0][0]               \n",
      "                                                                 attention_16[0][0]               \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 attention_19[0][0]               \n",
      "                                                                 attention_20[0][0]               \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 attention_23[0][0]               \n",
      "                                                                 attention_24[0][0]               \n",
      "                                                                 global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          4432128     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 256)          256         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 16,895,929\n",
      "Trainable params: 16,895,161\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 180000 samples\n",
      "Epoch 1/50\n",
      "   400/720000 [..............................] - ETA: 14:20:16 - loss: 1.0176 - acc: 0.4800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.319677). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000/720000 [==============================] - 1100s 2ms/step - loss: 0.1932 - acc: 0.9305 - val_loss: 0.1770 - val_acc: 0.9362\n",
      "Epoch 2/50\n",
      "720000/720000 [==============================] - 1048s 1ms/step - loss: 0.1788 - acc: 0.9355 - val_loss: 0.1713 - val_acc: 0.9383\n",
      "Epoch 3/50\n",
      "720000/720000 [==============================] - 1042s 1ms/step - loss: 0.1755 - acc: 0.9370 - val_loss: 0.1751 - val_acc: 0.9382\n",
      "Epoch 4/50\n",
      "720000/720000 [==============================] - 1046s 1ms/step - loss: 0.1734 - acc: 0.9376 - val_loss: 0.1800 - val_acc: 0.9345\n",
      "Epoch 5/50\n",
      "720000/720000 [==============================] - 1033s 1ms/step - loss: 0.1720 - acc: 0.9384 - val_loss: 0.1787 - val_acc: 0.9359\n",
      "180000/180000 [==============================] - 60s 334us/step\n",
      "1000000/1000000 [==============================] - 306s 306us/step\n",
      "MODEL COMPLIE...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, 1, 300)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, 1, 300)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_5 (Position (None, 1, 300)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_7 (Position (None, 1, 300)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_9 (Position (None, 1, 300)       0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_11 (Positio (None, 1, 300)       0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, 1, 300)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, 1, 300)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_6 (Position (None, 1, 300)       0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_8 (Position (None, 1, 300)       0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_10 (Positio (None, 1, 300)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_12 (Positio (None, 1, 300)       0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 300)       0           position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 300)       0           position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 300)       0           position__embedding_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 300)       0           position__embedding_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 300)       0           position__embedding_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 300)       0           position__embedding_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 300)       0           position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 300)       0           position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 300)       0           position__embedding_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 300)       0           position__embedding_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 300)       0           position__embedding_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 300)       0           position__embedding_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 128)       123264      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 128)       123264      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 128)       123264      bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 128)       123264      bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1, 128)       123264      bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1, 128)       123264      bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 128)       123264      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 128)       123264      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 128)       123264      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 128)       123264      bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1, 128)       123264      bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1, 128)       123264      bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 200)       51400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 200)       77000       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 200)       128200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 200)       205000      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1, 200)       51400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1, 200)       77000       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 200)       128200      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 200)       205000      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 200)       51400       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 200)       77000       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 200)       128200      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 200)       205000      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 200)       51400       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1, 200)       77000       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1, 200)       128200      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1, 200)       205000      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1, 200)       51400       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1, 200)       77000       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1, 200)       128200      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1, 200)       205000      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1, 200)       51400       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1, 200)       77000       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1, 200)       128200      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1, 200)       205000      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1, 200)       51400       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1, 200)       77000       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 200)       128200      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 200)       205000      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1, 200)       51400       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1, 200)       77000       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 200)       128200      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 200)       205000      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1, 200)       51400       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1, 200)       77000       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1, 200)       128200      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 200)       205000      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 200)       51400       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1, 200)       77000       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1, 200)       128200      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1, 200)       205000      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1, 200)       51400       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1, 200)       77000       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1, 200)       128200      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1, 200)       205000      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1, 200)       51400       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1, 200)       77000       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1, 200)       128200      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1, 200)       205000      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 200)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 200)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 200)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 200)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 200)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 200)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 200)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 200)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 200)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 200)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1, 200)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 1, 200)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1, 200)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1, 200)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 1, 200)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1, 200)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 1, 200)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1, 200)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1, 200)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1, 200)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1, 200)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 1, 200)       0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1, 200)       0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 1, 200)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 200)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 200)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 200)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 200)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 200)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 200)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 200)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 200)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 1, 200)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 1, 200)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 1, 200)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 1, 200)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 200)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 200)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 1, 200)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1, 200)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1, 200)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1, 200)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 1, 200)       0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 1, 200)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1, 200)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1, 200)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1, 200)       0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1, 200)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1017)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 200)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 200)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 200)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 200)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 200)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 200)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 200)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 200)          0           max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 200)          0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 200)          0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 200)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 200)          0           max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 200)          0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 200)          0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 200)          0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 200)          0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 200)          0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 200)          0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 200)          0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 200)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 200)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 200)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 200)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 200)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 200)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 200)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 200)          0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 200)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 200)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 200)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 200)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 200)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 200)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 200)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 200)          0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 200)          0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 200)          0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 200)          0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 200)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 200)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 200)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 200)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          130304      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          257         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          129         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 256)          257         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          129         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800)          0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 256)          257         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 128)          129         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 800)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 256)          257         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 128)          129         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 800)          0           flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 256)          257         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 128)          129         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 800)          0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 256)          257         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_22 (Attention)        (None, 128)          129         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          257         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          129         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 800)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 256)          257         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          129         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800)          0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 256)          257         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 128)          129         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 800)          0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 256)          257         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 128)          129         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 800)          0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 256)          257         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 128)          129         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 800)          0           flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_23 (Attention)        (None, 256)          257         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 128)          129         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17312)        0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 attention_6[0][0]                \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 attention_9[0][0]                \n",
      "                                                                 attention_10[0][0]               \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 attention_13[0][0]               \n",
      "                                                                 attention_14[0][0]               \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 attention_17[0][0]               \n",
      "                                                                 attention_18[0][0]               \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 attention_21[0][0]               \n",
      "                                                                 attention_22[0][0]               \n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 attention_8[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 attention_11[0][0]               \n",
      "                                                                 attention_12[0][0]               \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 attention_15[0][0]               \n",
      "                                                                 attention_16[0][0]               \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 attention_19[0][0]               \n",
      "                                                                 attention_20[0][0]               \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 attention_23[0][0]               \n",
      "                                                                 attention_24[0][0]               \n",
      "                                                                 global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          4432128     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 256)          256         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 16,895,929\n",
      "Trainable params: 16,895,161\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 180000 samples\n",
      "Epoch 1/50\n",
      "   400/720000 [..............................] - ETA: 14:17:15 - loss: 1.0312 - acc: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.325835). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000/720000 [==============================] - 1080s 2ms/step - loss: 0.1927 - acc: 0.9305 - val_loss: 0.1770 - val_acc: 0.9357\n",
      "Epoch 2/50\n",
      "720000/720000 [==============================] - 1041s 1ms/step - loss: 0.1786 - acc: 0.9358 - val_loss: 0.1738 - val_acc: 0.9369\n",
      "Epoch 3/50\n",
      "720000/720000 [==============================] - 1045s 1ms/step - loss: 0.1753 - acc: 0.9373 - val_loss: 0.1727 - val_acc: 0.9380\n",
      "Epoch 4/50\n",
      "720000/720000 [==============================] - 1049s 1ms/step - loss: 0.1732 - acc: 0.9380 - val_loss: 0.1726 - val_acc: 0.9371\n",
      "Epoch 5/50\n",
      "720000/720000 [==============================] - 1045s 1ms/step - loss: 0.1716 - acc: 0.9385 - val_loss: 0.1716 - val_acc: 0.9379\n",
      "Epoch 6/50\n",
      "720000/720000 [==============================] - 1037s 1ms/step - loss: 0.1704 - acc: 0.9390 - val_loss: 0.1767 - val_acc: 0.9381\n",
      "Epoch 7/50\n",
      "720000/720000 [==============================] - 1029s 1ms/step - loss: 0.1696 - acc: 0.9394 - val_loss: 0.1710 - val_acc: 0.9385\n",
      "Epoch 8/50\n",
      "720000/720000 [==============================] - 1027s 1ms/step - loss: 0.1685 - acc: 0.9398 - val_loss: 0.1714 - val_acc: 0.9391\n",
      "Epoch 9/50\n",
      "720000/720000 [==============================] - 1033s 1ms/step - loss: 0.1680 - acc: 0.9399 - val_loss: 0.1739 - val_acc: 0.9386\n",
      "Epoch 10/50\n",
      "720000/720000 [==============================] - 1032s 1ms/step - loss: 0.1671 - acc: 0.9403 - val_loss: 0.1797 - val_acc: 0.9348\n",
      "180000/180000 [==============================] - 64s 356us/step\n",
      "1000000/1000000 [==============================] - 330s 330us/step\n",
      "MODEL COMPLIE...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, 1, 300)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, 1, 300)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_5 (Position (None, 1, 300)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_7 (Position (None, 1, 300)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_9 (Position (None, 1, 300)       0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_11 (Positio (None, 1, 300)       0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, 1, 300)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, 1, 300)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_6 (Position (None, 1, 300)       0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_8 (Position (None, 1, 300)       0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_10 (Positio (None, 1, 300)       0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_12 (Positio (None, 1, 300)       0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 300)       0           position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 300)       0           position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 300)       0           position__embedding_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 300)       0           position__embedding_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 300)       0           position__embedding_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 300)       0           position__embedding_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 300)       0           position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 300)       0           position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 300)       0           position__embedding_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 300)       0           position__embedding_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 300)       0           position__embedding_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 300)       0           position__embedding_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 256)       439296      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1, 256)       439296      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 128)       123264      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 128)       123264      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 128)       123264      bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 128)       123264      bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1, 128)       123264      bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1, 128)       123264      bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 128)       123264      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 128)       123264      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 128)       123264      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 128)       123264      bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1, 128)       123264      bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1, 128)       123264      bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 200)       51400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 200)       77000       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 200)       128200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 200)       205000      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1, 200)       51400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1, 200)       77000       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 200)       128200      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 200)       205000      bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 200)       51400       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 200)       77000       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 200)       128200      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 200)       205000      bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 200)       51400       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1, 200)       77000       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1, 200)       128200      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1, 200)       205000      bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1, 200)       51400       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1, 200)       77000       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1, 200)       128200      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1, 200)       205000      bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1, 200)       51400       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1, 200)       77000       bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1, 200)       128200      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 1, 200)       205000      bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1, 200)       51400       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1, 200)       77000       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 200)       128200      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 200)       205000      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1, 200)       51400       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1, 200)       77000       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 200)       128200      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 200)       205000      bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1, 200)       51400       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1, 200)       77000       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1, 200)       128200      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 200)       205000      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 200)       51400       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1, 200)       77000       bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1, 200)       128200      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1, 200)       205000      bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1, 200)       51400       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1, 200)       77000       bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1, 200)       128200      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1, 200)       205000      bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1, 200)       51400       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1, 200)       77000       bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1, 200)       128200      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1, 200)       205000      bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 200)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 200)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 200)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 200)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 200)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 200)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 200)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 200)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 200)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 200)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1, 200)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 1, 200)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1, 200)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1, 200)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 1, 200)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1, 200)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 1, 200)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1, 200)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1, 200)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1, 200)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1, 200)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 1, 200)       0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 1, 200)       0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 1, 200)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 200)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 200)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 200)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 200)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 200)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 200)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 200)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 200)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 1, 200)       0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 1, 200)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 1, 200)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 1, 200)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 200)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 200)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 1, 200)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1, 200)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1, 200)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 1, 200)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 1, 200)       0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 1, 200)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1, 200)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1, 200)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1, 200)       0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1, 200)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1017)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 200)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 200)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 200)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 200)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 200)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 200)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 200)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 200)          0           max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 200)          0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 200)          0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 200)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 200)          0           max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 200)          0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 200)          0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 200)          0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 200)          0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 200)          0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 200)          0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 200)          0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 200)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 200)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 200)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 200)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 200)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 200)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 200)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 200)          0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 200)          0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 200)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 200)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 200)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 200)          0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 200)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 200)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 200)          0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 200)          0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 200)          0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 200)          0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 200)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 200)          0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 200)          0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 200)          0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          130304      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          257         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          129         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 256)          257         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          129         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800)          0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 256)          257         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 128)          129         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 800)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 256)          257         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 128)          129         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 800)          0           flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 256)          257         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 128)          129         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 800)          0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 256)          257         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_22 (Attention)        (None, 128)          129         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          257         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          129         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 800)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 256)          257         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          129         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800)          0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 256)          257         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 128)          129         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 800)          0           flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 256)          257         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 128)          129         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 800)          0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 256)          257         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 128)          129         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 128)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 800)          0           flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_23 (Attention)        (None, 256)          257         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 128)          129         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17312)        0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 attention_6[0][0]                \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 attention_9[0][0]                \n",
      "                                                                 attention_10[0][0]               \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 attention_13[0][0]               \n",
      "                                                                 attention_14[0][0]               \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 attention_17[0][0]               \n",
      "                                                                 attention_18[0][0]               \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 attention_21[0][0]               \n",
      "                                                                 attention_22[0][0]               \n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 attention_8[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 attention_11[0][0]               \n",
      "                                                                 attention_12[0][0]               \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 attention_15[0][0]               \n",
      "                                                                 attention_16[0][0]               \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 attention_19[0][0]               \n",
      "                                                                 attention_20[0][0]               \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 attention_23[0][0]               \n",
      "                                                                 attention_24[0][0]               \n",
      "                                                                 global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          4432128     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 256)          256         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 16,895,929\n",
      "Trainable params: 16,895,161\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 180000 samples\n",
      "Epoch 1/50\n",
      "   400/720000 [..............................] - ETA: 14:34:46 - loss: 0.8784 - acc: 0.5025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.332503). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413600/720000 [================>.............] - ETA: 7:27 - loss: 0.1999 - acc: 0.9282"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ea60d3ac275c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mpred_val_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATA_SPLIT_SEED = 2020\n",
    "cb = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "      CyclicLR(base_lr=0.001, max_lr=0.002,\n",
    "               step_size=300., mode='exp_range',\n",
    "               gamma=0.99994)]\n",
    "\n",
    "maxlen=200\n",
    "# for gender\n",
    "num_classes = 1\n",
    "# train_y = np_utils.to_categorical(train_user[\"gender\"]-1)\n",
    "train_y = (train_user[\"gender\"]-1).values.reshape(-1, 1)\n",
    "\n",
    "train_set = list(train_ftset_w2v.values()) + \\\n",
    "            list(train_ftset_d2v.values()) + [mms_tr_df, ]\n",
    "#             list(train_ftset_glv.values()) + \\\n",
    "#             list(train_ftset_svd.values()) + \n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "test_set = list(test_ftset_w2v.values()) + \\\n",
    "           list(test_ftset_d2v.values()) + [mms_te_df, ]\n",
    "#            list(test_ftset_glv.values()) + \\\n",
    "#            list(test_ftset_svd.values()) + \n",
    "\n",
    "\n",
    "predicted_train_gender = np.zeros(train_y.shape)\n",
    "predicted_gender = np.zeros((len(test_user),num_classes))\n",
    "splits = list(KFold(n_splits=5, shuffle=True, random_state=DATA_SPLIT_SEED).split(train_set[0], train_y))\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(splits):\n",
    "    K.clear_session()\n",
    "\n",
    "    X_train_set = list()\n",
    "    X_val_set = list()\n",
    "\n",
    "    for cur_train in train_set:\n",
    "        X_train_set.append(cur_train[train_idx])\n",
    "        X_val_set.append(cur_train[valid_idx])\n",
    "\n",
    "    y_train = train_y[train_idx]\n",
    "    y_val = train_y[valid_idx]\n",
    "\n",
    "    model = sim_lstm_atten(maxlen, num_classes)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RAdam(lr=0.001), metrics=['acc'])\n",
    "    print(\"MODEL COMPLIE...\")\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(X_train_set, y_train, batch_size=200, epochs=50, validation_data=(X_val_set, y_val), callbacks=cb, verbose=1)\n",
    "    pred_val_y = model.predict(X_val_set, batch_size=200, verbose=1)\n",
    "    pred_test_y = model.predict(test_set, batch_size=200, verbose=1)\n",
    "    predicted_train_gender[valid_idx] = pred_val_y\n",
    "    predicted_gender += pred_test_y / len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(train_y,axis=1),np.argmax(predicted_train_gender,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = (train_user[\"gender\"]-1).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9410222222222222\n",
      "0.9358722222222222\n",
      "0.93485\n",
      "0.6692166666666667\n",
      "0.6689833333333334\n"
     ]
    }
   ],
   "source": [
    "for idx, (train_idx, valid_idx) in enumerate(splits):\n",
    "    print(accuracy_score((train_y[valid_idx] >= 0.5).astype(int),(predicted_train_gender[valid_idx] >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_gender >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    736327\n",
       "2    263673\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame((predicted_gender >= 0.5).astype(int))+1)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9372481481481482"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9410222222222222 + 0.9358722222222222 + 0.93485)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.401875925925926"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.46462777777777775 + 0.9372481481481482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: \n",
    "# 1. add stats feature and prediction embedding\n",
    "# 2. optimize embedding\n",
    "# 3. adjust network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4299088888888889 + 0.9316455555555555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TODO \n",
    "\n",
    "# 1. add stats feature\n",
    "# 预期，提高0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. optimize embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb_multi_age = lgb.Booster(model_file=f\"{UMDIR}/lgb_multi_age_20200511045531.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb_multi_gender = lgb.Booster(model_file=f\"{UMDIR}/lgb_multi_gender_20200511034408.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_user[[UID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res[\"predicted_age\"] = np.argmax(predicted_age, axis=1)+1\n",
    "# res[\"predicted_age\"] = predicted_age\n",
    "# res[\"predicted_age\"] = [list(x).index(max(x))+1 for x in model_lgb_multi_age.predict(test_feat, num_iteration=model_lgb_multi_age.best_iteration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_gender\"] = (predicted_gender >= 0.5).astype(int)+1\n",
    "# res[\"predicted_gender\"] = [list(x).index(max(x))+1 for x in model_lgb_multi_gender.predict(test_feat, num_iteration=model_lgb_multi_gender.best_iteration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_suffix = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(int(time.time())))\n",
    "res.to_csv(f\"{RESDIR}/res-{res_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     278243\n",
       "4     179808\n",
       "2     172987\n",
       "5     145293\n",
       "6      97462\n",
       "7      48419\n",
       "9      25342\n",
       "1      24323\n",
       "10     14655\n",
       "8      13468\n",
       "Name: predicted_age, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"predicted_age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    736327\n",
       "2    263673\n",
       "Name: predicted_gender, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"predicted_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(f\"{RESDIR}/res-20200605094137.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     253015\n",
       "2     176461\n",
       "4     172392\n",
       "5     131855\n",
       "6     125634\n",
       "7      53348\n",
       "1      26667\n",
       "8      25059\n",
       "9      24135\n",
       "10     11434\n",
       "Name: predicted_age, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"predicted_age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    679272\n",
       "2    320728\n",
       "Name: predicted_gender, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"predicted_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_gender\"] = tmp[\"predicted_gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"predicted_age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cent result to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ti import session\n",
    "ti_session = session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ti_session.upload_data(path=f\"{RESDIR}/res-20200515004850.csv\", bucket=\"etveritas-1252104022\", key_prefix=RESDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "355px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
