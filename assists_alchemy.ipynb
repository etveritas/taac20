{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if used pip install package\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install wget\n",
    "# !pip install gensim\n",
    "# !pip install catboost\n",
    "# !pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import gc\n",
    "import wget\n",
    "import time\n",
    "import tarfile\n",
    "import zipfile\n",
    "import functools\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from itertools import product, combinations\n",
    "from scipy.special import comb, perm\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cbt\n",
    "from glove import *\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression,BayesianRidge,SGDClassifier,PassiveAggressiveClassifier,RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC,NuSVC,SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# import keras\n",
    "# import keras.backend as K\n",
    "# from keras import layers\n",
    "\n",
    "\n",
    "import gensim\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.init(object_store_memory=int(100e6))\n",
    "# import modin.pandas as pd\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, filename='default.log', stream=sys.stdout):\n",
    "        self.terminal = stream\n",
    "        self.log = open(filename, 'a')\n",
    "        \n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "        \n",
    "    def flush(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.stdout = Logger(\"logs/default.log\", sys.stdout)\n",
    "# sys.stderr = Logger(\"logs/default_err.log\", sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDIR = \"data\"\n",
    "UDDIR = \"user_data\"\n",
    "UFEDIR = \"user_data/feat_data_v05\"\n",
    "UMDIR = \"user_data/model_data\"\n",
    "RESDIR = \"prediction_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UID = \"user_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (Only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fname = wget.download(\"https://tesla-ap-shanghai-1256322946.cos.ap-shanghai.myqcloud.com/cephfs/tesla_common/deeplearning/dataset/algo_contest/train_preliminary.zip\", out=DDIR)\n",
    "# test_fname = wget.download(\"https://tesla-ap-shanghai-1256322946.cos.ap-shanghai.myqcloud.com/cephfs/tesla_common/deeplearning/dataset/algo_contest/test.zip\", out=DDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myunzip(filename):\n",
    "#     zFile = zipfile.ZipFile(filename, \"r\")\n",
    "#     for fileM in zFile.namelist(): \n",
    "#         zFile.extract(fileM, DDIR)\n",
    "#         print(fileM)\n",
    "#     zFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myunzip(train_fname)\n",
    "# myunzip(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bch_rencol(values, prefix=\"\", suffix=\"\"):\n",
    "    return list(map(lambda x: f\"{prefix}\"+\"_\".join(list(map(lambda y: str(y), x)))+f\"{suffix}\" \n",
    "                    if hasattr(x, \"__iter__\") and not isinstance(x, str) \n",
    "                    else f\"{prefix}\"+str(x)+f\"{suffix}\", values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mynunique(values):\n",
    "    return values.nunique(dropna=False)\n",
    "def getidxmax(x):\n",
    "    return x.idxmax()[1]\n",
    "# for time series\n",
    "def at_len(x):\n",
    "    return len(x)\n",
    "\n",
    "def at_sum(x):\n",
    "    return np.sum(x)\n",
    "\n",
    "def at_max(x):\n",
    "    return np.max(x)\n",
    "\n",
    "def at_min(x):\n",
    "    return np.min(x)\n",
    "\n",
    "def at_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def at_range(x):\n",
    "    return at_max(x) - at_min(x)\n",
    "\n",
    "def at_nunq(x):\n",
    "    return len(set(x))\n",
    "\n",
    "def at_lenDrange(x):\n",
    "    return at_len(x)/(at_range(x)+1)\n",
    "\n",
    "def at_lenDnunq(x):\n",
    "    return at_len(x)/at_nunq(x)\n",
    "\n",
    "def at_percentile(n):\n",
    "    def at_percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    at_percentile_.__name__ = f\"at_percentile_{n}\"\n",
    "    return at_percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP_SET = [\"sum\", \"max\", \"min\", \"mean\", \"std\"]\n",
    "OP_SET1 = [\"nunique\", \"sum\", \"max\", \"min\", \"mean\", \"std\", \"median\", \"skew\", at_percentile(0.25), at_percentile(0.75)]\n",
    "OP_SET2 = [\"sum\", \"max\", \"min\", \"mean\", \"std\", \"median\", \"skew\", at_percentile(0.25), at_percentile(0.75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_SET = [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\", \"time\", \"click_times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesting_level = 0\n",
    "is_start = None\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "        self.history = [self.start]\n",
    "\n",
    "    def check(self, info):\n",
    "        current = time.time()\n",
    "        print(f\"[{info}] spend {current - self.history[-1]:0.2f} sec\")\n",
    "        self.history.append(current)\n",
    "\n",
    "def log(entry):\n",
    "    global nesting_level\n",
    "    space = \"-\" * (4 * nesting_level)\n",
    "    print(f\"{space}{entry}\")\n",
    "\n",
    "def timeit(method, start_log=None):\n",
    "    @functools.wraps(method)\n",
    "    def timed(*args, **kw):\n",
    "        global is_start\n",
    "        global nesting_level\n",
    "\n",
    "        if not is_start:\n",
    "            print()\n",
    "\n",
    "        is_start = True\n",
    "        log(f\"Start [{method.__name__}]:\" + (start_log if start_log else \"\"))\n",
    "        log(f'Start time: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "        nesting_level += 1\n",
    "\n",
    "        start_time = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        end_time = time.time()\n",
    "\n",
    "        nesting_level -= 1\n",
    "        log(f\"End   [{method.__name__}]. Time elapsed: {end_time - start_time:0.2f} sec.\")\n",
    "        is_start = False\n",
    "\n",
    "        return result\n",
    "\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_fname = sorted(os.listdir(UFEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = pd.read_csv(f\"{DDIR}/train_preliminary/user.csv\")\n",
    "test_user = pd.read_csv(f\"{DDIR}/test/user.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadnprec(col, max_features=None, maxlen=None, train_order=train_user[UID].values, test_order=test_user[UID].values):\n",
    "    train_seq = pd.read_pickle(f\"{UDDIR}/imd/train_{col}_seq.pkl\")\n",
    "    test_seq = pd.read_pickle(f\"{UDDIR}/imd/test_{col}_seq.pkl\")\n",
    "    \n",
    "    # train_seq[col] = train_seq[col].apply(lambda x: \" \".join(x))\n",
    "    # test_seq[col] = test_seq[col].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    train_seq.sort_index(inplace=True)\n",
    "    test_seq.sort_index(inplace=True)\n",
    "    \n",
    "    assert (train_seq.index.values != train_order).sum() == 0\n",
    "    assert (test_seq.index.values != test_order).sum() == 0\n",
    "    \n",
    "    train_X = train_seq[col].values\n",
    "    test_X = test_seq[col].values\n",
    "    \n",
    "    tol_X = np.concatenate([train_X, test_X])\n",
    "    \n",
    "    # Tokenize the sentences\n",
    "    tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(tol_X))\n",
    "    \n",
    "    tol_X = tokenizer.texts_to_sequences(tol_X)\n",
    "\n",
    "    # Pad the sentences \n",
    "    tol_X = keras.preprocessing.sequence.pad_sequences(tol_X, maxlen=maxlen, padding=\"post\")\n",
    "    \n",
    "    train_X = tol_X[:len(train_seq)]\n",
    "    test_X = tol_X[len(train_seq):]\n",
    "    \n",
    "    return train_X, test_X, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(col, word_index, max_features):\n",
    "    \n",
    "    EMBEDDING_FILE = (f\"{UMDIR}/vectors/glove_{col}.model\")\n",
    "    k = Glove.load(EMBEDDING_FILE)\n",
    "    \n",
    "    embeddings_index = []\n",
    "    for i in tqdm(k.dictionary.keys()):\n",
    "        embeddings_index.append((i,k.word_vectors[k.dictionary[i]]))\n",
    "\n",
    "    embeddings_index = dict(pd.DataFrame(embeddings_index).values)\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v(col, word_index, max_features, embed_size):    \n",
    "    EMBEDDING_FILE = (f\"{UMDIR}/vectors/w2v{embed_size}/w2v_{col}.model\")\n",
    "    \n",
    "    model = gensim.models.Word2Vec.load(EMBEDDING_FILE)\n",
    "    assert list(word_index.keys()) == model.wv.index2word\n",
    "    \n",
    "    embeddings_index = dict()\n",
    "    for word in model.wv.index2word:\n",
    "        embeddings_index[word] = model.wv[word]\n",
    "    \n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    if max_features is None:\n",
    "        nb_words = len(word_index)+1\n",
    "    else:\n",
    "        nb_words = min(max_features, len(word_index)+1)\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_IDS = [\"creative_id\", \"ad_id\", \"advertiser_id\",]   # \"product_id\", \"product_category\", \"industry\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default max_features 5000\n",
    "maxlen = 128\n",
    "embed_size = 128\n",
    "max_features = None\n",
    "# max_features = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_textprec_dic = dict()\n",
    "test_textprec_dic = dict()\n",
    "w2v_wordidx_dic = dict()\n",
    "emb_matrix_dic = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:22<00:00, 147.58s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2020)\n",
    "for cur_id in tqdm(USE_IDS):\n",
    "    train_textprec_dic[cur_id], test_textprec_dic[cur_id], w2v_wordidx_dic[cur_id] = loadnprec(cur_id, max_features, maxlen)\n",
    "    emb_matrix_dic[cur_id] = load_w2v(cur_id, w2v_wordidx_dic[cur_id], max_features, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{UDDIR}/imd/train_textprec_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pickle.dumps(train_textprec_dic), f, protocol=4)\n",
    "\n",
    "with open(f\"{UDDIR}/imd/test_textprec_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pickle.dumps(test_textprec_dic), f, protocol=4)\n",
    "\n",
    "with open(f\"{UDDIR}/imd/w2v_wordidx_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pickle.dumps(w2v_wordidx_dic), f, protocol=4)\n",
    "\n",
    "with open(f\"{UDDIR}/imd/emb_matrix_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pickle.dumps(emb_matrix_dic), f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{UDDIR}/imd/train_textprec_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"rb\") as f:\n",
    "#     train_textprec_dic = pickle.loads(pickle.load(f))\n",
    "    \n",
    "# with open(f\"{UDDIR}/imd/test_textprec_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"rb\") as f:\n",
    "#     test_textprec_dic = pickle.loads(pickle.load(f))\n",
    "\n",
    "# with open(f\"{UDDIR}/imd/w2v_wordidx_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"rb\") as f:\n",
    "#     w2v_wordidx_dic = pickle.loads(pickle.load(f))\n",
    "\n",
    "# with open(f\"{UDDIR}/imd/emb_matrix_dic_w2v{embed_size}_seq{maxlen}_mf{max_features}.pkl\", \"rb\") as f:\n",
    "#     emb_matrix_dic = pickle.loads(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_fname = sorted(os.listdir(UFEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux = pd.DataFrame(train_user[UID])\n",
    "test_aux = pd.DataFrame(test_user[UID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"tfidf_count_emb_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        gender_agg_pred = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "        train_aux = pd.merge(train_aux, gender_agg_pred, how=\"left\", on=UID)\n",
    "        test_aux = pd.merge(test_aux, gender_agg_pred, how=\"left\", on=UID)\n",
    "        gender_agg_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"meta_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        gender_agg_pred = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "        train_aux = pd.merge(train_aux, gender_agg_pred, how=\"left\", on=UID)\n",
    "        test_aux = pd.merge(test_aux, gender_agg_pred, how=\"left\", on=UID)\n",
    "        gender_agg_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats cate target encode\n",
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"train_stats_catemlb\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        train_aux = pd.merge(train_aux, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "    elif fname.startswith(\"test_stats_catemlb\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        test_aux = pd.merge(test_aux, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats o1\n",
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"train_stats_o1\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        train_aux = pd.merge(train_aux, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "    elif fname.startswith(\"test_stats_o1\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        test_aux = pd.merge(test_aux, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stats getidxmax\n",
    "# for fname in feat_fname:\n",
    "#     if fname.startswith(\"train_stats_o2_getidxmax\"):\n",
    "#         print(\"current filename: \", fname)\n",
    "#         train_aux = pd.merge(train_aux, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "#     elif fname.startswith(\"test_stats_o2_getidxmax\"):\n",
    "#         print(\"current filename: \", fname)\n",
    "#         test_aux = pd.merge(test_aux, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"tfidf_svd_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        cur_tfidf_svd = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "        train_aux = pd.merge(train_aux, cur_tfidf_svd, how=\"left\", on=UID)\n",
    "        test_aux = pd.merge(test_aux, cur_tfidf_svd, how=\"left\", on=UID)\n",
    "        cur_tfidf_svd = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # word2vec\n",
    "# for cur_id in USE_IDS:\n",
    "#     fname = f\"w2v_avg_{cur_id}.pkl\"\n",
    "#     print(\"current filename: \", fname)\n",
    "#     cur_df = pd.read_pickle(f\"{UFEDIR}/{fname}\")\n",
    "#     train_aux = pd.merge(train_aux, cur_df, how=\"left\", on=UID)\n",
    "#     test_aux = pd.merge(test_aux, cur_df, how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux.set_index(UID, inplace=True)\n",
    "test_aux.set_index(UID, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_aux.columns == test_aux.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux = train_aux.astype(\"float32\")\n",
    "test_aux = test_aux.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnaninf(val):\n",
    "    return np.mean(val[(~np.isnan(val))&(~np.isinf(val))].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillmean(df):\n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].count() < len(df):\n",
    "            df[col] = df[col].replace([np.nan, np.inf], nnaninf(df[col]))\n",
    "    # check\n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].count() < len(df):\n",
    "            log(col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillmean_abs(df):\n",
    "    for col in tqdm(df.columns):\n",
    "        u = at_percentile(75)(df[col])\n",
    "        l = at_percentile(25)(df[col])\n",
    "        iqr = u - l\n",
    "        up_bound = u + 1.5*iqr\n",
    "        low_bound = l - 1.5*iqr\n",
    "        \n",
    "        df[col][df[col] < low_bound] = np.mean(df[col].values)\n",
    "        df[col][df[col] > up_bound] = np.mean(df[col].values)\n",
    "    # check\n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].count() < len(df):\n",
    "            log(col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux = fillmean(train_aux)\n",
    "test_aux = fillmean(test_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_aux = fillmean_abs(train_aux)\n",
    "test_aux = fillmean_abs(test_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmms(tr_df, te_df):\n",
    "    tol_df = pd.concat([tr_df, te_df])\n",
    "    mms = MinMaxScaler()\n",
    "    mms_tol_df = mms.fit_transform(tol_df)\n",
    "    mms_tr_df = mms_tol_df[:len(tr_df)]\n",
    "    mms_te_df = mms_tol_df[len(tr_df):]\n",
    "    \n",
    "    return mms_tr_df, mms_te_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_aux_scal, test_aux_scal = transmms(train_aux, test_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux_scal.max(), train_aux_scal.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aux_scal.max(), test_aux_scal.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_aux.to_pickle(f\"{UDDIR}/imd/train_aux.pkl\")\n",
    "# test_aux.to_pickle(f\"{UDDIR}/imd/test_aux.pkl\")\n",
    "np.save(f\"{UDDIR}/imd/train_aux_scal.npy\", train_aux_scal)\n",
    "np.save(f\"{UDDIR}/imd/test_aux_scal.npy\", test_aux_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_aux, test_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux_scal = np.load(f\"{UDDIR}/imd/train_aux_scal.npy\")\n",
    "test_aux_scal = np.load(f\"{UDDIR}/imd/test_aux_scal.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 1349)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aux_scal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftAttention(object):\n",
    "    \"\"\"\n",
    "    Layer to compute local inference between two encoded sentences a and b.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        a = inputs[0]\n",
    "        b = inputs[1]\n",
    "\n",
    "        attention = layers.Lambda(self._attention,\n",
    "                                        output_shape = self._attention_output_shape,\n",
    "                                        arguments = None)(inputs)\n",
    "\n",
    "        align_a = layers.Lambda(self._soft_alignment,\n",
    "                                     output_shape = self._soft_alignment_output_shape,\n",
    "                                     arguments = None)([attention, a])\n",
    "        align_b = layers.Lambda(self._soft_alignment,\n",
    "                                     output_shape = self._soft_alignment_output_shape,\n",
    "                                     arguments = None)([attention, b])\n",
    "\n",
    "        return align_a, align_b\n",
    "\n",
    "    def _attention(self, inputs):\n",
    "        \"\"\"\n",
    "        Compute the attention between elements of two sentences with the dot\n",
    "        product.\n",
    "        Args:\n",
    "            inputs: A list containing two elements, one for the first sentence\n",
    "                    and one for the second, both encoded by a BiLSTM.\n",
    "        Returns:\n",
    "            A tensor containing the dot product (attention weights between the\n",
    "            elements of the two sentences).\n",
    "        \"\"\"\n",
    "        attn_weights = K.batch_dot(x=inputs[0],\n",
    "                                   y=K.permute_dimensions(inputs[1],\n",
    "                                                          pattern=(0, 2, 1)))\n",
    "        return K.permute_dimensions(attn_weights, (0, 2, 1))\n",
    "\n",
    "    def _attention_output_shape(self, inputs):\n",
    "        input_shape = inputs[0]\n",
    "        embedding_size = input_shape[1]\n",
    "        return (input_shape[0], embedding_size, embedding_size)\n",
    "\n",
    "    def _soft_alignment(self, inputs):\n",
    "        \"\"\"\n",
    "        Compute the soft alignment between the elements of two sentences.\n",
    "        Args:\n",
    "            inputs: A list of two elements, the first is a tensor of attention\n",
    "                    weights, the second is the encoded sentence on which to\n",
    "                    compute the alignments.\n",
    "        Returns:\n",
    "            A tensor containing the alignments.\n",
    "        \"\"\"\n",
    "        attention = inputs[0]\n",
    "        sentence = inputs[1]\n",
    "\n",
    "        # Subtract the max. from the attention weights to avoid overflows.\n",
    "        exp = K.exp(attention - K.max(attention, axis=-1, keepdims=True))\n",
    "        exp_sum = K.sum(exp, axis=-1, keepdims=True)\n",
    "        softmax = exp / exp_sum\n",
    "\n",
    "        return K.batch_dot(softmax, sentence)\n",
    "\n",
    "    def _soft_alignment_output_shape(self, inputs):\n",
    "        attention_shape = inputs[0]\n",
    "        sentence_shape = inputs[1]\n",
    "        return (attention_shape[0], attention_shape[1], sentence_shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esim(id1, id2):\n",
    "\n",
    "    inp_a = layers.Input(shape=(maxlen,))\n",
    "    inp_b = layers.Input(shape=(maxlen,))\n",
    "    \n",
    "    # embedding layer\n",
    "    embedded_a = layers.Embedding(len(emb_matrix_dic[id1]), embed_size, weights=[emb_matrix_dic[id1]], trainable=False)(inp_a)\n",
    "    embedded_b = layers.Embedding(len(emb_matrix_dic[id2]), embed_size, weights=[emb_matrix_dic[id2]], trainable=False)(inp_b)\n",
    "    \n",
    "    # Encoding Layer\n",
    "    bilstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.1))\n",
    "    \n",
    "    encoded_a = bilstm(embedded_a)\n",
    "    encoded_b = bilstm(embedded_b)\n",
    "    \n",
    "    # local inference layer \n",
    "    atten_a, atten_b = SoftAttention()([encoded_a, encoded_b])\n",
    "\n",
    "    sub_a_atten = layers.Lambda(lambda x: x[0]-x[1])([encoded_a, atten_a])\n",
    "    sub_b_atten = layers.Lambda(lambda x: x[0]-x[1])([encoded_b, atten_b])\n",
    "\n",
    "    mul_a_atten = layers.Lambda(lambda x: x[0]*x[1])([encoded_a, atten_a])\n",
    "    mul_b_atten = layers.Lambda(lambda x: x[0]*x[1])([encoded_b, atten_b])\n",
    "\n",
    "    m_a = layers.concatenate([encoded_a, atten_a, sub_a_atten, mul_a_atten])\n",
    "    m_b = layers.concatenate([encoded_b, atten_b, sub_b_atten, mul_b_atten])\n",
    "    \n",
    "    # Inference composition layer\n",
    "    composition_a = layers.Bidirectional(layers.LSTM(\n",
    "        128,\n",
    "        return_sequences=True,\n",
    "        dropout=0.2\n",
    "    ))(m_a)\n",
    "\n",
    "    avg_pool_a = layers.GlobalAveragePooling1D()(composition_a)\n",
    "    max_pool_a = layers.GlobalMaxPooling1D()(composition_a)\n",
    "\n",
    "    composition_b = layers.Bidirectional(layers.LSTM(\n",
    "        128,\n",
    "        return_sequences=True,\n",
    "        dropout=0.2\n",
    "    ))(m_b)\n",
    "\n",
    "    avg_pool_b = layers.GlobalAveragePooling1D()(composition_b)\n",
    "    max_pool_b = layers.GlobalMaxPooling1D()(composition_b)\n",
    "    \n",
    "    \n",
    "    pooled = layers.concatenate([avg_pool_a, max_pool_a, avg_pool_b, max_pool_b])\n",
    "    pooled = layers.Dropout(rate=0.1)(pooled)\n",
    "    \n",
    "    inp_aux = layers.Input(shape=(train_aux_scal.shape[1], ))\n",
    "    aux_1 = layers.Dense(32)(inp_aux)\n",
    "    \n",
    "    conc = layers.concatenate([pooled, aux_1])\n",
    "    \n",
    "    conc = layers.Dense(256, activation=\"relu\")(conc)\n",
    "    conc = layers.Dense(64, activation=\"relu\")(conc)\n",
    "    conc = layers.Dense(32, activation=\"relu\")(conc)\n",
    "    \n",
    "    conc = layers.Dropout(rate=0.2)(conc)\n",
    "\n",
    "    out_age = layers.Dense(10, activation=\"softmax\", name=\"out_age\")(conc)\n",
    "    out_gender = layers.Dense(1, activation=\"sigmoid\", name=\"out_gender\")(conc)\n",
    "\n",
    "    model = keras.Model(inputs=[inp_a, inp_b, inp_aux], outputs=[out_age, out_gender])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = \"creative_id\"\n",
    "id2 = \"advertiser_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = esim(id1, id2)\n",
    "model.compile(\n",
    "    loss={\"out_age\": \"categorical_crossentropy\", \"out_gender\": \"binary_crossentropy\"},\n",
    "    loss_weights={\"out_age\": 1, \"out_gender\": 1},\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [train_textprec_dic[id1], train_textprec_dic[id2]]\n",
    "test_set = [test_textprec_dic[id1], test_textprec_dic[id2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y_age = keras.utils.to_categorical(train_user[\"age\"]-1)\n",
    "train_y_gender = (train_user[\"gender\"]-1).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_set = train_test_split(*train_set, train_y_age, train_y_gender, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tr = res_set[:-4:2]\n",
    "train_X_val = res_set[1:-4:2]\n",
    "train_y_tr_age = res_set[-4]\n",
    "train_y_val_age = res_set[-3]\n",
    "\n",
    "train_y_tr_gender = res_set[-2]\n",
    "train_y_val_gender = res_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elsp = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "filepath = f\"{UMDIR}/weights_improvement_fold.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [elsp,]  # checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_X_tr, [train_y_tr_age, train_y_tr_gender], validation_data=(train_X_val, [train_y_val_age, train_y_val_gender]), epochs=3, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{UMDIR}/5inp_esim_model_emb{embed_size}_seq{maxlen}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(f\"{UMDIR}/5inp_2bilstm_model_128.h5\")\n",
    "model._layers = [\n",
    "    layer for layer in model._layers if isinstance(layer, keras.layers.Layer)\n",
    "]\n",
    "keras.utils.plot_model(model, to_file=f\"{UMDIR}/5inp_esim_model_emb{embed_size}_seq{maxlen}.png\", show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 128, 128)     436834944   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 128)     7407488     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128, 256)     263168      embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128, 128)     0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 256)     0           lambda[0][0]                     \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 256)     0           lambda[0][0]                     \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 256)     0           bidirectional[0][0]              \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 256)     0           bidirectional[0][0]              \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 256)     0           bidirectional[1][0]              \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 128, 256)     0           bidirectional[1][0]              \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 1024)    0           bidirectional[0][0]              \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 1024)    0           bidirectional[1][0]              \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128, 256)     1180672     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 128, 256)     1180672     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1349)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           43200       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1056)         0           dropout[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          270592      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_age (Dense)                 (None, 10)           330         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "out_gender (Dense)              (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 447,199,627\n",
      "Trainable params: 2,957,195\n",
      "Non-trainable params: 444,242,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "704/704 [==============================] - 4248s 6s/step - loss: 1.7229 - out_age_loss: 1.5111 - out_gender_loss: 0.2118 - out_age_acc: 0.3860 - out_gender_acc: 0.9248 - val_loss: 1.5243 - val_out_age_loss: 1.3546 - val_out_gender_loss: 0.1697 - val_out_age_acc: 0.4407 - val_out_gender_acc: 0.9387\n",
      "Epoch 2/50\n",
      "704/704 [==============================] - 4169s 6s/step - loss: 1.5510 - out_age_loss: 1.3704 - out_gender_loss: 0.1806 - out_age_acc: 0.4370 - out_gender_acc: 0.9387 - val_loss: 1.4852 - val_out_age_loss: 1.3250 - val_out_gender_loss: 0.1602 - val_out_age_acc: 0.4505 - val_out_gender_acc: 0.9440\n",
      "Epoch 3/50\n",
      "704/704 [==============================] - 4164s 6s/step - loss: 1.5170 - out_age_loss: 1.3431 - out_gender_loss: 0.1740 - out_age_acc: 0.4470 - out_gender_acc: 0.9412 - val_loss: 1.4693 - val_out_age_loss: 1.3093 - val_out_gender_loss: 0.1600 - val_out_age_acc: 0.4556 - val_out_gender_acc: 0.9446\n",
      "Epoch 4/50\n",
      "704/704 [==============================] - 4119s 6s/step - loss: 1.4973 - out_age_loss: 1.3264 - out_gender_loss: 0.1709 - out_age_acc: 0.4534 - out_gender_acc: 0.9422 - val_loss: 1.4585 - val_out_age_loss: 1.3019 - val_out_gender_loss: 0.1567 - val_out_age_acc: 0.4576 - val_out_gender_acc: 0.9450\n",
      "Epoch 5/50\n",
      "704/704 [==============================] - 4080s 6s/step - loss: 1.4814 - out_age_loss: 1.3135 - out_gender_loss: 0.1679 - out_age_acc: 0.4574 - out_gender_acc: 0.9432 - val_loss: 1.4557 - val_out_age_loss: 1.2989 - val_out_gender_loss: 0.1568 - val_out_age_acc: 0.4596 - val_out_gender_acc: 0.9448\n",
      "Epoch 6/50\n",
      "704/704 [==============================] - 4062s 6s/step - loss: 1.4696 - out_age_loss: 1.3039 - out_gender_loss: 0.1657 - out_age_acc: 0.4608 - out_gender_acc: 0.9443 - val_loss: 1.4494 - val_out_age_loss: 1.2915 - val_out_gender_loss: 0.1579 - val_out_age_acc: 0.4622 - val_out_gender_acc: 0.9439\n",
      "Epoch 7/50\n",
      "704/704 [==============================] - 4053s 6s/step - loss: 1.4588 - out_age_loss: 1.2949 - out_gender_loss: 0.1639 - out_age_acc: 0.4639 - out_gender_acc: 0.9450 - val_loss: 1.4433 - val_out_age_loss: 1.2839 - val_out_gender_loss: 0.1594 - val_out_age_acc: 0.4650 - val_out_gender_acc: 0.9436\n",
      "Epoch 8/50\n",
      "704/704 [==============================] - 4074s 6s/step - loss: 1.4475 - out_age_loss: 1.2855 - out_gender_loss: 0.1621 - out_age_acc: 0.4672 - out_gender_acc: 0.9456 - val_loss: 1.4432 - val_out_age_loss: 1.2879 - val_out_gender_loss: 0.1554 - val_out_age_acc: 0.4620 - val_out_gender_acc: 0.9460\n",
      "Epoch 9/50\n",
      "704/704 [==============================] - 4073s 6s/step - loss: 1.4378 - out_age_loss: 1.2775 - out_gender_loss: 0.1603 - out_age_acc: 0.4703 - out_gender_acc: 0.9465 - val_loss: 1.4389 - val_out_age_loss: 1.2833 - val_out_gender_loss: 0.1556 - val_out_age_acc: 0.4633 - val_out_gender_acc: 0.9454\n",
      "Epoch 10/50\n",
      "704/704 [==============================] - 4189s 6s/step - loss: 1.4272 - out_age_loss: 1.2692 - out_gender_loss: 0.1580 - out_age_acc: 0.4726 - out_gender_acc: 0.9471 - val_loss: 1.4380 - val_out_age_loss: 1.2814 - val_out_gender_loss: 0.1566 - val_out_age_acc: 0.4643 - val_out_gender_acc: 0.9452\n",
      "Epoch 11/50\n",
      "704/704 [==============================] - 4140s 6s/step - loss: 1.4161 - out_age_loss: 1.2604 - out_gender_loss: 0.1557 - out_age_acc: 0.4760 - out_gender_acc: 0.9481 - val_loss: 1.4376 - val_out_age_loss: 1.2778 - val_out_gender_loss: 0.1599 - val_out_age_acc: 0.4683 - val_out_gender_acc: 0.9434\n",
      "Epoch 12/50\n",
      "113/704 [===>..........................] - ETA: 52:37 - loss: 1.4036 - out_age_loss: 1.2509 - out_gender_loss: 0.1527 - out_age_acc: 0.4775 - out_gender_acc: 0.9495"
     ]
    }
   ],
   "source": [
    "# K-fold\n",
    "id1 = \"creative_id\"\n",
    "id2 = \"advertiser_id\"\n",
    "\n",
    "train_set = [train_textprec_dic[id1], train_textprec_dic[id2], train_aux_scal]\n",
    "test_set = [test_textprec_dic[id1], test_textprec_dic[id2], test_aux_scal]\n",
    "\n",
    "train_y_age = keras.utils.to_categorical(train_user[\"age\"]-1)\n",
    "train_y_gender = (train_user[\"gender\"]-1).values.reshape(-1, 1)\n",
    "\n",
    "DATA_SPLIT_SEED = 2020\n",
    "nfolds = 5\n",
    "kfold = KFold(n_splits=nfolds, shuffle=True, random_state=DATA_SPLIT_SEED)\n",
    "\n",
    "predicted_train_age = np.zeros(train_y_age.shape)\n",
    "predicted_train_gender = np.zeros(train_y_gender.shape)\n",
    "predicted_age = np.zeros((len(test_user),train_y_age.shape[1]))\n",
    "predicted_gender = np.zeros((len(test_user),train_y_gender.shape[1]))\n",
    "\n",
    "elsp = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "cb = [elsp,] \n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(kfold.split(train_set[0])):\n",
    "    print(\"Current fold:\", idx+1)\n",
    "    \n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train_set = list()\n",
    "    X_val_set = list()\n",
    "    \n",
    "    for cur_train in train_set:\n",
    "        X_train_set.append(cur_train[train_idx])\n",
    "        X_val_set.append(cur_train[valid_idx])\n",
    "        \n",
    "    y_train_age = train_y_age[train_idx]\n",
    "    y_train_gender = train_y_gender[train_idx]\n",
    "    \n",
    "    y_val_age = train_y_age[valid_idx]\n",
    "    y_val_gender = train_y_gender[valid_idx]\n",
    "    \n",
    "\n",
    "    model = esim(id1, id2)\n",
    "    model.compile(\n",
    "        loss={\"out_age\": \"categorical_crossentropy\", \"out_gender\": \"binary_crossentropy\"},\n",
    "        loss_weights={\"out_age\": 1, \"out_gender\": 1},\n",
    "        optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(X_train_set, [y_train_age, y_train_gender], validation_data=(X_val_set, [y_val_age, y_val_gender]), batch_size=1024, epochs=50, callbacks=cb)\n",
    "    \n",
    "    predicted_train_age[valid_idx], predicted_train_gender[valid_idx] = model.predict(X_val_set, batch_size=1024, verbose=1)\n",
    "    pred_test_y_age, pred_test_y_gender = model.predict(test_set, batch_size=1024, verbose=1)\n",
    "    predicted_age += pred_test_y_age / nfolds\n",
    "    predicted_gender += pred_test_y_gender / nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(train_y_age, axis=1), np.argmax(predicted_train_age, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(train_y_gender, (predicted_train_gender >= 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(layers.Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = keras.initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = keras.regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = keras.constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(keras.layers.Layer):\n",
    "    r\"\"\"The attention layer that takes three inputs representing queries, keys and values.\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "        :param return_attention: Whether to return attention weights.\n",
    "        :param history_only: Whether to only use history data.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        self.intensity = self.attention = None\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "        }\n",
    "        base_config = super(ScaledDotProductAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            query_shape, key_shape, value_shape = input_shape\n",
    "        else:\n",
    "            query_shape = key_shape = value_shape = input_shape\n",
    "        output_shape = query_shape[:-1] + value_shape[-1:]\n",
    "        if self.return_attention:\n",
    "            attention_shape = query_shape[:2] + (key_shape[1],)\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            query, key, value = inputs\n",
    "        else:\n",
    "            query = key = value = inputs\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[1]\n",
    "        feature_dim = K.shape(query)[-1]\n",
    "        e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(feature_dim, dtype=K.floatx()))\n",
    "        if self.history_only:\n",
    "            query_len, key_len = K.shape(query)[1], K.shape(key)[1]\n",
    "            indices = K.expand_dims(K.arange(0, key_len), axis=0)\n",
    "            upper = K.expand_dims(K.arange(0, query_len), axis=-1)\n",
    "            e -= 10000.0 * K.expand_dims(K.cast(indices > upper, K.floatx()), axis=0)\n",
    "        if mask is not None:\n",
    "            e -= 10000.0 * (1.0 - K.cast(K.expand_dims(mask, axis=-2), K.floatx()))\n",
    "        self.intensity = e\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        self.attention = e / K.sum(e, axis=-1, keepdims=True)\n",
    "        v = K.batch_dot(self.attention, value)\n",
    "        if self.return_attention:\n",
    "            return [v, self.attention]\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqSelfAttention(keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e9)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': keras.initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = int(input_shape[2])\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = int(input_shape[2])\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        if self.attention_width is not None:\n",
    "            if self.history_only:\n",
    "                lower = K.arange(0, input_len) - (self.attention_width - 1)\n",
    "            else:\n",
    "                lower = K.arange(0, input_len) - self.attention_width // 2\n",
    "            lower = K.expand_dims(lower, axis=-1)\n",
    "            upper = lower + self.attention_width\n",
    "            indices = K.expand_dims(K.arange(0, input_len), axis=0)\n",
    "            e -= 10000.0 * (K.cast(indices < lower, K.floatx()) * K.cast(upper <= indices, K.floatx()))\n",
    "        if mask is not None:\n",
    "            mask = K.expand_dims(K.cast(mask, K.floatx()), axis=-1)\n",
    "            e -= 10000.0 * ((1.0 - mask) * (1.0 - K.permute_dimensions(mask, (0, 2, 1))))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        a = e / K.sum(e, axis=-1, keepdims=True)\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q = K.expand_dims(K.dot(inputs, self.Wt), 2)\n",
    "        k = K.expand_dims(K.dot(inputs, self.Wx), 1)\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e += self.ba[0]\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        indices = K.expand_dims(K.arange(0, input_len), axis=0)\n",
    "        diagonal = K.expand_dims(K.arange(0, input_len), axis=-1)\n",
    "        eye = K.cast(K.equal(indices, diagonal), K.floatx())\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - eye)) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqSelfAttention': SeqSelfAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqWeightedAttention(keras.layers.Layer):\n",
    "    r\"\"\"Y = \\text{softmax}(XW + b) X\n",
    "    See: https://arxiv.org/pdf/1708.00524.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_bias=True, return_attention=False, **kwargs):\n",
    "        super(SeqWeightedAttention, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.use_bias = use_bias\n",
    "        self.return_attention = return_attention\n",
    "        self.W, self.b = None, None\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'use_bias': self.use_bias,\n",
    "            'return_attention': self.return_attention,\n",
    "        }\n",
    "        base_config = super(SeqWeightedAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(int(input_shape[2]), 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=keras.initializers.get('uniform'))\n",
    "        if self.use_bias:\n",
    "            self.b = self.add_weight(shape=(1,),\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     initializer=keras.initializers.get('zeros'))\n",
    "        super(SeqWeightedAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        logits = K.dot(x, self.W)\n",
    "        if self.use_bias:\n",
    "            logits += self.b\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            logits -= 10000.0 * (1.0 - mask)\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return input_shape[0], output_len\n",
    "\n",
    "    def compute_mask(self, _, input_mask=None):\n",
    "        if self.return_attention:\n",
    "            return [None, None]\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqWeightedAttention': SeqWeightedAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = \"creative_id\"\n",
    "id2 = \"ad_id\"\n",
    "id3 = \"advertiser_id\"\n",
    "# id4 = \"product_id\"\n",
    "# id5 = \"industry\"\n",
    "# id6 = \"product_category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1 = layers.Input(shape=(maxlen,))\n",
    "inp_2 = layers.Input(shape=(maxlen,))\n",
    "inp_3 = layers.Input(shape=(maxlen,))\n",
    "# inp_4 = layers.Input(shape=(maxlen,))\n",
    "# inp_5 = layers.Input(shape=(maxlen,))\n",
    "# inp_6 = layers.Input(shape=(maxlen,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_1 = layers.Embedding(input_dim=len(emb_matrix_dic[id1]), output_dim=embed_size, weights=[emb_matrix_dic[id1]], trainable=False)(inp_1)\n",
    "embed_2 = layers.Embedding(input_dim=len(emb_matrix_dic[id2]), output_dim=embed_size, weights=[emb_matrix_dic[id2]], trainable=False)(inp_2)\n",
    "embed_3 = layers.Embedding(input_dim=len(emb_matrix_dic[id3]), output_dim=embed_size, weights=[emb_matrix_dic[id3]], trainable=False)(inp_3)\n",
    "# embed_4 = layers.Embedding(input_dim=len(emb_matrix_dic[id4]), output_dim=embed_size, weights=[emb_matrix_dic[id4]], trainable=False)(inp_4)\n",
    "# embed_5 = layers.Embedding(input_dim=len(emb_matrix_dic[id5]), output_dim=embed_size, weights=[emb_matrix_dic[id5]], trainable=False)(inp_5)\n",
    "# embed_6 = layers.Embedding(input_dim=len(emb_matrix_dic[id6]), output_dim=embed_size, weights=[emb_matrix_dic[id6]], trainable=False)(inp_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_1 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_1)\n",
    "# gru_1 = layers.Bidirectional(layers.GRU(64, return_sequences=True))(bilstm_1)\n",
    "bilstm_2 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_2)\n",
    "# gru_2 = layers.Bidirectional(layers.GRU(64, return_sequences=True))(bilstm_2)\n",
    "bilstm_3 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_3)\n",
    "# gru_3 = layers.Bidirectional(layers.GRU(64, return_sequences=True))(bilstm_3)\n",
    "# bilstm_4 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_4)\n",
    "# gru_4 = layers.Bidirectional(layers.GRU(64, return_sequences=True))(bilstm_4)\n",
    "# bilstm_5 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_5)\n",
    "# gru_5 = layers.Bidirectional(layers.GRU(64, return_sequences=True))(bilstm_5)\n",
    "# bilstm_6 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_6)\n",
    "# bilstm_6 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(bilstm_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilstm_1 = layers.Bidirectional(layers.LSTM(128))(embed_1)\n",
    "# bilstm_2 = layers.Bidirectional(layers.LSTM(128))(embed_2)\n",
    "# bilstm_3 = layers.Bidirectional(layers.LSTM(128))(embed_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atten_1 = Attention(maxlen)(bilstm_1)\n",
    "# atten_11 = Attention(maxlen)(gru_1)\n",
    "# atten_2 = Attention(maxlen)(bilstm_2)\n",
    "# atten_22 = Attention(maxlen)(gru_2)\n",
    "# atten_3 = Attention(maxlen)(bilstm_3)\n",
    "# atten_33 = Attention(maxlen)(gru_3)\n",
    "# atten_4 = Attention(maxlen)(bilstm_4)\n",
    "# atten_44 = Attention(maxlen)(gru_4)\n",
    "# atten_5 = Attention(maxlen)(bilstm_5)\n",
    "# atten_55 = Attention(maxlen)(gru_5)\n",
    "# atten_6 = Attention(maxlen)(bilstm_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxpool_1 = layers.GlobalMaxPooling1D()(gru_1)\n",
    "# maxpool_2 = layers.GlobalMaxPooling1D()(gru_2)\n",
    "# maxpool_3 = layers.GlobalMaxPooling1D()(gru_3)\n",
    "# maxpool_4 = layers.GlobalMaxPooling1D()(gru_4)\n",
    "# maxpool_5 = layers.GlobalMaxPooling1D()(gru_5)\n",
    "# maxpool_6 = layers.GlobalMaxPooling1D()(bilstm_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp_aux = layers.Input(shape=(train_aux_scal.shape[1], ))\n",
    "# aux_1 = layers.Dense(128)(inp_aux)\n",
    "# aux_1 = layers.BatchNormalization()(aux_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conc_list = [maxpool_1, maxpool_2, maxpool_3, ]  #  maxpool_4, maxpool_5, aux_1]\n",
    "# conc_list = [bilstm_1, bilstm_2, bilstm_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conc_list = [atten_1, atten_11, maxpool_1, atten_2, atten_22, maxpool_2, atten_3, atten_33, maxpool_3, atten_4, atten_44, maxpool_4, atten_5, atten_55, maxpool_5, aux_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conc = layers.concatenate(conc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_conc = layers.concatenate([bilstm_1, bilstm_2, bilstm_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_1 = ScaledDotProductAttention()(bilstm_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_1 = layers.GlobalMaxPooling1D()(atten_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = maxpool_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conc = layers.Dense(256)(atten_1)\n",
    "# conc = layers.BatchNormalization()(conc)\n",
    "# conc = layers.PReLU()(conc)\n",
    "# conc = layers.Dropout(0.2)(conc)\n",
    "\n",
    "# conc = layers.Dense(128)(conc)\n",
    "# conc = layers.BatchNormalization()(conc)\n",
    "\n",
    "# out_age = layers.Dense(10, activation=\"softmax\", name=\"out_age\")(conc)\n",
    "# out_gender = layers.Dense(1, activation=\"sigmoid\", name=\"out_gender\")(conc)\n",
    "\n",
    "conc = layers.Dense(256, activation=\"relu\")(conc)\n",
    "conc = layers.Dense(64, activation=\"relu\")(conc)\n",
    "conc = layers.Dense(32, activation=\"relu\")(conc)\n",
    "\n",
    "conc = layers.Dropout(rate=0.2)(conc)\n",
    "\n",
    "out_age = layers.Dense(10, activation=\"softmax\", name=\"out_age\")(conc)\n",
    "out_gender = layers.Dense(1, activation=\"sigmoid\", name=\"out_gender\")(conc)\n",
    "\n",
    "model = keras.Model(inputs=[inp_1, inp_2, inp_3, ], outputs=[out_age, out_gender])  #  inp_4, inp_5, inp_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current lr=0.0005\n",
    "model.compile(\n",
    "    loss={\"out_age\": \"categorical_crossentropy\", \"out_gender\": \"binary_crossentropy\"},\n",
    "    loss_weights={\"out_age\": 1, \"out_gender\": 1},\n",
    "    optimizer=tfa.optimizers.RectifiedAdam(lr=0.001), \n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tfa.optimizers.RectifiedAdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [train_textprec_dic[id1], train_textprec_dic[id2], train_textprec_dic[id3],]   # train_textprec_dic[id1], train_textprec_dic[id2], train_textprec_dic[id3], train_textprec_dic[id4], train_textprec_dic[id5], train_aux_scal]\n",
    "test_set = [test_textprec_dic[id1], test_textprec_dic[id2], test_textprec_dic[id3],]   # test_textprec_dic[id1], test_textprec_dic[id2], test_textprec_dic[id3], test_textprec_dic[id4], test_textprec_dic[id5], test_aux_scal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_age = keras.utils.to_categorical(train_user[\"age\"]-1)\n",
    "train_y_gender = (train_user[\"gender\"]-1).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_set = train_test_split(*train_set, train_y_age, train_y_gender, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tr = res_set[:-4:2]\n",
    "train_X_val = res_set[1:-4:2]\n",
    "train_y_tr_age = res_set[-4]\n",
    "train_y_val_age = res_set[-3]\n",
    "\n",
    "train_y_tr_gender = res_set[-2]\n",
    "train_y_val_gender = res_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsp = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "filepath = f\"{UMDIR}/weights_improvement_fold.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [elsp,]  # checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_X_tr, [train_y_tr_age, train_y_tr_gender], validation_data=(train_X_val, [train_y_val_age, train_y_val_gender]), batch_size=1024, epochs=10, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/20\n",
    "22500/22500 [==============================] - 2096s 93ms/step - loss: 1.6319 - out_age_loss: 1.4304 - out_gender_loss: 0.2015 - out_age_acc: 0.4164 - out_gender_acc: 0.9272 - val_loss: 1.4971 - val_out_age_loss: 1.3261 - val_out_gender_loss: 0.1710 - val_out_age_acc: 0.4511 - val_out_gender_acc: 0.9396\n",
    "Epoch 2/20\n",
    "22500/22500 [==============================] - 2092s 93ms/step - loss: 1.5176 - out_age_loss: 1.3389 - out_gender_loss: 0.1787 - out_age_acc: 0.4474 - out_gender_acc: 0.9367 - val_loss: 1.4781 - val_out_age_loss: 1.3116 - val_out_gender_loss: 0.1666 - val_out_age_acc: 0.4571 - val_out_gender_acc: 0.9408\n",
    "Epoch 3/20\n",
    "22500/22500 [==============================] - 2094s 93ms/step - loss: 1.4770 - out_age_loss: 1.3061 - out_gender_loss: 0.1709 - out_age_acc: 0.4607 - out_gender_acc: 0.9398 - val_loss: 1.4576 - val_out_age_loss: 1.2924 - val_out_gender_loss: 0.1652 - val_out_age_acc: 0.4647 - val_out_gender_acc: 0.9412\n",
    "Epoch 4/20\n",
    "22500/22500 [==============================] - 2099s 93ms/step - loss: 1.4410 - out_age_loss: 1.2765 - out_gender_loss: 0.1645 - out_age_acc: 0.4714 - out_gender_acc: 0.9421 - val_loss: 1.4564 - val_out_age_loss: 1.2911 - val_out_gender_loss: 0.1652 - val_out_age_acc: 0.4643 - val_out_gender_acc: 0.9415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(f\"{UMDIR}/3inp_2bilstm_model_emb{embed_size}_seq{maxlen}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.model.load_model(filepath)\n",
    "# pred_res = model.predict(test_set, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_X_val, [train_y_val_age, train_y_val_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/3\n",
    "22500/22500 [==============================] - 127s 6ms/step - loss: 1.6434 - out_age_loss: 1.4391 - out_gender_loss: 0.2043 - out_age_acc: 0.4136 - out_gender_acc: 0.9259 - val_loss: 1.5569 - val_out_age_loss: 1.3704 - val_out_gender_loss: 0.1865 - val_out_age_acc: 0.4366 - val_out_gender_acc: 0.9329\n",
    "Epoch 2/3\n",
    "22500/22500 [==============================] - 127s 6ms/step - loss: 1.5836 - out_age_loss: 1.3904 - out_gender_loss: 0.1932 - out_age_acc: 0.4306 - out_gender_acc: 0.9311 - val_loss: 1.5369 - val_out_age_loss: 1.3560 - val_out_gender_loss: 0.1809 - val_out_age_acc: 0.4392 - val_out_gender_acc: 0.9349\n",
    "Epoch 3/3\n",
    "22500/22500 [==============================] - 128s 6ms/step - loss: 1.5697 - out_age_loss: 1.3798 - out_gender_loss: 0.1900 - out_age_acc: 0.4348 - out_gender_acc: 0.9324 - val_loss: 1.5385 - val_out_age_loss: 1.3586 - val_out_gender_loss: 0.1798 - val_out_age_acc: 0.4391 - val_out_gender_acc: 0.9349\n",
    "<tensorflow.python.keras.callbacks.History at 0x7f1870d90cf8>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22500/22500 [==============================] - 126s 6ms/step - loss: 1.5604 - out_age_loss: 1.3715 - out_gender_loss: 0.1889 - out_age_acc: 0.4366 - out_gender_acc: 0.9328 - val_loss: 1.5267 - val_out_age_loss: 1.3472 - val_out_gender_loss: 0.1795 - val_out_age_acc: 0.4420 - val_out_gender_acc: 0.9356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(f\"{UMDIR}/3inp_2bilstm_model_emb{embed_size}_seq{maxlen}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = model.predict(test_set, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(f\"{UMDIR}/3inp_2bilstm_model_emb{embed_size}_seq{maxlen}.h5\")\n",
    "# model = keras.models.load_model(f\"{UMDIR}/5inp_2bilstm_model_128.h5\")\n",
    "model._layers = [\n",
    "    layer for layer in model._layers if isinstance(layer, keras.layers.Layer)\n",
    "]\n",
    "keras.utils.plot_model(model, to_file=f\"{UMDIR}/3inp_2bilstm_model_emb{embed_size}_seq{maxlen}.png\", show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# K-fold\n",
    "id1 = \"creative_id\"\n",
    "id2 = \"ad_id\"\n",
    "id3 = \"advertiser_id\"\n",
    "\n",
    "\n",
    "train_set = [train_textprec_dic[id1], train_textprec_dic[id2], train_textprec_dic[id3],]\n",
    "test_set = [test_textprec_dic[id1], test_textprec_dic[id2], test_textprec_dic[id3],]  \n",
    "\n",
    "train_y_age = keras.utils.to_categorical(train_user[\"age\"]-1)\n",
    "train_y_gender = (train_user[\"gender\"]-1).values.reshape(-1, 1)\n",
    "\n",
    "DATA_SPLIT_SEED = 2020\n",
    "nfolds = 5\n",
    "kfold = KFold(n_splits=nfolds, shuffle=True, random_state=DATA_SPLIT_SEED)\n",
    "\n",
    "predicted_train_age = np.zeros(train_y_age.shape)\n",
    "predicted_train_gender = np.zeros(train_y_gender.shape)\n",
    "predicted_age = np.zeros((len(test_user),train_y_age.shape[1]))\n",
    "predicted_gender = np.zeros((len(test_user),train_y_gender.shape[1]))\n",
    "\n",
    "elsp = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "cb = [elsp,] \n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(kfold.split(train_set[0])):\n",
    "    print(\"Current fold:\", idx+1)\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train_set = list()\n",
    "    X_val_set = list()\n",
    "    \n",
    "    for cur_train in train_set:\n",
    "        X_train_set.append(cur_train[train_idx])\n",
    "        X_val_set.append(cur_train[valid_idx])\n",
    "        \n",
    "    y_train_age = train_y_age[train_idx]\n",
    "    y_train_gender = train_y_gender[train_idx]\n",
    "    \n",
    "    y_val_age = train_y_age[valid_idx]\n",
    "    y_val_gender = train_y_gender[valid_idx]\n",
    "    \n",
    "    inp_1 = layers.Input(shape=(maxlen,))\n",
    "    inp_2 = layers.Input(shape=(maxlen,))\n",
    "    inp_3 = layers.Input(shape=(maxlen,))\n",
    "    \n",
    "    embed_1 = layers.Embedding(input_dim=len(emb_matrix_dic[id1]), output_dim=embed_size, weights=[emb_matrix_dic[id1]], trainable=False)(inp_1)\n",
    "    embed_2 = layers.Embedding(input_dim=len(emb_matrix_dic[id2]), output_dim=embed_size, weights=[emb_matrix_dic[id2]], trainable=False)(inp_2)\n",
    "    embed_3 = layers.Embedding(input_dim=len(emb_matrix_dic[id3]), output_dim=embed_size, weights=[emb_matrix_dic[id3]], trainable=False)(inp_3)\n",
    "\n",
    "    bilstm_1 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_1)\n",
    "    bilstm_2 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_2)\n",
    "    bilstm_3 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(embed_3)\n",
    "    \n",
    "    bilstm_conc = layers.concatenate([bilstm_1, bilstm_2, bilstm_3])\n",
    "    atten_1 = Attention()(bilstm_conc)\n",
    "#     atten_1 = Attention(maxlen)(bilstm_1)\n",
    "#     atten_2 = Attention(maxlen)(bilstm_2)\n",
    "#     atten_3 = Attention(maxlen)(bilstm_3)\n",
    "    \n",
    "#     conc_list = [atten_1, atten_2, atten_3]\n",
    "    \n",
    "#     conc = layers.concatenate(conc_list)\n",
    "    conc = layers.Dense(256, activation=\"relu\")(atten_1)\n",
    "    conc = layers.Dense(64, activation=\"relu\")(conc)\n",
    "    conc = layers.Dense(32, activation=\"relu\")(conc)\n",
    "    \n",
    "    conc = layers.Dropout(rate=0.2)(conc)\n",
    "    \n",
    "    out_age = layers.Dense(10, activation=\"softmax\", name=\"out_age\")(conc)\n",
    "    out_gender = layers.Dense(1, activation=\"sigmoid\", name=\"out_gender\")(conc)\n",
    "\n",
    "    model = keras.Model(inputs=[inp_1, inp_2, inp_3, ], outputs=[out_age, out_gender])\n",
    "    \n",
    "    model.compile(\n",
    "        loss={\"out_age\": \"categorical_crossentropy\", \"out_gender\": \"binary_crossentropy\"},\n",
    "        loss_weights={\"out_age\": 1, \"out_gender\": 1},\n",
    "        optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(X_train_set, [y_train_age, y_train_gender], validation_data=(X_val_set, [y_val_age, y_val_gender]), batch_size=1024, epochs=50, callbacks=cb)\n",
    "    \n",
    "    predicted_train_age[valid_idx], predicted_train_gender[valid_idx] = model.predict(X_val_set, batch_size=1024, verbose=1)\n",
    "    pred_test_y_age, pred_test_y_gender = model.predict(test_set, batch_size=1024, verbose=1)\n",
    "    predicted_age += pred_test_y_age / nfolds\n",
    "    predicted_gender += pred_test_y_gender / nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers.modeling_tf_bert import (BertConfig, TFBertModel,\n",
    "                                           TFBertEmbeddings, TFBertMainLayer,\n",
    "                                           TFBertEncoder, TFBertAttention, \n",
    "                                           TFBertSelfAttention, TFBertLayer, TFBertPooler,\n",
    "                                           TFBertIntermediate, TFBertOutput,\n",
    "                                           TFBertForSequenceClassification, TFBertSelfOutput\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cts = pd.read_pickle(f\"{UDDIR}/imd/train_click_times_seq.pkl\")\n",
    "test_cts = pd.read_pickle(f\"{UDDIR}/imd/test_click_times_seq.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = keras.preprocessing.sequence.pad_sequences(train_cts[\"click_times\"].values, maxlen=maxlen, padding=\"post\")\n",
    "test_mask = keras.preprocessing.sequence.pad_sequences(test_cts[\"click_times\"].values, maxlen=maxlen, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position ids\n",
    "train_pos_ids = dict()\n",
    "for col in train_textprec_dic:\n",
    "    lines, cols = train_textprec_dic[col].shape\n",
    "    train_pos_ids[col] = np.array([list(range(cols))]*lines)\n",
    "\n",
    "test_pos_ids = dict()\n",
    "for col in test_textprec_dic:\n",
    "    lines, cols = test_textprec_dic[col].shape\n",
    "    test_pos_ids[col] = np.array([list(range(cols))]*lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token type ids\n",
    "train_token_ids = dict()\n",
    "for col in train_textprec_dic:\n",
    "    lines, cols = train_textprec_dic[col].shape\n",
    "    train_token_ids[col] = np.array([[0]*cols]*lines)\n",
    "\n",
    "test_token_ids = dict()\n",
    "for col in test_textprec_dic:\n",
    "    lines, cols = test_textprec_dic[col].shape\n",
    "    test_token_ids[col] = np.array([[0]*cols]*lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = \"creative_id\"\n",
    "id2 = \"ad_id\"\n",
    "id3 = \"advertiser_id\"\n",
    "id4 = \"product_id\"\n",
    "id5 = \"industry\"\n",
    "# id6 = \"product_category\"\n",
    "TFBS = [id1, id2, id4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My own transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(initializer_range=0.02):\n",
    "    \"\"\"Creates a `tf.initializers.truncated_normal` with the given range.\n",
    "    Args:\n",
    "        initializer_range: float, initializer range for stddev.\n",
    "    Returns:\n",
    "        TruncatedNormal initializer with stddev = `initializer_range`.\n",
    "    \"\"\"\n",
    "    return keras.initializers.TruncatedNormal(stddev=initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_bool_to_primitive(bool_variable, default_tensor_to_true=False):\n",
    "    \"\"\"Function arguments can be inserted as boolean tensor\n",
    "        and bool variables to cope with keras serialization\n",
    "        we need to cast `output_attentions` to correct bool\n",
    "        if it is a tensor\n",
    "\n",
    "    Args:\n",
    "        default_tensor_to_true: bool, if tensor should default to True\n",
    "        in case tensor has no numpy attribute\n",
    "    \"\"\"\n",
    "    # if bool variable is tensor and has numpy value\n",
    "    if tf.is_tensor(bool_variable):\n",
    "        if hasattr(bool_variable, \"numpy\"):\n",
    "            return bool(bool_variable.numpy())\n",
    "        elif default_tensor_to_true:\n",
    "            return True\n",
    "\n",
    "    # else variable is bool\n",
    "    return bool_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"\"\" Gaussian Error Linear Unit.\n",
    "    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n",
    "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
    "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "        Also see https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    cdf = 0.5 * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0)))\n",
    "    return x * cdf\n",
    "\n",
    "\n",
    "def gelu_new(x):\n",
    "    \"\"\"Gaussian Error Linear Unit.\n",
    "    This is a smoother version of the RELU.\n",
    "    Original paper: https://arxiv.org/abs/1606.08415\n",
    "    Args:\n",
    "        x: float Tensor to perform activation.\n",
    "    Returns:\n",
    "        `x` with the GELU activation applied.\n",
    "    \"\"\"\n",
    "    cdf = 0.5 * (1.0 + tf.tanh((np.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3)))))\n",
    "    return x * cdf\n",
    "\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "\n",
    "ACT2FN = {\n",
    "    \"gelu\": tf.keras.layers.Activation(gelu),\n",
    "    \"relu\": tf.keras.activations.relu,\n",
    "    \"swish\": tf.keras.layers.Activation(swish),\n",
    "    \"gelu_new\": tf.keras.layers.Activation(gelu_new),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyTFBertEmbedding(emb_matrix, config):\n",
    "    # input ids embedding\n",
    "    inp_ids = layers.Input(shape=(maxlen,))\n",
    "    inputs_embeds = layers.Embedding(input_dim=len(emb_matrix), output_dim=embed_size, weights=[emb_matrix], trainable=False)(inp_ids)\n",
    "    \n",
    "    # input position Embedding\n",
    "    inp_pos = layers.Input(shape=(maxlen,))\n",
    "    position_embeds = layers.Embedding(input_dim=config.max_position_embeddings, output_dim=embed_size, weights=positional_encoding(config.max_position_embeddings, embed_size), trainable=False)(inp_pos)\n",
    "    \n",
    "    # input token type Embedding\n",
    "    inp_token_type = layers.Input(shape=(maxlen,))\n",
    "    token_type_embeds = layers.Embedding(input_dim=config.type_vocab_size, output_dim=embed_size, embeddings_initializer=get_initializer(config.initializer_range))(inp_token_type)\n",
    "    \n",
    "    embeds = inputs_embeds + position_embeds + token_type_embeds\n",
    "    embeds = layers.LayerNormalization(epsilon=config.layer_norm_eps)(embeds)\n",
    "    embeds = layers.Dropout(config.hidden_dropout_prob)(embeds)\n",
    "    \n",
    "    ret = {\"inputs\": [inp_ids, inp_pos, inp_token_type],\n",
    "           \"embeddings\": embeds\n",
    "          }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoder include encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        assert config.hidden_size % config.num_attention_heads == 0\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = tf.keras.layers.Dense(\n",
    "            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range)\n",
    "        )\n",
    "        self.key = tf.keras.layers.Dense(\n",
    "            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range)\n",
    "        )\n",
    "        self.value = tf.keras.layers.Dense(\n",
    "            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range)\n",
    "        )\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.attention_head_size))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        hidden_states, attention_mask, head_mask, output_attentions = inputs\n",
    "\n",
    "        batch_size = shape_list(hidden_states)[0]\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer, batch_size)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer, batch_size)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = tf.matmul(\n",
    "            query_layer, key_layer, transpose_b=True\n",
    "        )  # (batch size, num_heads, seq_len_q, seq_len_k)\n",
    "        dk = tf.cast(shape_list(key_layer)[-1], tf.float32)  # scale attention_scores\n",
    "        attention_scores = attention_scores / tf.math.sqrt(dk)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in TFBertModel call() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = tf.nn.softmax(attention_scores, axis=-1)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs, training=training)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = tf.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = tf.transpose(context_layer, perm=[0, 2, 1, 3])\n",
    "        context_layer = tf.reshape(\n",
    "            context_layer, (batch_size, -1, self.all_head_size)\n",
    "        )  # (batch_size, seq_len_q, all_head_size)\n",
    "\n",
    "        outputs = (\n",
    "            (context_layer, attention_probs) if cast_bool_to_primitive(output_attentions) is True else (context_layer,)\n",
    "        )\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyTFBertAttention(inputs, config, training=True):\n",
    "    input_tensor, attention_mask, head_mask, output_attentions = inputs\n",
    "    self_attention = TFBertSelfAttention(config)\n",
    "    dense_output = TFBertSelfOutput(config)\n",
    "    \n",
    "    self_outputs = self_attention(\n",
    "        [input_tensor, attention_mask, head_mask, output_attentions], training=training\n",
    "    )\n",
    "    attention_output = dense_output([self_outputs[0], input_tensor], training=training)\n",
    "    outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyTFBertLayer(inputs, config, training=True):\n",
    "    hidden_states, attention_mask, head_mask, output_attentions = inputs\n",
    "    \n",
    "    intermediate = TFBertIntermediate(config)\n",
    "    bert_output = TFBertOutput(config)\n",
    "    \n",
    "    attention_outputs = MyTFBertAttention([hidden_states, attention_mask, head_mask, output_attentions], config, training=training)\n",
    "    attention_output = attention_outputs[0]\n",
    "    \n",
    "    intermediate_output = intermediate(attention_output)\n",
    "    layer_output = bert_output([intermediate_output, attention_output], training=training)\n",
    "    outputs = (layer_output,) + attention_outputs[1:]  # add attentions if we output them\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyTFBertEncoder(inputs, config, training=True):\n",
    "    hidden_states, attention_mask, head_mask, output_attentions = inputs\n",
    "    output_hidden_states = config.output_hidden_states\n",
    "    all_hidden_states = ()\n",
    "    all_attentions = ()\n",
    "    \n",
    "    for i in range(config.num_hidden_layers):\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        layer_outputs = MyTFBertLayer([hidden_states, attention_mask, head_mask[i], output_attentions], config, training=training)\n",
    "        hidden_states = layer_outputs[0]\n",
    "\n",
    "        if cast_bool_to_primitive(output_attentions) is True:\n",
    "            all_attentions = all_attentions + (layer_outputs[1],)\n",
    "\n",
    "    # Add last layer\n",
    "    if output_hidden_states:\n",
    "        all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "    outputs = (hidden_states,)\n",
    "    if output_hidden_states:\n",
    "        outputs = outputs + (all_hidden_states,)\n",
    "    if cast_bool_to_primitive(output_attentions) is True:\n",
    "        outputs = outputs + (all_attentions,)\n",
    "    return outputs  # outputs, (hidden states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyBertModel(pre_embeds):\n",
    "    config = BertConfig(\n",
    "        intermediate_size=128,\n",
    "        max_position_embeddings=maxlen,\n",
    "        num_attention_heads=4,\n",
    "        num_hidden_layers=2,\n",
    "        type_vocab_size=1,\n",
    "        vocab_size=len(pre_embeds),\n",
    "        hidden_size=embed_size\n",
    "    )\n",
    "    retbyemb = MyTFBertEmbedding(pre_embeds, config)\n",
    "    \n",
    "    inps = retbyemb[\"inputs\"]\n",
    "    embeds = retbyemb[\"embeddings\"]\n",
    "    \n",
    "    inp_atten_mask = layers.Input(shape=(1, 1, maxlen))\n",
    "    head_mask = [None] * config.num_hidden_layers\n",
    "    inputs = embeds, inp_atten_mask, head_mask, config.output_attentions\n",
    "    outputs = MyTFBertEncoder(inputs, config)\n",
    "    \n",
    "    ret = {\"inputs\": inps+[inp_atten_mask],\n",
    "           \"layers\": outputs\n",
    "          }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_1 = MyBertModel(emb_matrix_dic[id1])\n",
    "inps_1 = ret_1[\"inputs\"]\n",
    "bert_layer_1 = ret_1[\"layers\"]\n",
    "\n",
    "ret_2 = MyBertModel(emb_matrix_dic[id2])\n",
    "inps_2 = ret_2[\"inputs\"]\n",
    "bert_layer_2 = ret_2[\"layers\"]\n",
    "\n",
    "ret_3 = MyBertModel(emb_matrix_dic[id3])\n",
    "inps_3 = ret_3[\"inputs\"]\n",
    "bert_layer_3 = ret_3[\"layers\"]\n",
    "\n",
    "# ret_4 = MyBertModel(emb_matrix_dic[id4])\n",
    "# inps_4 = ret_4[\"inputs\"]\n",
    "# bert_layer_4 = ret_4[\"layers\"]\n",
    "\n",
    "# ret_5 = MyBertModel(emb_matrix_dic[id5])\n",
    "# inps_5 = ret_5[\"inputs\"]\n",
    "# bert_layer_5 = ret_5[\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_1 = layers.LSTM(128, return_sequences=True)(bert_layer_1[0])\n",
    "bilstm_2 = layers.LSTM(128, return_sequences=True)(bert_layer_2[0])\n",
    "bilstm_3 = layers.LSTM(128, return_sequences=True)(bert_layer_3[0])\n",
    "# bilstm_4 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(bert_layer_4[0])\n",
    "# bilstm_5 = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(bert_layer_5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_1 = layers.GlobalMaxPooling1D()(bilstm_1)\n",
    "maxpool_2 = layers.GlobalMaxPooling1D()(bilstm_2)\n",
    "maxpool_3 = layers.GlobalMaxPooling1D()(bilstm_3)\n",
    "# maxpool_4 = layers.GlobalMaxPooling1D()(bilstm_4)\n",
    "# maxpool_5 = layers.GlobalMaxPooling1D()(bilstm_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_list = [maxpool_1, maxpool_2, maxpool_3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = layers.concatenate(conc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conc = keras.layers.Dense(256)(conc)\n",
    "conc = keras.layers.BatchNormalization()(conc)\n",
    "conc = keras.layers.PReLU()(conc)\n",
    "conc = keras.layers.Dropout(0.2)(conc)\n",
    "\n",
    "conc = keras.layers.Dense(128)(conc)\n",
    "conc = keras.layers.BatchNormalization()(conc)\n",
    "\n",
    "out_age = keras.layers.Dense(10, activation=\"softmax\", name=\"out_age\")(conc)\n",
    "out_gender = keras.layers.Dense(1, activation=\"sigmoid\", name=\"out_gender\")(conc)\n",
    "\n",
    "model = keras.Model(inputs=[inps_1, inps_2, inps_3], outputs=[out_age, out_gender])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss={\"out_age\": \"categorical_crossentropy\", \"out_gender\": \"binary_crossentropy\"},\n",
    "    loss_weights={\"out_age\": 1, \"out_gender\": 1},\n",
    "    optimizer=tfa.optimizers.RectifiedAdam(lr=0.001), \n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, pos, token, mask\n",
    "train_set = list()\n",
    "test_set = list()\n",
    "for col in TFBS:\n",
    "    train_set += [train_textprec_dic[col], train_pos_ids[col], train_token_ids[col], train_mask.reshape(-1,1,1,maxlen)]\n",
    "    test_set += [test_textprec_dic[col], test_pos_ids[col], test_token_ids[col], test_mask.reshape(-1,1,1,maxlen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = [train_txtprec, train_txtprec, train_mask, train_mask.reshape(-1,1,1,maxlen)]\n",
    "# test_set = [test_txtprec, test_txtprec, train_mask, test_mask.reshape(-1,1,1,maxlen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_age = keras.utils.to_categorical(train_user[\"age\"]-1)\n",
    "train_y_gender = (train_user[\"gender\"]-1).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_set = train_test_split(*train_set, train_y_age, train_y_gender, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tr = res_set[:-4:2]\n",
    "train_X_val = res_set[1:-4:2]\n",
    "train_y_tr_age = res_set[-4]\n",
    "train_y_val_age = res_set[-3]\n",
    "\n",
    "train_y_tr_gender = res_set[-2]\n",
    "train_y_val_gender = res_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsp = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "filepath = f\"{UMDIR}/weights_improvement_fold.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [elsp,]  # checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_X_tr, [train_y_tr_age, train_y_tr_gender], validation_data=(train_X_val, [train_y_val_age, train_y_val_gender]), epochs=3, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(f\"{UMDIR}/3inp_bert_4heads2layers_model_emb{embed_size}_seq{maxlen}.h5\")\n",
    "# model = keras.models.load_model(f\"{UMDIR}/5inp_2bilstm_model_128.h5\")\n",
    "model._layers = [\n",
    "    layer for layer in model._layers if isinstance(layer, keras.layers.Layer)\n",
    "]\n",
    "keras.utils.plot_model(model, to_file=f\"{UMDIR}/3inp_bert_4heads2layers_model_emb{embed_size}_seq{maxlen}.png\", show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1411/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Transfomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position encoding\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, emded_dim, embedding_matrix):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=len(embedding_matrix), output_dim=emded_dim, weights=[embedding_matrix], trainable=False)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emded_dim, weights=positional_encoding(maxlen, embed_size), trainable=False)\n",
    "        self.emded_dim = emded_dim\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 128\n",
    "\n",
    "num_enc = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = \"creative_id\"\n",
    "id2 = \"ad_id\"\n",
    "id3 = \"product_id\"\n",
    "\n",
    "# id1 = \"creative_id\"\n",
    "# id2 = \"ad_id\"\n",
    "# id3 = \"advertiser_id\"\n",
    "# id4 = \"product_id\"\n",
    "# id5 = \"industry\"\n",
    "# # id6 = \"product_category\"\n",
    "# TFBS = [id1, id2, id4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1 = layers.Input(shape=(maxlen,))\n",
    "inp_2 = layers.Input(shape=(maxlen,))\n",
    "inp_3 = layers.Input(shape=(maxlen,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_1 = TokenAndPositionEmbedding(maxlen, embed_size, emb_matrix_dic[id1])(inp_1)\n",
    "embed_2 = TokenAndPositionEmbedding(maxlen, embed_size, emb_matrix_dic[id1])(inp_2)\n",
    "embed_3 = TokenAndPositionEmbedding(maxlen, embed_size, emb_matrix_dic[id1])(inp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_1 = list()\n",
    "transf_2 = list()\n",
    "transf_3 = list()\n",
    "for i in range(num_enc):\n",
    "    if i == 0:\n",
    "        transf_1.append(TransformerBlock(embed_size, num_heads, ff_dim)(embed_1))\n",
    "        transf_2.append(TransformerBlock(embed_size, num_heads, ff_dim)(embed_2))\n",
    "        transf_3.append(TransformerBlock(embed_size, num_heads, ff_dim)(embed_3))\n",
    "    else:\n",
    "        transf_1.append(TransformerBlock(embed_size, num_heads, ff_dim)(transf_1[-1]))\n",
    "        transf_2.append(TransformerBlock(embed_size, num_heads, ff_dim)(transf_2[-1]))\n",
    "        transf_3.append(TransformerBlock(embed_size, num_heads, ff_dim)(transf_3[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilstm_1 = list()\n",
    "# bilstm_2 = list()\n",
    "# bilstm_3 = list()\n",
    "# for i in range(num_enc):\n",
    "#     bilstm_1.append(layers.LSTM(128, return_sequences=True)(transf_1[i]))\n",
    "#     bilstm_2.append(layers.LSTM(128, return_sequences=True)(transf_2[i]))\n",
    "#     bilstm_3.append(layers.LSTM(128, return_sequences=True)(transf_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool_1 = list()\n",
    "avgpool_2 = list()\n",
    "avgpool_3 = list()\n",
    "for i in range(num_enc):\n",
    "    avgpool_1.append(layers.GlobalMaxPooling1D()(transf_1[i]))\n",
    "    avgpool_2.append(layers.GlobalMaxPooling1D()(transf_2[i]))\n",
    "    avgpool_3.append(layers.GlobalMaxPooling1D()(transf_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transf_1 = TransformerBlock(embed_size, num_heads, ff_dim)(embed_1)\n",
    "# transf_2 = TransformerBlock(embed_size, num_heads, ff_dim)(embed_2)\n",
    "# transf_3 = TransformerBlock(embed_size, num_heads, ff_dim)(embed_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgpool_1 = layers.GlobalAveragePooling1D()(transf_1)\n",
    "# avgpool_2 = layers.GlobalAveragePooling1D()(transf_2)\n",
    "# avgpool_3 = layers.GlobalAveragePooling1D()(transf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conc = layers.concatenate([avgpool_1, avgpool_2, avgpool_3])\n",
    "conc = layers.concatenate(avgpool_1+avgpool_2+avgpool_3)\n",
    "\n",
    "conc = layers.Dense(256)(conc)\n",
    "conc = layers.BatchNormalization()(conc)\n",
    "conc = layers.PReLU()(conc)\n",
    "conc = layers.Dropout(0.2)(conc)\n",
    "\n",
    "conc = layers.Dense(128)(conc)\n",
    "conc = layers.BatchNormalization()(conc)\n",
    "\n",
    "out_age = layers.Dense(10, activation=\"softmax\", name=\"out_age\")(conc)\n",
    "out_gender = layers.Dense(1, activation=\"sigmoid\", name=\"out_gender\")(conc)\n",
    "\n",
    "model = keras.Model(inputs=[inp_1, inp_2, inp_3,], outputs=[out_age, out_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss={\"out_age\": \"categorical_crossentropy\", \"out_gender\": \"binary_crossentropy\"},\n",
    "    loss_weights={\"out_age\": 1, \"out_gender\": 1},\n",
    "    optimizer=tfa.optimizers.RectifiedAdam(learning_rate=0.01), \n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [train_textprec_dic[id1], train_textprec_dic[id2], train_textprec_dic[id3]]\n",
    "test_set = [test_textprec_dic[id1], test_textprec_dic[id2], test_textprec_dic[id3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_age = keras.utils.to_categorical(train_user[\"age\"]-1)\n",
    "train_y_gender = (train_user[\"gender\"]-1).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_set = train_test_split(*train_set, train_y_age, train_y_gender, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tr = res_set[:-4:2]\n",
    "train_X_val = res_set[1:-4:2]\n",
    "train_y_tr_age = res_set[-4]\n",
    "train_y_val_age = res_set[-3]\n",
    "\n",
    "train_y_tr_gender = res_set[-2]\n",
    "train_y_val_gender = res_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsp = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "# filepath = f\"{UMDIR}/weights_improvement_fold.hdf5\"\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [elsp] #, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_X_tr, [train_y_tr_age, train_y_tr_gender], validation_data=(train_X_val, [train_y_val_age, train_y_val_gender]), epochs=5, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(f\"{UMDIR}/3inp_2bilstm_model_emb{embed_size}_seq{maxlen}.h5\")\n",
    "# model = keras.models.load_model(f\"{UMDIR}/5inp_2bilstm_model_128.h5\")\n",
    "model._layers = [\n",
    "    layer for layer in model._layers if isinstance(layer, keras.layers.Layer)\n",
    "]\n",
    "keras.utils.plot_model(model, to_file=f\"{UMDIR}/3inp_transformer_4heads2layers_model_emb{embed_size}_seq{maxlen}.png\", show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Search weights\n",
    "\n",
    "# class_num=10\n",
    "\n",
    "# weights = [1.0]*class_num\n",
    "\n",
    "\n",
    "\n",
    "# def search_weight(valid_y, raw_prob, init_weight=[1.0]*class_num, step=0.001):\n",
    "\n",
    "#     weight = init_weight.copy()\n",
    "\n",
    "#     f_best = accuracy_score(y_true=valid_y, y_pred=raw_prob.argmax(\n",
    "\n",
    "#         axis=1))\n",
    "\n",
    "#     flag_score = 0\n",
    "\n",
    "#     round_num = 1\n",
    "\n",
    "#     while(flag_score != f_best):\n",
    "\n",
    "#         print(\"round: \", round_num)\n",
    "\n",
    "#         round_num += 1\n",
    "\n",
    "#         flag_score = f_best\n",
    "\n",
    "#         for c in range(class_num):\n",
    "\n",
    "#             for n_w in range(0, 2000,10):\n",
    "\n",
    "#                 num = n_w * step\n",
    "\n",
    "#                 new_weight = weight.copy()\n",
    "\n",
    "#                 new_weight[c] = num\n",
    "\n",
    "\n",
    "\n",
    "#                 prob_df = raw_prob.copy()\n",
    "\n",
    "#                 prob_df = prob_df * np.array(new_weight)\n",
    "\n",
    "\n",
    "\n",
    "#                 f = accuracy_score(y_true=valid_y, y_pred=prob_df.argmax(\n",
    "\n",
    "#                     axis=1))\n",
    "\n",
    "#                 if f > f_best:\n",
    "\n",
    "#                     weight = new_weight.copy()\n",
    "\n",
    "#                     f_best = f\n",
    "\n",
    "#                     print(f)\n",
    "\n",
    "#     return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_user[[UID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res[\"predicted_age\"] = np.argmax(predicted_age, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_gender\"] = (predicted_gender >= 0.5).astype(int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_suffix = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(int(time.time())))\n",
    "res.to_csv(f\"{RESDIR}/res-{res_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cent result to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ti import session\n",
    "ti_session = session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ti_session.upload_data(path=f\"{RESDIR}/res-20200515004850.csv\", bucket=\"etveritas-1252104022\", key_prefix=RESDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "767px",
    "left": "28px",
    "top": "132px",
    "width": "355px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
