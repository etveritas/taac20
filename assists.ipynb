{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if used pip install package\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install wget\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import wget\n",
    "import time\n",
    "import tarfile\n",
    "import zipfile\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "import gensim\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDIR = \"data\"\n",
    "UDDIR = \"user_data\"\n",
    "UFEDIR = \"user_data/feat_data_v04\"\n",
    "UMDIR = \"user_data/model_data\"\n",
    "RESDIR = \"prediction_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UID = \"user_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (Only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fname = wget.download(\"https://tesla-ap-shanghai-1256322946.cos.ap-shanghai.myqcloud.com/cephfs/tesla_common/deeplearning/dataset/algo_contest/train_preliminary.zip\", out=DDIR)\n",
    "# test_fname = wget.download(\"https://tesla-ap-shanghai-1256322946.cos.ap-shanghai.myqcloud.com/cephfs/tesla_common/deeplearning/dataset/algo_contest/test.zip\", out=DDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myunzip(filename):\n",
    "#     zFile = zipfile.ZipFile(filename, \"r\")\n",
    "#     for fileM in zFile.namelist(): \n",
    "#         zFile.extract(fileM, DDIR)\n",
    "#         print(fileM)\n",
    "#     zFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myunzip(train_fname)\n",
    "# myunzip(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bch_rencol(values, prefix=\"\", suffix=\"\"):\n",
    "    return list(map(lambda x: f\"{prefix}\"+\"_\".join(list(map(lambda y: str(y), x)))+f\"{suffix}\" \n",
    "                    if hasattr(x, \"__iter__\") and not isinstance(x, str) \n",
    "                    else f\"{prefix}\"+str(x)+f\"{suffix}\", values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mynunique(values):\n",
    "    return values.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getidxmax(x):\n",
    "    return x.idxmax()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for time series\n",
    "def at_len(x):\n",
    "    return len(x)\n",
    "\n",
    "def at_sum(x):\n",
    "    return np.sum(x)\n",
    "\n",
    "def at_max(x):\n",
    "    return np.max(x)\n",
    "\n",
    "def at_min(x):\n",
    "    return np.min(x)\n",
    "\n",
    "def at_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def at_range(x):\n",
    "    return at_max(x) - at_min(x)\n",
    "\n",
    "def at_nunq(x):\n",
    "    return len(set(x))\n",
    "\n",
    "def at_lenDrange(x):\n",
    "    return at_len(x)/(at_range(x)+1)\n",
    "\n",
    "def at_lenDnunq(x):\n",
    "    return at_len(x)/at_nunq(x)\n",
    "\n",
    "def at_percentile(n):\n",
    "    def at_percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    at_percentile_.__name__ = f\"at_percentile_{n}\"\n",
    "    return at_percentile_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP_SET = [\"sum\", \"max\", \"min\", \"mean\", \"std\", getidxmax, \"nunique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration (todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train data\n",
    "train_click_log = pd.read_csv(f\"{DDIR}/train_preliminary/click_log.csv\")\n",
    "train_ad = pd.read_csv(f\"{DDIR}/train_preliminary/ad.csv\")\n",
    "# tag\n",
    "train_user = pd.read_csv(f\"{DDIR}/train_preliminary/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_click_log = pd.read_csv(f\"{DDIR}/test/click_log.csv\")\n",
    "test_ad = pd.read_csv(f\"{DDIR}/test/ad.csv\")\n",
    "test_user = pd.read_csv(f\"{DDIR}/test/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_click_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_click_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad[\"product_id\"] = train_ad[\"product_id\"].replace(\"\\\\N\", -1).astype(int)\n",
    "train_ad[\"industry\"] = train_ad[\"industry\"].replace(\"\\\\N\", -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ad[\"product_id\"] = test_ad[\"product_id\"].replace(\"\\\\N\", -1).astype(int)\n",
    "test_ad[\"industry\"] = test_ad[\"industry\"].replace(\"\\\\N\", -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creative id in train (creative id is unique in train_ad)\n",
    "len(train_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creative id in test (creative id is unique in test_ad)\n",
    "len(test_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the same creative_id in train and test have same ad info\n",
    "insect1d = np.intersect1d(train_click_log.creative_id.unique(), test_click_log.creative_id.unique())\n",
    "print(\"Same creative id: \", insect1d.shape)\n",
    "print(\"Diff number: \", np.sum(train_ad[train_ad.creative_id.isin(insect1d)].values != test_ad[test_ad.creative_id.isin(insect1d)].values))\n",
    "# checked: they all have same ad info (result is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether click and ad have diff creative_id\n",
    "print(\"Diff list: \", np.setdiff1d(train_click_log.creative_id.unique(), train_ad.creative_id))\n",
    "print(\"Diff list: \", np.setdiff1d(train_ad.creative_id, train_click_log.creative_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether click and ad have diff creative_id\n",
    "print(\"Diff list: \", np.setdiff1d(test_click_log.creative_id.unique(), test_ad.creative_id))\n",
    "print(\"Diff list: \", np.setdiff1d(test_ad.creative_id, test_click_log.creative_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click time\n",
    "sns.lineplot(x=train_click_log.time.value_counts().index, y=train_click_log.time.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=test_click_log.time.value_counts().index, y=test_click_log.time.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_grouped = data.groupby(data.index)\n",
    "# results = Parallel(n_jobs=8)(delayed(key_func)(group) for name, group in data_grouped)\n",
    "# data = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Edit\n",
    "# train_click_log.sort_values(by=\"time\", inplace=True)\n",
    "# test_click_log.sort_values(by=\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_train = pd.merge(train_click_log, train_ad, how=\"left\", on=\"creative_id\")\n",
    "tol_test = pd.merge(test_click_log, test_ad, how=\"left\", on=\"creative_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_click_log, train_ad\n",
    "del test_click_log, test_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tol_data = pd.concat([tol_train, tol_test]).sort_values(by=\"time\").reset_index(drop=True)\n",
    "# pd.DataFrame(np.sort(tol_test[UID].unique()), columns=[UID]).to_csv(f\"{DDIR}/test/user.csv\", index=False)\n",
    "# tol_data.to_csv(f\"{DDIR}/tol_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = tol_train.groupby([UID], sort=False)[[\"creative_id\", \"ad_id\"]].agg(lambda x: [f\"word_{y}\" for y in x])\n",
    "# tmp.columns = bch_rencol(tmp.columns)\n",
    "# tmp.to_pickle(f\"{UDDIR}/imd/train_cidnaid_seq.pkl\")\n",
    "# tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = tol_test.groupby([UID], sort=False)[[\"creative_id\", \"ad_id\"]].agg(lambda x: [f\"word_{y}\" for y in x])\n",
    "# tmp.columns = bch_rencol(tmp.columns)\n",
    "# tmp.to_pickle(f\"{UDDIR}/imd/test_cidnaid_seq.pkl\")\n",
    "# tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cidnaid_seq = pd.read_pickle(f\"{UDDIR}/imd/train_cidnaid_seq.pkl\")\n",
    "test_cidnaid_seq = pd.read_pickle(f\"{UDDIR}/imd/test_cidnaid_seq.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_cidnaid_seq = pd.concat([train_cidnaid_seq, test_cidnaid_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_cidnaid_seq[\"creative_id\"] = tol_cidnaid_seq[\"creative_id\"].apply(lambda x: \" \".join(x))\n",
    "tol_cidnaid_seq[\"ad_id\"] = tol_cidnaid_seq[\"ad_id\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_cidnaid_seq, test_cidnaid_seq\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_enc = TfidfVectorizer(ngram_range=(1, 2), max_features=2000000, max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = tfidf_enc.fit_transform(tol_cidnaid_seq[\"ad_id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.sparse.save_npz(f\"{UDDIR}/imd/sparse_ad_id.npz\", tfidf_vec)\n",
    "# tmp = scipy.sparse.load_npz(f\"{UDDIR}/imd/sparse_creative_id.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vec = scipy.sparse.load_npz(f\"{UDDIR}/imd/sparse_ad_id.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpt = 64\n",
    "svd_enc = TruncatedSVD(n_components=ncpt, n_iter=20, random_state=2020)\n",
    "mode_svd = svd_enc.fit_transform(tfidf_vec)\n",
    "mode_svd = pd.DataFrame(mode_svd)\n",
    "mode_svd.columns = ['svd_ad_id_{}'.format(i) for i in range(ncpt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_svd.index = tol_cidnaid_seq.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_svd.to_pickle(f\"{UFEDIR}/ad_id_tfidf_svd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cidnaid_seq = pd.read_pickle(f\"{UDDIR}/imd/train_cidnaid_seq.pkl\")\n",
    "test_cidnaid_seq = pd.read_pickle(f\"{UDDIR}/imd/test_cidnaid_seq.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_cidnaid_seq = pd.concat([train_cidnaid_seq, test_cidnaid_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=tol_cidnaid_seq[\"ad_id\"], size=vector_size, window=5, min_count=5, workers=12, sg=0, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{UMDIR}/w2v_ad_id.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_id_w2v = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(tol_cidnaid_seq[\"ad_id\"]):\n",
    "    tmp = np.zeros(vector_size)\n",
    "    for wd in col:\n",
    "        if wd in model:\n",
    "            tmp += model[wd]\n",
    "    ad_id_w2v.append(list(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ad_id_w2v = pd.DataFrame(ad_id_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ad_id_w2v.index = tol_cidnaid_seq.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ad_id_w2v.to_pickle(f\"{UFEDIR}/cum_ad_id_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv = model.wv\n",
    "# vocab_list = wv.index2word\n",
    "# word_idx_dict = {}\n",
    "# for idx, word in enumerate(vocab_list):\n",
    "#     word_idx_dict[word] = idx\n",
    "    \n",
    "# vectors_arr = wv.vectors\n",
    "# vectors_arr = np.concatenate((np.zeros(vector_size)[np.newaxis, :], vectors_arr), axis=0)#第0位置的vector为'unk'的vector\n",
    "\n",
    "# f_wordidx = open(feature_path + 'word_seg_word_idx_dict.pkl', 'wb')\n",
    "# f_vectors = open(feature_path + 'word_seg_vectors_arr.pkl', 'wb')\n",
    "# pickle.dump(word_idx_dict, f_wordidx)\n",
    "# pickle.dump(vectors_arr, f_vectors)\n",
    "# f_wordidx.close()\n",
    "# f_vectors.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creative id map (use k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ucid = pd.merge(tol_train[[UID, \"creative_id\"]], train_user, how=\"left\", on=UID)\n",
    "test_ucid = tol_test[[UID, \"creative_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=False, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_cid_map_dic = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_train_ucid = pd.DataFrame()\n",
    "re_test_ucid = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfn = 0\n",
    "for tr_idx, val_idx in kfold.split(train_ucid):\n",
    "    tr_ucid, val_ucid = train_ucid.iloc[tr_idx], train_ucid.iloc[val_idx]\n",
    "    kf_cid_map = tr_ucid.groupby([\"creative_id\"])[[\"age\", \"gender\"]].agg([\"mean\"])\n",
    "    kf_cid_map.columns = bch_rencol(kf_cid_map.columns, prefix=\"creative_id_\")\n",
    "    kf_cid_map.drop(np.setdiff1d(kf_cid_map.index.unique(), test_ucid[\"creative_id\"].unique()), inplace=True)\n",
    "    kf_cid_map_dic[kfn] = copy.deepcopy(kf_cid_map)\n",
    "    val_ucid = pd.merge(val_ucid, kf_cid_map, how=\"left\", on=\"creative_id\")\n",
    "    re_train_ucid = pd.concat([re_train_ucid, val_ucid])\n",
    "    kfn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfn = 0\n",
    "for _, val_idx in kfold.split(test_ucid):\n",
    "    val_ucid = test_ucid.iloc[val_idx]\n",
    "    val_ucid = pd.merge(val_ucid, kf_cid_map_dic[kfn], how=\"left\", on=\"creative_id\")\n",
    "    re_test_ucid = pd.concat([re_test_ucid, val_ucid])\n",
    "    kfn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ucid) == len(re_train_ucid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ucid) == len(re_test_ucid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = re_train_ucid.groupby([UID])[\"creative_id_age_mean\", \"creative_id_gender_mean\"].agg([\"sum\", \"max\", \"mean\", \"min\", \"std\"])\n",
    "tmp.columns = bch_rencol(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/train_o1_cid_map.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = re_test_ucid.groupby([UID])[\"creative_id_age_mean\", \"creative_id_gender_mean\"].agg([\"sum\", \"max\", \"mean\", \"min\", \"std\"])\n",
    "tmp.columns = bch_rencol(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/test_o1_cid_map.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Click log (Order 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_dic = {\n",
    "        UID: [\"count\"], \n",
    "        \"click_times\": [\"sum\", \"max\", \"mean\", \"std\", at_nunq, at_range, at_lenDnunq, at_lenDrange, at_percentile(.75), at_percentile(.25)],\n",
    "        \"time\": [\"nunique\", \"mean\", \"max\", \"min\", at_range, at_lenDnunq, at_lenDrange, at_percentile(.75), at_percentile(.25)],\n",
    "        \"creative_id\": [\"nunique\", at_lenDnunq],\n",
    "        \"ad_id\": [\"nunique\", at_lenDnunq],\n",
    "        \"product_id\": [\"nunique\", at_lenDnunq],\n",
    "        \"product_category\": [\"nunique\", at_lenDnunq],\n",
    "        \"advertiser_id\": [\"nunique\", at_lenDnunq],\n",
    "        \"industry\": [\"nunique\", at_lenDnunq],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ops_dic:\n",
    "    tmp = tol_train.groupby([UID], sort=False)[[col]].agg(ops_dic[col])\n",
    "    tmp.columns = bch_rencol(tmp.columns)\n",
    "    tmp.to_pickle(f\"{UFEDIR}/train_o1_{col}.pkl\")\n",
    "    tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ops_dic:\n",
    "    tmp = tol_test.groupby([UID], sort=False)[[col]].agg(ops_dic[col])\n",
    "    tmp.columns = bch_rencol(tmp.columns)\n",
    "    tmp.to_pickle(f\"{UFEDIR}/test_o1_{col}.pkl\")\n",
    "    tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tol_train.groupby([UID, \"time\"], sort=False)[[\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]].agg([\"nunique\", at_lenDnunq])\\\n",
    ".groupby([UID]).agg([\"sum\", \"max\", \"min\", \"mean\", \"std\"])\n",
    "tmp.columns = bch_rencol(tmp.columns)\n",
    "tmp.to_pickle(f\"{UFEDIR}/train_o1_time2columns.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tol_test.groupby([UID, \"time\"], sort=False)[[\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]].agg([\"nunique\", at_lenDnunq])\\\n",
    ".groupby([UID]).agg([\"sum\", \"max\", \"min\", \"mean\", \"std\"])\n",
    "tmp.columns = bch_rencol(tmp.columns)\n",
    "tmp.to_pickle(f\"{UFEDIR}/test_o1_time2columns.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_pickle(f\"{UFEDIR}/test_o1_time2columns.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = bch_rencol(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/test_o1_time2columns.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # before features v03\n",
    "# # for train\n",
    "# tmp = tol_train.groupby([UID], sort=False).agg(\n",
    "#     {\n",
    "#         UID: [\"count\"], \n",
    "#         \"click_times\": [\"sum\", \"max\", \"mean\", \"std\"],\n",
    "#         \"time\": [\"nunique\", \"mean\", \"max\", \"min\"],\n",
    "#         \"creative_id\": [\"nunique\"],\n",
    "#         \"ad_id\": [\"nunique\"],\n",
    "#         \"product_id\": [\"nunique\"],\n",
    "#         \"product_category\": [\"nunique\"],\n",
    "#         \"advertiser_id\": [\"nunique\"],\n",
    "#         \"industry\": [\"nunique\"],\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # before features v03\n",
    "# tmp.columns = bch_rencol(tmp.columns)\n",
    "# tmp.to_pickle(f\"{UFEDIR}/train_o1.pkl\")\n",
    "# tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # before features v03\n",
    "# # for test\n",
    "# tmp = tol_test.groupby([UID], sort=False).agg(\n",
    "#     {\n",
    "#         UID: [\"count\"], \n",
    "#         \"click_times\": [\"sum\", \"max\", \"mean\", \"std\"],\n",
    "#         \"time\": [\"nunique\", \"mean\", \"max\", \"min\"],\n",
    "#         \"creative_id\": [\"nunique\"],\n",
    "#         \"ad_id\": [\"nunique\"],\n",
    "#         \"product_id\": [\"nunique\"],\n",
    "#         \"product_category\": [\"nunique\"],\n",
    "#         \"advertiser_id\": [\"nunique\"],\n",
    "#         \"industry\": [\"nunique\"],\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # before features v03\n",
    "# tmp.columns = bch_rencol(tmp.columns)\n",
    "# tmp.to_pickle(f\"{UFEDIR}/test_o1.pkl\")\n",
    "# tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Click log (Order 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2_ops_dic = {\n",
    "    \"click_times\": [\"sum\", \"max\", \"mean\", \"std\", at_nunq, at_range, at_lenDnunq, at_lenDrange, at_percentile(.75), at_percentile(.25)],\n",
    "    \"time\": [\"nunique\", \"mean\", \"max\", \"min\", at_range, at_lenDnunq, at_lenDrange, at_percentile(.75), at_percentile(.25)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_cols = [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature v03\n",
    "for col in hold_cols:\n",
    "    tmp = tol_train.groupby([UID, col], sort=False)[[col]].agg([\"count\"]).groupby([UID]).agg(OP_SET)\n",
    "    tmp.columns = bch_rencol(tmp.columns)\n",
    "    tmp.to_pickle(f\"{UFEDIR}/train_o2_{col}2{col}.pkl\")\n",
    "    tmp = None\n",
    "    for ocol in o2_ops_dic:\n",
    "        tmp = tol_train.groupby([UID, col], sort=False)[[ocol]].agg(o2_ops_dic[ocol]).groupby([UID]).agg([\"sum\", \"max\", \"min\", \"mean\", \"std\"])\n",
    "        tmp.columns = bch_rencol(tmp.columns)\n",
    "        tmp.to_pickle(f\"{UFEDIR}/train_o2_{col}2{ocol}.pkl\")\n",
    "        tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature v03\n",
    "for col in hold_cols:\n",
    "    tmp = tol_test.groupby([UID, col], sort=False)[[col]].agg([\"count\"]).groupby([UID]).agg(OP_SET)\n",
    "    tmp.columns = bch_rencol(tmp.columns)\n",
    "    tmp.to_pickle(f\"{UFEDIR}/test_o2_{col}2{col}.pkl\")\n",
    "    tmp = None\n",
    "    for ocol in o2_ops_dic:\n",
    "        tmp = tol_test.groupby([UID, col], sort=False)[[ocol]].agg(o2_ops_dic[ocol]).groupby([UID]).agg([\"sum\", \"max\", \"min\", \"mean\", \"std\"])\n",
    "        tmp.columns = bch_rencol(tmp.columns)\n",
    "        tmp.to_pickle(f\"{UFEDIR}/test_o2_{col}2{ocol}.pkl\")\n",
    "        tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # before v03\n",
    "# # train\n",
    "# for col in [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]:\n",
    "#     tmp = tol_train.groupby([UID, col], sort=False)[[col]].agg([\"count\"]).groupby([UID]).agg(OP_SET)\n",
    "#     tmp.columns = bch_rencol(tmp.columns)\n",
    "#     tmp.to_pickle(f\"{UFEDIR}/train_o2_{col}.pkl\")\n",
    "#     tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # before v03\n",
    "# # test\n",
    "# for col in [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]:\n",
    "#     tmp = tol_test.groupby([UID, col], sort=False)[[col]].agg([\"count\"]).groupby([UID]).agg(OP_SET)\n",
    "#     tmp.columns = bch_rencol(tmp.columns)\n",
    "#     tmp.to_pickle(f\"{UFEDIR}/test_o2_{col}.pkl\")\n",
    "#     tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tmp = tol_train.groupby([UID, \"product_category\"], sort=False)[[\"product_category\"]].agg([\"count\"]).unstack().fillna(0)\n",
    "tmp.columns = bch_rencol(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/train_onehot.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tmp = tol_test.groupby([UID, \"product_category\"], sort=False)[[\"product_category\"]].agg([\"count\"]).unstack().fillna(0)\n",
    "tmp.columns = bch_rencol(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/test_onehot.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Windows (Time Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 9\n",
    "tol_bins = pd.cut(pd.concat([tol_train[\"time\"], tol_test[\"time\"]]), bins, labels=range(bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_train[f\"bins{bins}\"] = tol_bins[:len(tol_train)]\n",
    "tol_test[f\"bins{bins}\"] = tol_bins[len(tol_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tmp = tol_train.groupby([UID, f\"bins{bins}\"], sort=False).agg(\n",
    "    {\n",
    "        UID: [\"count\"], \n",
    "        \"click_times\": [\"sum\", \"max\", \"mean\", \"std\"],\n",
    "        \"time\": [\"nunique\", \"mean\", \"max\", \"min\"],\n",
    "        \"creative_id\": [\"nunique\"],\n",
    "        \"ad_id\": [\"nunique\"],\n",
    "        \"product_id\": [\"nunique\"],\n",
    "        \"product_category\": [\"nunique\"],\n",
    "        \"advertiser_id\": [\"nunique\"],\n",
    "        \"industry\": [\"nunique\"],\n",
    "    }\n",
    ").unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = bch_rencol(tmp.columns, prefix=f\"bins{bins}_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/train_bins{bins}_o1.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tmp = tol_test.groupby([UID, f\"bins{bins}\"], sort=False).agg(\n",
    "    {\n",
    "        UID: [\"count\"], \n",
    "        \"click_times\": [\"sum\", \"max\", \"mean\", \"std\"],\n",
    "        \"time\": [\"nunique\", \"mean\", \"max\", \"min\"],\n",
    "        \"creative_id\": [\"nunique\"],\n",
    "        \"ad_id\": [\"nunique\"],\n",
    "        \"product_id\": [\"nunique\"],\n",
    "        \"product_category\": [\"nunique\"],\n",
    "        \"advertiser_id\": [\"nunique\"],\n",
    "        \"industry\": [\"nunique\"],\n",
    "    }\n",
    ").unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = bch_rencol(tmp.columns, prefix=f\"bins{bins}_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_pickle(f\"{UFEDIR}/test_bins{bins}_o1.pkl\")\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for col in [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]:\n",
    "    for i in range(bins):\n",
    "        tmp = tol_train[tol_train[f\"bins{bins}\"] == i].groupby([UID, col], sort=False)[[col]].agg([\"count\"]).groupby([UID]).agg(OP_SET)\n",
    "        tmp.columns = bch_rencol(tmp.columns, prefix=f\"bins{bins}_{i}_\")\n",
    "        tmp.to_pickle(f\"{UFEDIR}/train_bins{bins}_{i}_o2_{col}.pkl\")\n",
    "        tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "for col in [\"creative_id\", \"ad_id\", \"product_id\", \"product_category\", \"advertiser_id\", \"industry\"]:\n",
    "    for i in range(bins):\n",
    "        tmp = tol_test[tol_test[f\"bins{bins}\"] == i].groupby([UID, col], sort=False)[[col]].agg([\"count\"]).groupby([UID]).agg(OP_SET)\n",
    "        tmp.columns = bch_rencol(tmp.columns, prefix=f\"bins{bins}_{i}_\")\n",
    "        tmp.to_pickle(f\"{UFEDIR}/test_bins{bins}_{i}_o2_{col}.pkl\")\n",
    "        tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = pd.read_csv(f\"{DDIR}/train_preliminary/user.csv\")\n",
    "test_user = pd.read_csv(f\"{DDIR}/test/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.DataFrame()\n",
    "test_feat = pd.DataFrame()\n",
    "train_feat[UID] = train_user[UID]\n",
    "test_feat[UID] = test_user[UID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_creative_id_w2v = pd.read_pickle(f\"{UFEDIR}/cum_creative_id_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ad_id_w2v = pd.read_pickle(f\"{UFEDIR}/cum_ad_id_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_id_tfidf_svd = pd.read_pickle(f\"{UFEDIR}/creative_id_tfidf_svd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_id_tfidf_svd = pd.read_pickle(f\"{UFEDIR}/ad_id_tfidf_svd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.merge(train_feat, cum_creative_id_w2v, how=\"left\", on=UID)\n",
    "test_feat = pd.merge(test_feat, cum_creative_id_w2v, how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.merge(train_feat, cum_ad_id_w2v, how=\"left\", on=UID)\n",
    "test_feat = pd.merge(test_feat, cum_ad_id_w2v, how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.merge(train_feat, creative_id_tfidf_svd, how=\"left\", on=UID)\n",
    "test_feat = pd.merge(test_feat, creative_id_tfidf_svd, how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.merge(train_feat, ad_id_tfidf_svd, how=\"left\", on=UID)\n",
    "test_feat = pd.merge(test_feat, ad_id_tfidf_svd, how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_fname = os.listdir(UFEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current filename:  train_o1_cid_map.pkl\n",
      "current filename:  test_o1_cid_map.pkl\n"
     ]
    }
   ],
   "source": [
    "for fname in feat_fname:\n",
    "    if fname.startswith(\"train_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        train_feat = pd.merge(train_feat, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)\n",
    "    elif fname.startswith(\"test_\"):\n",
    "        print(\"current filename: \", fname)\n",
    "        test_feat = pd.merge(test_feat, pd.read_pickle(f\"{UFEDIR}/{fname}\"), how=\"left\", on=UID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make sure feat and user(target) have same order\n",
    "# if true --> sum == 0\n",
    "np.sum(train_feat[UID] != train_user[UID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 395)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 395)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat.to_pickle(f\"{UDDIR}/feat_ing/train_feat_tol_v05.pkl\")\n",
    "# test_feat.to_pickle(f\"{UDDIR}/feat_ing/test_feat_tol_v05.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat = pd.read_pickle(f\"{UDDIR}/feat_ing/train_feat_tol_v02.pkl\")\n",
    "# test_feat = pd.read_pickle(f\"{UDDIR}/feat_ing/test_feat_tol_v02.pkl\")\n",
    "# train_user = pd.read_csv(f\"{DDIR}/train_preliminary/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat.drop([col for col in train_feat.columns if col.find(\"creative_id_gender_\") != -1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feat.drop([col for col in test_feat.columns if col.find(\"creative_id_gender_\") != -1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training&Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_feat_tr, train_feat_val, train_tag_tr, train_tag_val = train_test_split(train_feat, train_user, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.drop(UID, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_tr.drop(UID, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_val.drop(UID, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbds_train_tr_age = lgb.Dataset(train_feat_tr, train_tag_tr[\"age\"]-1)\n",
    "lgbds_train_val_age = lgb.Dataset(train_feat_val, train_tag_val[\"age\"]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_age = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"seed\": 2020,\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_multi_age_off = lgb.train(params_age, lgbds_train_tr_age, num_boost_round=1000, valid_sets=[lgbds_train_val_age], verbose_eval=50, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_age_prob = model_lgb_multi_age_off.predict(train_feat_val, num_iteration=model_lgb_multi_age_off.best_iteration)\n",
    "train_val_age_pred = [list(x).index(max(x))+1 for x in train_val_age_prob]\n",
    "age_acy = accuracy_score(train_val_age_pred, train_tag_val[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbds_train_age = lgb.Dataset(train_feat, train_user[\"age\"]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_age = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"seed\": 2020,\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_multi_age = lgb.train(params_age, lgbds_train_age, num_boost_round=1000, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndt = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(int(time.time())))\n",
    "model_lgb_multi_age.save_model(f\"{UMDIR}/lgb_multi_age_{ndt}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.drop(UID, axis=1, inplace=True)\n",
    "test_feat.drop(UID, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_user[[UID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_age = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"seed\": 2020,\n",
    "    \"n_jobs\": -1,\n",
    "    \"min_child_weight\": 30,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 5,     \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "result_proba = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.638411\n",
      "[100]\tvalid_0's multi_error: 0.629528\n",
      "[150]\tvalid_0's multi_error: 0.624606\n",
      "[200]\tvalid_0's multi_error: 0.621739\n",
      "[250]\tvalid_0's multi_error: 0.619917\n",
      "[300]\tvalid_0's multi_error: 0.618433\n",
      "[350]\tvalid_0's multi_error: 0.617589\n",
      "[400]\tvalid_0's multi_error: 0.617078\n",
      "[450]\tvalid_0's multi_error: 0.616794\n",
      "[500]\tvalid_0's multi_error: 0.616589\n",
      "[550]\tvalid_0's multi_error: 0.616833\n",
      "Early stopping, best iteration is:\n",
      "[491]\tvalid_0's multi_error: 0.616228\n",
      "current validation score:  0.38377222222222224\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.639794\n",
      "[100]\tvalid_0's multi_error: 0.629994\n",
      "[150]\tvalid_0's multi_error: 0.625639\n",
      "[200]\tvalid_0's multi_error: 0.6226\n",
      "[250]\tvalid_0's multi_error: 0.620467\n",
      "[300]\tvalid_0's multi_error: 0.619817\n",
      "[350]\tvalid_0's multi_error: 0.618394\n",
      "[400]\tvalid_0's multi_error: 0.617717\n",
      "[450]\tvalid_0's multi_error: 0.6173\n",
      "[500]\tvalid_0's multi_error: 0.616789\n",
      "[550]\tvalid_0's multi_error: 0.616389\n",
      "[600]\tvalid_0's multi_error: 0.6167\n",
      "[650]\tvalid_0's multi_error: 0.616633\n",
      "Early stopping, best iteration is:\n",
      "[551]\tvalid_0's multi_error: 0.616306\n",
      "current validation score:  0.38369444444444445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.640183\n",
      "[100]\tvalid_0's multi_error: 0.630578\n",
      "[150]\tvalid_0's multi_error: 0.625311\n",
      "[200]\tvalid_0's multi_error: 0.622689\n",
      "[250]\tvalid_0's multi_error: 0.620367\n",
      "[300]\tvalid_0's multi_error: 0.6197\n",
      "[350]\tvalid_0's multi_error: 0.61905\n",
      "[400]\tvalid_0's multi_error: 0.6184\n",
      "[450]\tvalid_0's multi_error: 0.618139\n",
      "[500]\tvalid_0's multi_error: 0.617778\n",
      "[550]\tvalid_0's multi_error: 0.616811\n",
      "[600]\tvalid_0's multi_error: 0.616606\n"
     ]
    }
   ],
   "source": [
    "for tr_idx, val_idx in kfold.split(train_feat, train_user[\"age\"]-1):\n",
    "    tr_x, tr_y, val_x, val_y = train_feat.iloc[tr_idx], train_user[\"age\"].iloc[tr_idx]-1, train_feat.iloc[val_idx], train_user[\"age\"].iloc[val_idx]-1\n",
    "    train_set = lgb.Dataset(tr_x, tr_y)\n",
    "    val_set = lgb.Dataset(val_x, val_y)\n",
    "    lgb_model = lgb.train(params_age, train_set,\n",
    "                          valid_sets=[val_set], early_stopping_rounds=100, num_boost_round=40000, verbose_eval=50)\n",
    "    val_pred = np.argmax(lgb_model.predict(\n",
    "        val_x, num_iteration=lgb_model.best_iteration), axis=1)\n",
    "    val_score = accuracy_score(val_pred, val_y)\n",
    "    result_proba.append(lgb_model.predict(\n",
    "        test_feat, num_iteration=lgb_model.best_iteration))\n",
    "    scores.append(val_score)\n",
    "    print(\"current validation score: \", val_score)\n",
    "print(\"accuracy score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_age = np.argmax(np.mean(result_proba, axis=0), axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_age\"] = predicted_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbds_train_tr_gender = lgb.Dataset(train_feat_tr, train_tag_tr[\"gender\"]-1)\n",
    "lgbds_train_val_gender = lgb.Dataset(train_feat_val, train_tag_val[\"gender\"]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gender = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 2,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"seed\": 2020,\n",
    "    \"n_jobs\": -1,\n",
    "    \"min_child_weight\": 30,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_multi_gender_off = lgb.train(params_gender, lgbds_train_tr_gender, num_boost_round=1000, valid_sets=[lgbds_train_val_gender], verbose_eval=50, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_gender_prob = model_lgb_multi_gender_off.predict(train_feat_val, num_iteration=model_lgb_multi_gender_off.best_iteration)\n",
    "train_val_gender_pred = [list(x).index(max(x))+1 for x in train_val_gender_prob]\n",
    "gender_acy = accuracy_score(train_val_gender_pred, train_tag_val[\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbds_train_gender = lgb.Dataset(train_feat, train_user[\"gender\"]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_multi_gender = lgb.train(params_gender, lgbds_train_gender, num_boost_round=1000, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndt = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(int(time.time())))\n",
    "model_lgb_multi_gender.save_model(f\"{UMDIR}/lgb_multi_gender_{ndt}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gender = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 2,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"seed\": 2020,\n",
    "    \"n_jobs\": -1,\n",
    "    \"min_child_weight\": 30,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_scores = []\n",
    "gender_result_proba = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.0769889\n",
      "[100]\tvalid_0's multi_error: 0.0740056\n",
      "[150]\tvalid_0's multi_error: 0.0725722\n",
      "[200]\tvalid_0's multi_error: 0.0719167\n",
      "[250]\tvalid_0's multi_error: 0.0712667\n",
      "[300]\tvalid_0's multi_error: 0.0709833\n",
      "[350]\tvalid_0's multi_error: 0.07065\n",
      "[400]\tvalid_0's multi_error: 0.0704556\n",
      "[450]\tvalid_0's multi_error: 0.0705111\n",
      "[500]\tvalid_0's multi_error: 0.0702056\n",
      "[550]\tvalid_0's multi_error: 0.0702778\n",
      "[600]\tvalid_0's multi_error: 0.0703556\n",
      "Early stopping, best iteration is:\n",
      "[533]\tvalid_0's multi_error: 0.0700889\n",
      "(180000,)\n",
      "current validation score:  0.9299111111111111\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.0780278\n",
      "[100]\tvalid_0's multi_error: 0.0749444\n",
      "[150]\tvalid_0's multi_error: 0.0738611\n",
      "[200]\tvalid_0's multi_error: 0.0729833\n",
      "[250]\tvalid_0's multi_error: 0.0724833\n",
      "[300]\tvalid_0's multi_error: 0.0722667\n",
      "[350]\tvalid_0's multi_error: 0.0721722\n",
      "[400]\tvalid_0's multi_error: 0.0719389\n",
      "[450]\tvalid_0's multi_error: 0.072\n",
      "[500]\tvalid_0's multi_error: 0.0718778\n",
      "[550]\tvalid_0's multi_error: 0.0719444\n",
      "[600]\tvalid_0's multi_error: 0.0717833\n",
      "[650]\tvalid_0's multi_error: 0.0716056\n",
      "[700]\tvalid_0's multi_error: 0.0715778\n",
      "[750]\tvalid_0's multi_error: 0.0714444\n",
      "[800]\tvalid_0's multi_error: 0.0715\n",
      "[850]\tvalid_0's multi_error: 0.0714389\n",
      "[900]\tvalid_0's multi_error: 0.0714\n",
      "[950]\tvalid_0's multi_error: 0.0712778\n",
      "[1000]\tvalid_0's multi_error: 0.0711056\n",
      "[1050]\tvalid_0's multi_error: 0.0711222\n",
      "[1100]\tvalid_0's multi_error: 0.0711056\n",
      "Early stopping, best iteration is:\n",
      "[1015]\tvalid_0's multi_error: 0.0710556\n",
      "(180000,)\n",
      "current validation score:  0.9289444444444445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.0769889\n",
      "[100]\tvalid_0's multi_error: 0.0738944\n",
      "[150]\tvalid_0's multi_error: 0.0724889\n",
      "[200]\tvalid_0's multi_error: 0.0717111\n",
      "[250]\tvalid_0's multi_error: 0.0712667\n",
      "[300]\tvalid_0's multi_error: 0.0709222\n",
      "[350]\tvalid_0's multi_error: 0.0709667\n",
      "[400]\tvalid_0's multi_error: 0.0706278\n",
      "[450]\tvalid_0's multi_error: 0.0706222\n",
      "[500]\tvalid_0's multi_error: 0.0703778\n",
      "[550]\tvalid_0's multi_error: 0.0703278\n",
      "[600]\tvalid_0's multi_error: 0.07025\n",
      "[650]\tvalid_0's multi_error: 0.0702\n",
      "[700]\tvalid_0's multi_error: 0.0701333\n",
      "[750]\tvalid_0's multi_error: 0.0701111\n",
      "[800]\tvalid_0's multi_error: 0.0701222\n",
      "[850]\tvalid_0's multi_error: 0.0699333\n",
      "[900]\tvalid_0's multi_error: 0.0699611\n",
      "[950]\tvalid_0's multi_error: 0.0700056\n",
      "Early stopping, best iteration is:\n",
      "[869]\tvalid_0's multi_error: 0.0699056\n",
      "(180000,)\n",
      "current validation score:  0.9300944444444444\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.0785556\n",
      "[100]\tvalid_0's multi_error: 0.0755944\n",
      "[150]\tvalid_0's multi_error: 0.0741278\n",
      "[200]\tvalid_0's multi_error: 0.0734722\n",
      "[250]\tvalid_0's multi_error: 0.07285\n",
      "[300]\tvalid_0's multi_error: 0.0724444\n",
      "[350]\tvalid_0's multi_error: 0.0723333\n",
      "[400]\tvalid_0's multi_error: 0.0722167\n",
      "[450]\tvalid_0's multi_error: 0.0720944\n",
      "[500]\tvalid_0's multi_error: 0.0720889\n",
      "[550]\tvalid_0's multi_error: 0.0719889\n",
      "[600]\tvalid_0's multi_error: 0.0718722\n",
      "[650]\tvalid_0's multi_error: 0.0719389\n",
      "[700]\tvalid_0's multi_error: 0.0717889\n",
      "[750]\tvalid_0's multi_error: 0.0717556\n",
      "[800]\tvalid_0's multi_error: 0.0717722\n",
      "[850]\tvalid_0's multi_error: 0.0716722\n",
      "[900]\tvalid_0's multi_error: 0.0716944\n",
      "[950]\tvalid_0's multi_error: 0.0714667\n",
      "[1000]\tvalid_0's multi_error: 0.0715222\n",
      "[1050]\tvalid_0's multi_error: 0.0715056\n",
      "Early stopping, best iteration is:\n",
      "[955]\tvalid_0's multi_error: 0.0714167\n",
      "(180000,)\n",
      "current validation score:  0.9285833333333333\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_error: 0.0775389\n",
      "[100]\tvalid_0's multi_error: 0.0746444\n",
      "[150]\tvalid_0's multi_error: 0.0731056\n",
      "[200]\tvalid_0's multi_error: 0.0726222\n",
      "[250]\tvalid_0's multi_error: 0.0721111\n",
      "[300]\tvalid_0's multi_error: 0.0718667\n",
      "[350]\tvalid_0's multi_error: 0.0714333\n",
      "[400]\tvalid_0's multi_error: 0.0712111\n",
      "[450]\tvalid_0's multi_error: 0.0710889\n",
      "[500]\tvalid_0's multi_error: 0.0707389\n",
      "[550]\tvalid_0's multi_error: 0.0708778\n",
      "[600]\tvalid_0's multi_error: 0.0706722\n",
      "[650]\tvalid_0's multi_error: 0.07065\n",
      "[700]\tvalid_0's multi_error: 0.07045\n",
      "[750]\tvalid_0's multi_error: 0.0702611\n",
      "[800]\tvalid_0's multi_error: 0.0703389\n",
      "Early stopping, best iteration is:\n",
      "[735]\tvalid_0's multi_error: 0.0702222\n",
      "(180000,)\n",
      "current validation score:  0.9297777777777778\n",
      "accuracy score:  0.3834677777777778\n"
     ]
    }
   ],
   "source": [
    "for tr_idx, val_idx in kfold.split(train_feat, train_user[\"gender\"]-1):\n",
    "    tr_x, tr_y, val_x, val_y = train_feat.iloc[tr_idx], train_user[\"gender\"].iloc[tr_idx]-1, train_feat.iloc[val_idx], train_user[\"gender\"].iloc[val_idx]-1\n",
    "    train_set = lgb.Dataset(tr_x, tr_y)\n",
    "    val_set = lgb.Dataset(val_x, val_y)\n",
    "    lgb_model = lgb.train(params_gender, train_set,\n",
    "                          valid_sets=[val_set], early_stopping_rounds=100, num_boost_round=40000, verbose_eval=50)\n",
    "    val_pred = np.argmax(lgb_model.predict(\n",
    "        val_x, num_iteration=lgb_model.best_iteration), axis=1)\n",
    "    print(val_pred.shape)\n",
    "    val_score = accuracy_score(val_pred, val_y)\n",
    "    gender_result_proba.append(lgb_model.predict(\n",
    "        test_feat, num_iteration=lgb_model.best_iteration))\n",
    "    gender_scores.append(val_score)\n",
    "    print(\"current validation score: \", val_score)\n",
    "print(\"accuracy score: \", np.mean(gender_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_error: 0.0769889\n",
    "[100]\tvalid_0's multi_error: 0.0740056\n",
    "[150]\tvalid_0's multi_error: 0.0725722\n",
    "[200]\tvalid_0's multi_error: 0.0719167\n",
    "[250]\tvalid_0's multi_error: 0.0712667\n",
    "[300]\tvalid_0's multi_error: 0.0709833\n",
    "[350]\tvalid_0's multi_error: 0.07065\n",
    "[400]\tvalid_0's multi_error: 0.0704556\n",
    "[450]\tvalid_0's multi_error: 0.0705111\n",
    "[500]\tvalid_0's multi_error: 0.0702056\n",
    "[550]\tvalid_0's multi_error: 0.0702778\n",
    "[600]\tvalid_0's multi_error: 0.0703556\n",
    "Early stopping, best iteration is:\n",
    "[533]\tvalid_0's multi_error: 0.0700889\n",
    "current validation score:  0.9299111111111111\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_error: 0.0780278\n",
    "[100]\tvalid_0's multi_error: 0.0749444\n",
    "[150]\tvalid_0's multi_error: 0.0738611\n",
    "[200]\tvalid_0's multi_error: 0.0729833\n",
    "[250]\tvalid_0's multi_error: 0.0724833\n",
    "[300]\tvalid_0's multi_error: 0.0722667\n",
    "[350]\tvalid_0's multi_error: 0.0721722\n",
    "[400]\tvalid_0's multi_error: 0.0719389\n",
    "[450]\tvalid_0's multi_error: 0.072\n",
    "[500]\tvalid_0's multi_error: 0.0718778\n",
    "[550]\tvalid_0's multi_error: 0.0719444\n",
    "[600]\tvalid_0's multi_error: 0.0717833\n",
    "[650]\tvalid_0's multi_error: 0.0716056\n",
    "[700]\tvalid_0's multi_error: 0.0715778\n",
    "[750]\tvalid_0's multi_error: 0.0714444\n",
    "[800]\tvalid_0's multi_error: 0.0715\n",
    "[850]\tvalid_0's multi_error: 0.0714389\n",
    "[900]\tvalid_0's multi_error: 0.0714\n",
    "[950]\tvalid_0's multi_error: 0.0712778\n",
    "[1000]\tvalid_0's multi_error: 0.0711056\n",
    "[1050]\tvalid_0's multi_error: 0.0711222\n",
    "[1100]\tvalid_0's multi_error: 0.0711056\n",
    "Early stopping, best iteration is:\n",
    "[1015]\tvalid_0's multi_error: 0.0710556\n",
    "current validation score:  0.9289444444444445\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_error: 0.0769889\n",
    "[100]\tvalid_0's multi_error: 0.0738944\n",
    "[150]\tvalid_0's multi_error: 0.0724889\n",
    "[200]\tvalid_0's multi_error: 0.0717111\n",
    "[250]\tvalid_0's multi_error: 0.0712667\n",
    "[300]\tvalid_0's multi_error: 0.0709222\n",
    "[350]\tvalid_0's multi_error: 0.0709667\n",
    "[400]\tvalid_0's multi_error: 0.0706278\n",
    "[450]\tvalid_0's multi_error: 0.0706222\n",
    "[500]\tvalid_0's multi_error: 0.0703778\n",
    "[550]\tvalid_0's multi_error: 0.0703278\n",
    "[600]\tvalid_0's multi_error: 0.07025\n",
    "[650]\tvalid_0's multi_error: 0.0702\n",
    "[700]\tvalid_0's multi_error: 0.0701333\n",
    "[750]\tvalid_0's multi_error: 0.0701111\n",
    "[800]\tvalid_0's multi_error: 0.0701222\n",
    "[850]\tvalid_0's multi_error: 0.0699333\n",
    "[900]\tvalid_0's multi_error: 0.0699611\n",
    "[950]\tvalid_0's multi_error: 0.0700056\n",
    "Early stopping, best iteration is:\n",
    "[869]\tvalid_0's multi_error: 0.0699056\n",
    "current validation score:  0.9300944444444444\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_error: 0.0785556\n",
    "[100]\tvalid_0's multi_error: 0.0755944\n",
    "[150]\tvalid_0's multi_error: 0.0741278\n",
    "[200]\tvalid_0's multi_error: 0.0734722\n",
    "[250]\tvalid_0's multi_error: 0.07285\n",
    "[300]\tvalid_0's multi_error: 0.0724444\n",
    "[350]\tvalid_0's multi_error: 0.0723333\n",
    "[400]\tvalid_0's multi_error: 0.0722167\n",
    "[450]\tvalid_0's multi_error: 0.0720944\n",
    "[500]\tvalid_0's multi_error: 0.0720889\n",
    "[550]\tvalid_0's multi_error: 0.0719889\n",
    "[600]\tvalid_0's multi_error: 0.0718722\n",
    "[650]\tvalid_0's multi_error: 0.0719389\n",
    "[700]\tvalid_0's multi_error: 0.0717889\n",
    "[750]\tvalid_0's multi_error: 0.0717556\n",
    "[800]\tvalid_0's multi_error: 0.0717722\n",
    "[850]\tvalid_0's multi_error: 0.0716722\n",
    "[900]\tvalid_0's multi_error: 0.0716944\n",
    "[950]\tvalid_0's multi_error: 0.0714667\n",
    "[1000]\tvalid_0's multi_error: 0.0715222\n",
    "[1050]\tvalid_0's multi_error: 0.0715056\n",
    "Early stopping, best iteration is:\n",
    "[955]\tvalid_0's multi_error: 0.0714167\n",
    "current validation score:  0.9285833333333333\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_error: 0.0775389\n",
    "[100]\tvalid_0's multi_error: 0.0746444\n",
    "[150]\tvalid_0's multi_error: 0.0731056\n",
    "[200]\tvalid_0's multi_error: 0.0726222\n",
    "[250]\tvalid_0's multi_error: 0.0721111\n",
    "[300]\tvalid_0's multi_error: 0.0718667\n",
    "[350]\tvalid_0's multi_error: 0.0714333\n",
    "[400]\tvalid_0's multi_error: 0.0712111\n",
    "[450]\tvalid_0's multi_error: 0.0710889\n",
    "[500]\tvalid_0's multi_error: 0.0707389\n",
    "[550]\tvalid_0's multi_error: 0.0708778\n",
    "[600]\tvalid_0's multi_error: 0.0706722\n",
    "[650]\tvalid_0's multi_error: 0.07065\n",
    "[700]\tvalid_0's multi_error: 0.07045\n",
    "[750]\tvalid_0's multi_error: 0.0702611\n",
    "[800]\tvalid_0's multi_error: 0.0703389\n",
    "Early stopping, best iteration is:\n",
    "[735]\tvalid_0's multi_error: 0.0702222\n",
    "current validation score:  0.9297777777777778\n",
    "accuracy score:  0.3834677777777778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31368333, 1.31263889, 1.31427222, 1.30891111, 1.31514444])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gender_scores) + np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_result_proba[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gender_result_proba, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gender = np.argmax(np.mean(gender_result_proba, axis=0), axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_gender\"] = predicted_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb_multi_age = lgb.Booster(model_file=f\"{UMDIR}/lgb_multi_age_20200511045531.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb_multi_gender = lgb.Booster(model_file=f\"{UMDIR}/lgb_multi_gender_20200511034408.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model_lgb_multi_gender, max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model_lgb_multi_age, max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_feat[[UID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat.drop(UID, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res[\"predicted_age\"] = [list(x).index(max(x))+1 for x in model_lgb_multi_age.predict(test_feat, num_iteration=model_lgb_multi_age.best_iteration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"predicted_gender\"] = [list(x).index(max(x))+1 for x in model_lgb_multi_gender.predict(test_feat, num_iteration=model_lgb_multi_gender.best_iteration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_suffix = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(int(time.time())))\n",
    "res.to_csv(f\"{RESDIR}/res-{res_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     311174\n",
       "2     157088\n",
       "5     140865\n",
       "4     138148\n",
       "6     122965\n",
       "7      57124\n",
       "1      23535\n",
       "8      20220\n",
       "9      16601\n",
       "10     12280\n",
       "Name: predicted_age, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"predicted_age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    674121\n",
       "2    325879\n",
       "Name: predicted_gender, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"predicted_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cent result to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ti import session\n",
    "ti_session = session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ti_session.upload_data(path=f\"{RESDIR}/res-20200515004850.csv\", bucket=\"etveritas-1252104022\", key_prefix=RESDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
